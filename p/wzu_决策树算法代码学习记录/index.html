<!DOCTYPE html>
<html lang="en-us">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='这是WZU老师课程的机器学习--决策树代码的学习记录'><title>WZU_决策树算法代码学习记录</title>

<link rel='canonical' href='https://example.com/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/'>

<link rel="stylesheet" href="/scss/style.min.css"><meta property='og:title' content='WZU_决策树算法代码学习记录'>
<meta property='og:description' content='这是WZU老师课程的机器学习--决策树代码的学习记录'>
<meta property='og:url' content='https://example.com/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/'>
<meta property='og:site_name' content='叶宇浩随记博客'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='python' /><meta property='article:tag' content='sklearn' /><meta property='article:published_time' content='2021-09-07T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2021-09-07T00:00:00&#43;00:00'/>
<meta name="twitter:title" content="WZU_决策树算法代码学习记录">
<meta name="twitter:description" content="这是WZU老师课程的机器学习--决策树代码的学习记录">
    </head>
    <body class="
    article-page has-toc
">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex 
    
        extended
    
">
    
        <div id="article-toolbar">
            <a href="/" class="back-home">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



                <span>Back</span>
            </a>
        </div>
    
<main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/code/" style="background-color: #fa1; color: #fff;">
                编程
            </a>
        
            <a href="/categories/deeplearning/" style="background-color: #0f1503; color: #fff;">
                深度学习
            </a>
        
    </header>
    

    <h2 class="article-title">
        <a href="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">WZU_决策树算法代码学习记录</a>
    </h2>

    
    <h3 class="article-subtitle">
        这是WZU老师课程的机器学习--决策树代码的学习记录
    </h3>
    

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Sep 07, 2021</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    6 minute read
                </time>
            </div>
        
    </footer>
    
</div>
</header>

    <section class="article-content">
    <h1 id="机器学习练习7-决策树">机器学习练习7 决策树</h1>
<p>代码修改并注释：黄海广，haiguang2000@wzu.edu.cn</p>
<p>1．分类决策树模型是表示基于特征对实例进行分类的树形结构。决策树可以转换成一个<strong>if-then</strong>规则的集合，也可以看作是定义在特征空间划分上的类的条件概率分布。</p>
<p>2．决策树学习旨在构建一个与训练数据拟合很好，并且复杂度小的决策树。因为从可能的决策树中直接选取最优决策树是NP完全问题。现实中采用启发式方法学习次优的决策树。</p>
<p>决策树学习算法包括3部分：特征选择、树的生成和树的剪枝。常用的算法有ID3、
C4.5和CART。</p>
<p>3．特征选择的目的在于选取对训练数据能够分类的特征。特征选择的关键是其准则。常用的准则如下：</p>
<p>（1）样本集合$D$对特征$A$的信息增益（ID3）</p>
<p>$$g(D, A)=H(D)-H(D|A)$$</p>
<p>$$H(D)=-\sum_{k=1}^{K} \frac{\left|C_{k}\right|}{|D|} \log <em>{2} \frac{\left|C</em>{k}\right|}{|D|}$$</p>
<p>$$H(D | A)=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} H\left(D_{i}\right)$$</p>
<p>其中，$H(D)$是数据集$D$的熵，$H(D_i)$是数据集$D_i$的熵，$H(D|A)$是数据集$D$对特征$A$的条件熵。	$D_i$是$D$中特征$A$取第$i$个值的样本子集，$C_k$是$D$中属于第$k$类的样本子集。$n$是特征$A$取 值的个数，$K$是类的个数。</p>
<p>（2）样本集合$D$对特征$A$的信息增益比（C4.5）</p>
<p>$$g_{R}(D, A)=\frac{g(D, A)}{H(D)}$$</p>
<p>其中，$g(D,A)$是信息增益，$H(D)$是数据集$D$的熵。</p>
<p>（3）样本集合$D$的基尼指数（CART）</p>
<p>$$\operatorname{Gini}(D)=1-\sum_{k=1}^{K}\left(\frac{\left|C_{k}\right|}{|D|}\right)^{2}$$</p>
<p>特征$A$条件下集合$D$的基尼指数：</p>
<p>$$\operatorname{Gini}(D, A)=\frac{\left|D_{1}\right|}{|D|} \operatorname{Gini}\left(D_{1}\right)+\frac{\left|D_{2}\right|}{|D|} \operatorname{Gini}\left(D_{2}\right)$$</p>
<p>4．决策树的生成。通常使用信息增益最大、信息增益比最大或基尼指数最小作为特征选择的准则。决策树的生成往往通过计算信息增益或其他指标，从根结点开始，递归地产生决策树。这相当于用信息增益或其他准则不断地选取局部最优的特征，或将训练集分割为能够基本正确分类的子集。</p>
<p>5．决策树的剪枝。由于生成的决策树存在过拟合问题，需要对它进行剪枝，以简化学到的决策树。决策树的剪枝，往往从已生成的树上剪掉一些叶结点或叶结点以上的子树，并将其父结点或根结点作为新的叶结点，从而简化生成的决策树。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">math</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">log</span>
</span></span></code></pre></div><h2 id="创建数据">创建数据</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_data</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">datasets</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;青年&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;一般&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;青年&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;好&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;青年&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;好&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;青年&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;一般&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;青年&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;一般&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;中年&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;一般&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;中年&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;好&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;中年&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;好&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;中年&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;非常好&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;中年&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;非常好&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;老年&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;非常好&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;老年&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;好&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;老年&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;好&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;老年&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;非常好&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">[</span><span class="s1">&#39;老年&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;一般&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">               <span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">u</span><span class="s1">&#39;年龄&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;有工作&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;有自己的房子&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;信贷情况&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;类别&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 返回数据集和每个维度的名称</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">labels</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">datasets</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">create_data</span><span class="p">()</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">train_data</span>
</span></span></code></pre></div><p>result:
<figure 
	
		class="gallery-image" 
		style="
			flex-grow: 64; 
			flex-basis: 155px"
	>
	<a href="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree.png" data-size="506x782">
		<img src="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree.png"
			width="506"
			height="782"
			srcset="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree_huaa677e10781e51e6b1f9a3967debba50_60527_480x0_resize_box_3.png 480w, /p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree_huaa677e10781e51e6b1f9a3967debba50_60527_1024x0_resize_box_3.png 1024w"
			loading="lazy"
			>
	</a>
	
</figure></p>
<h2 id="熵">熵</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">calc_ent</span><span class="p">(</span><span class="n">datasets</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">data_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">label_count</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">#这里for优化可以直接用dict的setdefault功能</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data_length</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">label</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">label_count</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">label_count</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="n">label_count</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="n">ent</span> <span class="o">=</span> <span class="o">-</span><span class="nb">sum</span><span class="p">([(</span><span class="n">p</span> <span class="o">/</span> <span class="n">data_length</span><span class="p">)</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">p</span> <span class="o">/</span> <span class="n">data_length</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">label_count</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ent</span>
</span></span></code></pre></div><h2 id="条件熵">条件熵</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">cond_ent</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">data_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">feature_sets</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data_length</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">feature</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">axis</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">feature_sets</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">feature_sets</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="n">feature_sets</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">cond_ent</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([(</span><span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">/</span> <span class="n">data_length</span><span class="p">)</span> <span class="o">*</span> <span class="n">calc_ent</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">feature_sets</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">cond_ent</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">calc_ent</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
</span></span></code></pre></div><p>result:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="mf">0.9709505944546686</span>
</span></span></code></pre></div><h2 id="信息增益">信息增益</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">info_gain</span><span class="p">(</span><span class="n">ent</span><span class="p">,</span> <span class="n">cond_ent</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ent</span> <span class="o">-</span> <span class="n">cond_ent</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">info_gain_train</span><span class="p">(</span><span class="n">datasets</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="n">ent</span> <span class="o">=</span> <span class="n">calc_ent</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">best_feature</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">count</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">c_info_gain</span> <span class="o">=</span> <span class="n">info_gain</span><span class="p">(</span><span class="n">ent</span><span class="p">,</span> <span class="n">cond_ent</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">c</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">best_feature</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">c</span><span class="p">,</span> <span class="n">c_info_gain</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;特征(</span><span class="si">{}</span><span class="s1">) 的信息增益为： </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">c_info_gain</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 比较大小</span>
</span></span><span class="line"><span class="cl">    <span class="n">best_</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">best_feature</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="s1">&#39;特征(</span><span class="si">{}</span><span class="s1">)的信息增益最大，选择为根节点特征&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">best_</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">info_gain_train</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">datasets</span><span class="p">))</span>
</span></span></code></pre></div><p>result:
<figure 
	
		class="gallery-image" 
		style="
			flex-grow: 335; 
			flex-basis: 805px"
	>
	<a href="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-1.png" data-size="638x190">
		<img src="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-1.png"
			width="638"
			height="190"
			srcset="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-1_hu4643c68ca5b6ff9b0867ad6789c831b9_47052_480x0_resize_box_3.png 480w, /p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-1_hu4643c68ca5b6ff9b0867ad6789c831b9_47052_1024x0_resize_box_3.png 1024w"
			loading="lazy"
			>
	</a>
	
</figure></p>
<h2 id="利用id3算法生成决策树">利用ID3算法生成决策树</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 定义节点类 二叉树</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Node</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feature_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">root</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="n">label</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">feature_name</span> <span class="o">=</span> <span class="n">feature_name</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">feature</span> <span class="o">=</span> <span class="n">feature</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">tree</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;label:&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">label</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;tree&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">result</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">add_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">[</span><span class="n">val</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">label</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">feature</span><span class="p">]]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DTree</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_tree</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 熵</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@staticmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">calc_ent</span><span class="p">(</span><span class="n">datasets</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">data_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">label_count</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data_length</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">label</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">label_count</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">label_count</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">            <span class="n">label_count</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="n">ent</span> <span class="o">=</span> <span class="o">-</span><span class="nb">sum</span><span class="p">([(</span><span class="n">p</span> <span class="o">/</span> <span class="n">data_length</span><span class="p">)</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">p</span> <span class="o">/</span> <span class="n">data_length</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">label_count</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">ent</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 经验条件熵</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">cond_ent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">data_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">feature_sets</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data_length</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">feature</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">axis</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">feature_sets</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">feature_sets</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">            <span class="n">feature_sets</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">cond_ent</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([(</span><span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">/</span> <span class="n">data_length</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">calc_ent</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">feature_sets</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">cond_ent</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 信息增益</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@staticmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">info_gain</span><span class="p">(</span><span class="n">ent</span><span class="p">,</span> <span class="n">cond_ent</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">ent</span> <span class="o">-</span> <span class="n">cond_ent</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">info_gain_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="n">ent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calc_ent</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">best_feature</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">count</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">c_info_gain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">info_gain</span><span class="p">(</span><span class="n">ent</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cond_ent</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">c</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">best_feature</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">c</span><span class="p">,</span> <span class="n">c_info_gain</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 比较大小</span>
</span></span><span class="line"><span class="cl">        <span class="n">best_</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">best_feature</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">best_</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">        input:数据集D(DataFrame格式)，特征集A，阈值eta
</span></span></span><span class="line"><span class="cl"><span class="s2">        output:决策树T
</span></span></span><span class="line"><span class="cl"><span class="s2">        &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span>
</span></span><span class="line"><span class="cl">                                               <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span>
</span></span><span class="line"><span class="cl">                                                                    <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">train_data</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span>
</span></span><span class="line"><span class="cl">                                                                                            <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 1,若D中实例属于同一类Ck，则T为单节点树，并将类Ck作为结点的类标记，返回T</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">Node</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 2, 若A为空，则T为单节点树，将D中实例树最大的类Ck作为该节点的类标记，返回T</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">Node</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">root</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">label</span><span class="o">=</span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 3,计算最大信息增益 同5.1,Ag为信息增益最大的特征</span>
</span></span><span class="line"><span class="cl">        <span class="n">max_feature</span><span class="p">,</span> <span class="n">max_info_gain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">info_gain_train</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_data</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">max_feature_name</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">max_feature</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 4,Ag的信息增益小于阈值eta,则置T为单节点树，并将D中是实例数最大的类Ck作为该节点的类标记，返回T</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">max_info_gain</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">Node</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">root</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">label</span><span class="o">=</span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 5,构建Ag子集</span>
</span></span><span class="line"><span class="cl">        <span class="n">node_tree</span> <span class="o">=</span> <span class="n">Node</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">root</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">feature_name</span><span class="o">=</span><span class="n">max_feature_name</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="n">max_feature</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">feature_list</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">max_feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">index</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">feature_list</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">sub_train_df</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train_data</span><span class="p">[</span><span class="n">max_feature_name</span><span class="p">]</span> <span class="o">==</span>
</span></span><span class="line"><span class="cl">                                          <span class="n">f</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">max_feature_name</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># 6, 递归生成树</span>
</span></span><span class="line"><span class="cl">            <span class="n">sub_tree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">sub_train_df</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">node_tree</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">sub_tree</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># pprint.pprint(node_tree.tree)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">node_tree</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_tree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tree</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">datasets</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">create_data</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">data_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">dt</span> <span class="o">=</span> <span class="n">DTree</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">tree</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_df</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tree</span>
</span></span></code></pre></div><p>result:
<figure 
	
		class="gallery-image" 
		style="
			flex-grow: 1256; 
			flex-basis: 3016px"
	>
	<a href="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-2.png" data-size="1282x102">
		<img src="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-2.png"
			width="1282"
			height="102"
			srcset="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-2_hu2b224ad3ce0027486c1003169c52b47a_29383_480x0_resize_box_3.png 480w, /p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-2_hu2b224ad3ce0027486c1003169c52b47a_29383_1024x0_resize_box_3.png 1024w"
			loading="lazy"
			>
	</a>
	
</figure>
code:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">dt</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="s1">&#39;老年&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;否&#39;</span><span class="p">,</span> <span class="s1">&#39;一般&#39;</span><span class="p">])</span>
</span></span></code></pre></div><p>result:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">否</span>
</span></span></code></pre></div><h2 id="scikit-learn实例">Scikit-learn实例</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
</span></span></code></pre></div><p>使用Iris数据集，我们可以构建如下树：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># data</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_data</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">100</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># print(data)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">data</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">feature_name</span><span class="o">=</span> <span class="n">create_data</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="决策树分类">决策树分类</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">graphviz</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</span></span></code></pre></div><p>result:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="mf">0.9666666666666667</span>
</span></span></code></pre></div><p>一旦经过训练，就可以用 plot_tree函数绘制树：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span> 
</span></span></code></pre></div><p>result:
<figure 
	
		class="gallery-image" 
		style="
			flex-grow: 149; 
			flex-basis: 358px"
	>
	<a href="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-3.png" data-size="1276x854">
		<img src="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-3.png"
			width="1276"
			height="854"
			srcset="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-3_hu543453693a1cab007329b96a93f3ee12_239271_480x0_resize_box_3.png 480w, /p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-3_hu543453693a1cab007329b96a93f3ee12_239271_1024x0_resize_box_3.png 1024w"
			loading="lazy"
			>
	</a>
	
</figure>
也可以导出树</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tree_pic</span> <span class="o">=</span> <span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="s2">&#34;mytree.pdf&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;mytree.pdf&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">dot_graph</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_graph</span><span class="p">)</span>
</span></span></code></pre></div><p>或者，还可以使用函数 export_text以文本格式导出树。此方法不需要安装外部库，而且更紧凑：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_text</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">r</span> <span class="o">=</span> <span class="n">export_text</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span><span class="n">feature_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
</span></span></code></pre></div><p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 145; 
			flex-basis: 348px"
	>
	<a href="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-4.png" data-size="554x382">
		<img src="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-4.png"
			width="554"
			height="382"
			srcset="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-4_hudf131d3da5792b6bac3f610cb25ffd22_56638_480x0_resize_box_3.png 480w, /p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-4_hudf131d3da5792b6bac3f610cb25ffd22_56638_1024x0_resize_box_3.png 1024w"
			loading="lazy"
			>
	</a>
	
</figure></p>
<h3 id="决策树回归">决策树回归</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Create a random dataset</span>
</span></span><span class="line"><span class="cl"><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="mi">5</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span><span class="p">[::</span><span class="mi">5</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">3</span> <span class="o">*</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">-</span> <span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Fit regression model</span>
</span></span><span class="line"><span class="cl"><span class="n">regr_1</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">regr_2</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">regr_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">regr_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Predict</span>
</span></span><span class="line"><span class="cl"><span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">y_1</span> <span class="o">=</span> <span class="n">regr_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y_2</span> <span class="o">=</span> <span class="n">regr_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Plot the results</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&#34;black&#34;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&#34;darkorange&#34;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;data&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&#34;cornflowerblue&#34;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;max_depth=2&#34;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&#34;yellowgreen&#34;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;max_depth=5&#34;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;data&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;target&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;Decision Tree Regression&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p>result:
<figure 
	
		class="gallery-image" 
		style="
			flex-grow: 163; 
			flex-basis: 392px"
	>
	<a href="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-5.png" data-size="766x468">
		<img src="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-5.png"
			width="766"
			height="468"
			srcset="/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-5_hu9b4ff2f2ca3be03c789e2eed866bfcc4_67268_480x0_resize_box_3.png 480w, /p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/picture/WZU-ML-lesson7-DecisonTree-5_hu9b4ff2f2ca3be03c789e2eed866bfcc4_67268_1024x0_resize_box_3.png 1024w"
			loading="lazy"
			>
	</a>
	
</figure></p>
<h3 id="scikit-learn-的决策树参数">Scikit-learn 的决策树参数</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s2">&#34;gini&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">splitter</span><span class="o">=</span><span class="s2">&#34;best&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">min_impurity_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">presort</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">参数含义</span><span class="err">：</span>
</span></span><span class="line"><span class="cl"><span class="mf">1.</span><span class="n">criterion</span><span class="p">:</span><span class="n">string</span><span class="p">,</span> <span class="n">optional</span> <span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&#34;gini&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span><span class="n">分裂节点时评价准则是Gini指数</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span><span class="n">分裂节点时的评价指标是信息增益</span><span class="err">。</span>
</span></span><span class="line"><span class="cl"><span class="mf">2.</span><span class="n">max_depth</span><span class="p">:</span><span class="nb">int</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span> <span class="n">optional</span> <span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="err">。</span><span class="n">指定树的最大深度</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">            <span class="n">如果为None</span><span class="err">，</span><span class="n">表示树的深度不限</span><span class="err">。</span><span class="n">直到所有的叶子节点都是纯净的</span><span class="err">，</span><span class="n">即叶子节点</span>
</span></span><span class="line"><span class="cl">            <span class="n">中所有的样本点都属于同一个类别</span><span class="err">。</span><span class="n">或者每个叶子节点包含的样本数小于min_samples_split</span><span class="err">。</span>
</span></span><span class="line"><span class="cl"><span class="mf">3.</span><span class="n">splitter</span><span class="p">:</span><span class="n">string</span><span class="p">,</span> <span class="n">optional</span> <span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&#34;best&#34;</span><span class="p">)</span><span class="err">。</span><span class="n">指定分裂节点时的策略</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">splitter</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span><span class="n">表示选择最优的分裂策略</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">splitter</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span><span class="n">表示选择最好的随机切分策略</span><span class="err">。</span>
</span></span><span class="line"><span class="cl"><span class="mf">4.</span><span class="n">min_samples_split</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">optional</span> <span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="err">。</span><span class="n">表示分裂一个内部节点需要的做少样本数</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">如果为整数</span><span class="err">，</span><span class="n">则min_samples_split就是最少样本数</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">如果为浮点数</span><span class="p">(</span><span class="mi">0</span><span class="n">到1之间</span><span class="p">)</span><span class="err">，</span><span class="n">则每次分裂最少样本数为ceil</span><span class="p">(</span><span class="n">min_samples_split</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mf">5.</span><span class="n">min_samples_leaf</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">optional</span> <span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="err">。</span><span class="n">指定每个叶子节点需要的最少样本数</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">如果为整数</span><span class="err">，</span><span class="n">则min_samples_split就是最少样本数</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">如果为浮点数</span><span class="p">(</span><span class="mi">0</span><span class="n">到1之间</span><span class="p">)</span><span class="err">，</span><span class="n">则每个叶子节点最少样本数为ceil</span><span class="p">(</span><span class="n">min_samples_leaf</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mf">6.</span><span class="n">min_weight_fraction_leaf</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span> <span class="n">optional</span> <span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">           <span class="n">指定叶子节点中样本的最小权重</span><span class="err">。</span>
</span></span><span class="line"><span class="cl"><span class="mf">7.</span><span class="n">max_features</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">string</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span> <span class="n">optional</span> <span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span>
</span></span><span class="line"><span class="cl">           <span class="n">搜寻最佳划分的时候考虑的特征数量</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">如果为整数</span><span class="err">，</span><span class="n">每次分裂只考虑max_features个特征</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">如果为浮点数</span><span class="p">(</span><span class="mi">0</span><span class="n">到1之间</span><span class="p">)</span><span class="err">，</span><span class="n">每次切分只考虑int</span><span class="p">(</span><span class="n">max_features</span> <span class="o">*</span> <span class="n">n_features</span><span class="p">)</span><span class="n">个特征</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">如果为</span><span class="s1">&#39;auto&#39;</span><span class="n">或者</span><span class="s1">&#39;sqrt&#39;</span><span class="p">,</span><span class="n">则每次切分只考虑sqrt</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span><span class="n">个特征</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">如果为</span><span class="s1">&#39;log2&#39;</span><span class="p">,</span><span class="n">则每次切分只考虑log2</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span><span class="n">个特征</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">如果为None</span><span class="p">,</span><span class="n">则每次切分考虑n_features个特征</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">如果已经考虑了max_features个特征</span><span class="err">，</span><span class="n">但还是没有找到一个有效的切分</span><span class="err">，</span><span class="n">那么还会继续寻找</span>
</span></span><span class="line"><span class="cl">           <span class="n">下一个特征</span><span class="err">，</span><span class="n">直到找到一个有效的切分为止</span><span class="err">。</span>
</span></span><span class="line"><span class="cl"><span class="mf">8.</span><span class="n">random_state</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">RandomState</span> <span class="n">instance</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span> <span class="n">optional</span> <span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">如果为整数</span><span class="err">，</span><span class="n">则它指定了随机数生成器的种子</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">如果为RandomState实例</span><span class="err">，</span><span class="n">则指定了随机数生成器</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">如果为None</span><span class="err">，</span><span class="n">则使用默认的随机数生成器</span><span class="err">。</span>
</span></span><span class="line"><span class="cl"><span class="mf">9.</span><span class="n">max_leaf_nodes</span><span class="p">:</span> <span class="nb">int</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span> <span class="n">optional</span> <span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="err">。</span><span class="n">指定了叶子节点的最大数量</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">如果为None</span><span class="p">,</span><span class="n">叶子节点数量不限</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">           <span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">如果为整数</span><span class="err">，</span><span class="n">则max_depth被忽略</span><span class="err">。</span>
</span></span><span class="line"><span class="cl"><span class="mf">10.</span><span class="n">min_impurity_decrease</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span> <span class="n">optional</span> <span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">         <span class="n">如果节点的分裂导致不纯度的减少</span><span class="p">(</span><span class="n">分裂后样本比分裂前更加纯净</span><span class="p">)</span><span class="n">大于或等于min_impurity_decrease</span><span class="err">，</span><span class="n">则分裂该节点</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">         <span class="n">加权不纯度的减少量计算公式为</span><span class="err">：</span>
</span></span><span class="line"><span class="cl">         <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
</span></span><span class="line"><span class="cl">                            <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">         <span class="n">其中N是样本的总数</span><span class="err">，</span><span class="n">N_t是当前节点的样本数</span><span class="err">，</span><span class="n">N_t_L是分裂后左子节点的样本数</span><span class="err">，</span>
</span></span><span class="line"><span class="cl">         <span class="n">N_t_R是分裂后右子节点的样本数</span><span class="err">。</span><span class="n">impurity指当前节点的基尼指数</span><span class="err">，</span><span class="n">right_impurity指</span>
</span></span><span class="line"><span class="cl">         <span class="n">分裂后右子节点的基尼指数</span><span class="err">。</span><span class="n">left_impurity指分裂后左子节点的基尼指数</span><span class="err">。</span>
</span></span><span class="line"><span class="cl"><span class="mf">11.</span><span class="n">min_impurity_split</span><span class="p">:</span><span class="nb">float</span>
</span></span><span class="line"><span class="cl">         <span class="n">树生长过程中早停止的阈值</span><span class="err">。</span><span class="n">如果当前节点的不纯度高于阈值</span><span class="err">，</span><span class="n">节点将分裂</span><span class="err">，</span><span class="n">否则它是叶子节点</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">         <span class="n">这个参数已经被弃用</span><span class="err">。</span><span class="n">用min_impurity_decrease代替了min_impurity_split</span><span class="err">。</span>
</span></span><span class="line"><span class="cl"><span class="mf">12.</span><span class="n">class_weight</span><span class="p">:</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">dicts</span><span class="p">,</span> <span class="s2">&#34;balanced&#34;</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span>
</span></span><span class="line"><span class="cl">         <span class="n">类别权重的形式为</span><span class="p">{</span><span class="n">class_label</span><span class="p">:</span> <span class="n">weight</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">         <span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">如果没有给出每个类别的权重</span><span class="err">，</span><span class="n">则每个类别的权重都为1</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">         <span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">如果class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="err">，</span><span class="n">则分类的权重与样本中每个类别出现的频率成反比</span><span class="err">。</span>
</span></span><span class="line"><span class="cl">         <span class="n">计算公式为</span><span class="err">：</span><span class="n">n_samples</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_classes</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">         <span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">如果sample_weight提供了样本权重</span><span class="p">(</span><span class="n">由fit方法提供</span><span class="p">)</span><span class="err">，</span><span class="n">则这些权重都会乘以sample_weight</span><span class="err">。</span>
</span></span><span class="line"><span class="cl"><span class="mf">13.</span><span class="n">presort</span><span class="p">:</span><span class="nb">bool</span><span class="p">,</span> <span class="n">optional</span> <span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">指定是否需要提前排序数据从而加速训练中寻找最优切分的过程</span><span class="err">。</span><span class="n">设置为True时</span><span class="err">，</span><span class="n">对于大数据集</span>
</span></span><span class="line"><span class="cl">        <span class="n">会减慢总体的训练过程</span><span class="err">；</span><span class="n">但是对于一个小数据集或者设定了最大深度的情况下</span><span class="err">，</span><span class="n">会加速训练过程</span><span class="err">。</span>
</span></span></code></pre></div><h3 id="决策树调参">决策树调参</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 导入库</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 导入数据集</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>  <span class="c1"># 以全部字典形式返回,有data,target,target_names三个键</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span>
</span></span><span class="line"><span class="cl"><span class="n">target</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">target</span>
</span></span><span class="line"><span class="cl"><span class="n">name</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">target_names</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 能一次性取前2个</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span></code></pre></div><p>result:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="p">(</span><span class="mi">150</span><span class="p">,)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 数据分为训练集和测试集</span>
</span></span><span class="line"><span class="cl"><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">y</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 用GridSearchCV寻找最优参数（字典）</span>
</span></span><span class="line"><span class="cl"><span class="n">param</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;min_impurity_decrease&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;最优分类器:&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="s1">&#39;最优分数:&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>  <span class="c1"># 得到最优的参数和分值</span>
</span></span></code></pre></div><p>result:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">最优分类器</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;criterion&#39;</span><span class="p">:</span> <span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">,</span> <span class="s1">&#39;min_impurity_decrease&#39;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">}</span> <span class="n">最优分数</span><span class="p">:</span> <span class="mf">0.9416666666666665</span>
</span></span></code></pre></div><h2 id="参考">参考</h2>
<ul>
<li><a class="link" href="https://github.com/fengdu78/lihang-code"  target="_blank" rel="noopener"
    >https://github.com/fengdu78/lihang-code</a></li>
<li>《统计学习方法》，清华大学出版社，李航著，2019年出版</li>
<li><a class="link" href="https://scikit-learn.org"  target="_blank" rel="noopener"
    >https://scikit-learn.org</a></li>
</ul>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/python/">python</a>
        
            <a href="/tags/sklearn/">sklearn</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
</article>

    <aside class="related-contents--wrapper">
    
    
        <h2 class="section-title">Related contents</h2>
        <div class="related-contents">
            <div class="flex article-list--tile">
                
                    
<article class="">
    <a href="/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_02_%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/">
        
        

        <div class="article-details">
            <h2 class="article-title">阿里云_ML_02_数据探索</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_03_%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">
        
        

        <div class="article-details">
            <h2 class="article-title">阿里云_ML_03_特征工程</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_04_%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/">
        
        

        <div class="article-details">
            <h2 class="article-title">阿里云_ML_04_模型训练</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_05_%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/">
        
        

        <div class="article-details">
            <h2 class="article-title">阿里云_ML_05_模型验证</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/sklearn%E4%B8%AD%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81cross-validation/">
        
        

        <div class="article-details">
            <h2 class="article-title">sklearn中的交叉验证Cross-Validation</h2>
        </div>
    </a>
</article>
                
            </div>
        </div>
    
</aside>

     
    
        
    <div class="disqus-container">
    <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hugo-theme-stack" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

<style>
    .disqus-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
</style>

<script>
    window.addEventListener('onColorSchemeChange', (e) => {
        if (DISQUS) {
            DISQUS.reset({
                reload: true
            });
        }
    })
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2022 - 
        
        2023 叶宇浩随记博客
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.5.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer="true"
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css"integrity="sha256-c0uckgykQ9v5k&#43;IqViZOZKc47Jn7KQil4/MP3ySA3F8="crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css"integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE="crossorigin="anonymous"
            >

            </main>
    
        <aside class="sidebar right-sidebar sticky">
            <section class="widget archives">
                <div class="widget-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



                </div>
                <h2 class="widget-title section-title">Table of contents</h2>
                
                <div class="widget--toc">
                    <nav id="TableOfContents">
  <ol>
    <li><a href="#创建数据">创建数据</a></li>
    <li><a href="#熵">熵</a></li>
    <li><a href="#条件熵">条件熵</a></li>
    <li><a href="#信息增益">信息增益</a></li>
    <li><a href="#利用id3算法生成决策树">利用ID3算法生成决策树</a></li>
    <li><a href="#scikit-learn实例">Scikit-learn实例</a>
      <ol>
        <li><a href="#决策树分类">决策树分类</a></li>
        <li><a href="#决策树回归">决策树回归</a></li>
        <li><a href="#scikit-learn-的决策树参数">Scikit-learn 的决策树参数</a></li>
        <li><a href="#决策树调参">决策树调参</a></li>
      </ol>
    </li>
    <li><a href="#参考">参考</a></li>
  </ol>
</nav>
                </div>
            </section>
        </aside>
    

        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g="crossorigin="anonymous"
                defer="false"
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
