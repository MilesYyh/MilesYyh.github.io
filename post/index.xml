<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 叶宇浩随记博客</title>
    <link>https://example.com/post/</link>
    <description>Recent content in Posts on 叶宇浩随记博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://example.com/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PPT插入可交互的3D蛋白结构展示</title>
      <link>https://example.com/p/ppt%E6%8F%92%E5%85%A5%E5%8F%AF%E4%BA%A4%E4%BA%92%E7%9A%843d%E8%9B%8B%E7%99%BD%E7%BB%93%E6%9E%84%E5%B1%95%E7%A4%BA/</link>
      <pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt%E6%8F%92%E5%85%A5%E5%8F%AF%E4%BA%A4%E4%BA%92%E7%9A%843d%E8%9B%8B%E7%99%BD%E7%BB%93%E6%9E%84%E5%B1%95%E7%A4%BA/</guid>
      <description>偶然间在公众号的文章看到了在PPT中插入3D结构的展示方法[^学习来源1],感觉挺好玩的，遂写此post记录
结构格式要求 结构文件格式要求为gltf格式
gltf格式 glTF™ is a royalty-free specification for the efficient transmission and loading of 3D scenes and models by engines and applications. glTF minimizes the size of 3D assets, and the runtime processing needed to unpack and use them. glTF defines an extensible, publishing format that streamlines authoring workflows and interactive services by enabling the interoperable use of 3D content across the industry. [^学习来源2]简单来说，gltf就是一种3D结构格式的文件
将结构保存为gtlf格式 使用完PyMOL调整完蛋白结构后，直接保存为gltf格式即可
save xxx.</description>
    </item>
    
    <item>
      <title>De novo design of small beta barrel proteins</title>
      <link>https://example.com/p/de-novo-design-of-small-beta-barrel-proteins/</link>
      <pubDate>Tue, 14 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/de-novo-design-of-small-beta-barrel-proteins/</guid>
      <description>De novo design of small beta barrel proteins
link:https://www.pnas.org/doi/abs/10.1073/pnas.2207974120</description>
    </item>
    
    <item>
      <title>氨基酸结构缺失修复</title>
      <link>https://example.com/p/%E6%B0%A8%E5%9F%BA%E9%85%B8%E7%BB%93%E6%9E%84%E7%BC%BA%E5%A4%B1%E4%BF%AE%E5%A4%8D/</link>
      <pubDate>Sat, 11 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E6%B0%A8%E5%9F%BA%E9%85%B8%E7%BB%93%E6%9E%84%E7%BC%BA%E5%A4%B1%E4%BF%AE%E5%A4%8D/</guid>
      <description>说明 之前从PDB数据库上下载某个基因的野生型结构时，发生存在AA缺失的现象，即某些位点上的AA没有，碰巧这个缺失的位点在突变的范围内，位点的缺失在PyMOL中表现为断点，看了下PDB文件 (从PDB数据库上下载下来的原文件) 的missing信息 (只有从PDB数据库上下载的结构文件才会有missing字段，像结构预测的软件是没有的)，确实是缺失的（避免是因为PyMOL不能识别导致）
位点在377上缺失 紧接着，使用trRosetta预测了野生型的蛋白结构，发现在使用gmx pdb2gmx 时发现这个新的结构文件上原子缺失了（并不等同于上面的氨基酸缺失），如下报错： 也就是说gmx发现这个蛋白结构文件23位点的色氨酸Trp缺失了CH2的原子信息（注意可能还存在其他原子的缺失，只是Tyr-23的缺失在前面，所以先报错了）
遂记录下解决办法，针对AA缺失和原子缺失的修复方法
氨基酸缺失 Chimera-modeller填补 注意了，这里一定是要用PDB数据库上下载下来的结构文件，因为只有PDB上的结构文件，有足够多的补充信息， 比如上面在Vscode中展示的missing字段
导入结构文件，只显示蛋白主体 command-line中输入
#导入文件 open 蛋白的IDcode(PDB数据库的) 可以看到这些377 residue确实是缺失的，断点线处
#只展示蛋白主体，因为PDB上还含有配体、水分子等信息，这里巧用的chimera的内置的key-word delete ~protein #确保删除了配体 delete ligand 注意下，这里delete后的那些stick展现的残基实际上是这个蛋白的活性位点，chimera会默认突出显示
使用Model Loops 顶部menu
Tools... Structure Editing... Model/Refine Loops 调整参数（主要调整这几个）：
Model/remodel : 看自己的缺失位置去确定 Number of models to generate: 生成的结果数 Modeller license key: 这个key可以自己去modeller申请，免费的，MODELIRANJE 实际上这里用到的是Modeller同源建模 等待结果即可，chiemra主窗口的左下角可以看进度（不过这里使用的云端的Modeller的程序，当然了可以指定自己本地的Modeller） 保存最优结构pdb 运行完Modeller，Chimera会自动将结构比对在主窗口中 这里保存#1.1的结果
单击Modeller Results中的#1.1 在点击Modeller Results中不同的结构时，chimera会自动比对这个结构和原来的结构，并且此时主窗口和model都会只展示（选择）他们两个，其他则被暂时hide了起来
保存为PDB文件 顶部menu File... Save PDB... 注意，在Save models的选项中，选择自己想要保存的结果即可，比如这里的#1.1就是377位点上被补全后的氨基酸+整个其他位点的整体蛋白了，所以可以不用选择自己导入的那个结构文件了 确实补充上了
手动复制位点PDB信息到文件 这个方法有个前提，就是，能同时找到同一个类型的蛋白，比如说A和B两个蛋白，他们实际上是同一个蛋白（不要在乎这里的名字A、B），（假设）A是通过X-ray的方法得到的结构信息，它缺失的位点信息是1-39，B是通过NMR的方法得到的结构信息，它缺失的位点信息是532-543，那么我想补全A的话，可以通过B的1-39的PDB坐标复制到A的文件中 这个产生的结果，相对其他办法，比较麻烦，而且误差会比较大，但是也很有用</description>
    </item>
    
    <item>
      <title>A simple method for displaying the hydropathic character of a protein</title>
      <link>https://example.com/p/a-simple-method-for-displaying-the-hydropathic-character-of-a-protein/</link>
      <pubDate>Fri, 10 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/a-simple-method-for-displaying-the-hydropathic-character-of-a-protein/</guid>
      <description>DOI: 10.1016/0022-2836(82)90515-0 这篇论文讲了Kyte-Doolittle-scale即蛋白疏水性的数值 </description>
    </item>
    
    <item>
      <title>Kaggle酶的热稳定性预测比赛_我的参赛笔记</title>
      <link>https://example.com/p/kaggle%E9%85%B6%E7%9A%84%E7%83%AD%E7%A8%B3%E5%AE%9A%E6%80%A7%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B_%E6%88%91%E7%9A%84%E5%8F%82%E8%B5%9B%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sun, 05 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/kaggle%E9%85%B6%E7%9A%84%E7%83%AD%E7%A8%B3%E5%AE%9A%E6%80%A7%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B_%E6%88%91%E7%9A%84%E5%8F%82%E8%B5%9B%E7%AC%94%E8%AE%B0/</guid>
      <description>最近参加了一次酶稳定性预测的比赛，挺折磨的，发现很多东西都不会（主要是深度学习方面，学的不怎么好，理论和实际都比较缺，打算今年考完研后再系统性的学习一遍深度学习，不过所幸下次的学习有前面的杂七杂八学过的基础，美滋滋），特写此post来记录第一次真正使用过深度学习解决问题。
顺便吐槽一下结果，在比赛ddl的前一天排名很好的，反正有铜牌（相当满足），比赛结束后直掉800多名hh。 比赛背景介绍 本次比赛实际上是一个回归任务，即输入的数据为：AA sequence（分别是野生型的突变序列）；输出数据为：酶的热稳定性值；即有一个蛋白（野生型），它有很多突变的位点，然后，我们需要看这些位点的突变是有利否，即这些突变能否提高热稳定性
简单介绍一些计算生物方面的知识： 我一开始特别想用深度学习的方法（比如写个bliLSTM）来着，但是其实也不一定非得到上深度学习，因为现有的很多计算方法的结果也挺可靠的
蛋白质稳定性工作在应用机器学习方法之前，在相关领域内也有一些计算方法可以实现，如：ESM, EVE 和 Rosetta （Rosetta 真的神！）等 ，在这次比赛中，直接运用这些方法而非机器学习方法也是允许的 AlphaFold2的诞生：我们在这次比赛中的目标是利用一级结构预测热稳定性，而如何利用一级结构预测整体的三级 PDB 文件：蛋白质的整体结构是三维的，如何通过结构化数据的方式理解三维的关系，包括每个氨基酸的坐标、种类等，常用的是PDB文件，PDB文件是一个开放的数据库，可以从中查询蛋白质相应的数据，如果是数据库中没有的蛋白质，则可以用AlphaFold2、I-TASSER、trRosetta、Robetta等进行预测，预测结果也是一个类似PDB格式的描述三维原子三维坐标关系的文件。 数据集介绍 比赛提供的wild-type序列：
VPVNPEPDATSVENVALKTGSGDSQSDPIKADLEVKGQSALPFDVDCWAILCKGAPNVLQRVNEKTKNSNRDRSGANKGPFKDPQKWGIKALPPKNPSWSAQDFKSPEEYAFASSLQGGTNAILAPVNLASQNSQGGVLNGFYSANKVAQFDPSKPQQTKGTWFQITKFTGAAGPYCKALGSNDKSVCDKNKNIAGDWGFDPAKWAYQYDEKNNKFNYVGK train.csv 文件： seq_id:每条序列的身份即ID，用以区分序列 protein_sequence:蛋白质序列（官方说他们人为的将大部分将test测试集中的蛋白序列大部分都保持在了固定的220AA，即测试集中的蛋白序列部分氨基酸是被删除了的，可能是留下了结构域的部分） pH:每条序列的pH最适条件值 data_scource:每条序列对应的来源（实际上是每条序列是从哪里收集来的信息） tm:熔融温度，值越高，表示酶稳定性越高 train_updates_20220929.csv： 也是训练数据，官方的Train.csv文件有一定的错误，因此在9月29日发布了这份修改了错误的版本 test.csv 测试集 (它这里的数据相比于train.csv，少了tm的值) sample_submission： 最终预测结果文件提交的格式示例 wildtype_structure_prediction_af2.pdb 本次比赛野生型蛋白的三维结构文件 wild-type结构长这样 评分函数 本次比赛的评估指标是spearman 相关系数，即反应的是我们预测的tm值与真实值之间的相关性，因此本次比赛的相对大小重要性大于预测的绝对大小
前期准备 本次比赛的目标是通过氨基酸序列，预测酶的热稳定性，即回归任务，核心难点有以下几块：
训练数据集的构建：本次比赛允许使用外部数据，因此有参赛者找寻了大量的可用外部数据，需要研究如何将不同来源的数据合并在一个训练数据集。同时本次的测试数据集是仅由一条原始序列，进行各种单点突变而成，因此也需要在构建训练数据集的过程中尽量相似于测试数据，即单点突变等。
tm数据的缺乏。大量的外部数据中，直接给定温度:Tm的数据还是比较少的，因此也由许多参赛者找寻了跟TM的相关数据，如预测ΔΔG等
思路 基本思路，目前核心解决这个比赛任务的思路有以下几种：
传统的生物学方法解决:如blosum评分矩阵，rosetta等，这种方式可以不用训练数据，直接对测试集数据进行计算，给出稳定性分数，优势是计算方便，缺点是目前来看准确性一般 机器学习的预测方式(3D CNN):蛋白质在空间中最终是三维结构，因此可以用3DCNN进行预测 Transformer(序列预测)：直接将蛋白质的氨基酸序列，如AAAKL…，作为序列，运用如LSTM、Transformer等模型进行序列预测 传统建模（XGBOOST、LIGHTGBM）：运用各种方式进行特征工程，运用XGB、LGB进行预测 开源方案 赛开始之初，最重要的就是研究目前开源的代码，主流的方案和思路是哪些，我主要看了三个，如下：
LB开源最高、0.603分： https://www.kaggle.com/code/seyered/eda-novozymes-enzyme-stability XGB：https://www.kaggle.com/code/cdeotte/xgboost-5000-mutations-200-pdb-files-lb-0-410 3DCNN：https://www.kaggle.com/code/vslaykovsky/nesp-thermonet-v2 LB-0.603 这个代码的核心本质是利用一系列传统的生物计算方法为主，兼顾一部分机器学习算法的结果，进行模型的加权融合。主要的方法包括：
Blosum: BLOSUM (Blocks of Amino Acid Substitution Matrix）：传统的生物方法，会计算序列之间每一个氨基酸变化带来的影响大小 PLDDT：Alphafold2在预测出整体结构后，对每一个氨基酸会给出一个置信度打分，即PLDDT，代表预测的准确与否，与稳定性有一定相关性 DeepDDG：利用深度学习预测稳定性的算法，已开源 Demask：利用线性模型预测的氨基酸改变后的作用大小 此外还有RMSD、SASA、Rosetta等，不一一赘述了，原文中有比较清晰的介绍 XGBoost 作者在通过一系列特征工程，构建了每条序列的特征，并且利用XGB模型进行预测，其中特征包括：</description>
    </item>
    
    <item>
      <title>De novo design of luciferases using deep learning</title>
      <link>https://example.com/p/de-novo-design-of-luciferases-using-deep-learning/</link>
      <pubDate>Thu, 02 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/de-novo-design-of-luciferases-using-deep-learning/</guid>
      <description>De novo design of luciferases using deep learning
link:https://www.nature.com/articles/s41586-023-05696-3</description>
    </item>
    
    <item>
      <title>《PROTEIN ANATOMY》</title>
      <link>https://example.com/p/protein-anatomy/</link>
      <pubDate>Sat, 25 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/protein-anatomy/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>Macromolecular modeling and design in Rosetta: recent methods and frameworks</title>
      <link>https://example.com/p/macromolecular-modeling-and-design-in-rosetta-recent-methods-and-frameworks/</link>
      <pubDate>Thu, 19 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/macromolecular-modeling-and-design-in-rosetta-recent-methods-and-frameworks/</guid>
      <description>Macromolecular modeling and design in Rosetta: recent methods and frameworks
link:https://www.nature.com/articles/s41592-020-0848-2</description>
    </item>
    
    <item>
      <title>pandas数据排序sort_values()和sort_index()</title>
      <link>https://example.com/p/pandas%E6%95%B0%E6%8D%AE%E6%8E%92%E5%BA%8Fsort_values%E5%92%8Csort_index/</link>
      <pubDate>Thu, 19 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pandas%E6%95%B0%E6%8D%AE%E6%8E%92%E5%BA%8Fsort_values%E5%92%8Csort_index/</guid>
      <description>df.sort_values() DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind=&amp;lsquo;quicksort&amp;rsquo;, na_position=&amp;lsquo;last&amp;rsquo;)
参数说明：
axis：{0 or ‘index’, 1 or ‘columns’}, default 0 by：str or list of str；如果axis=0，那么by=&amp;ldquo;列名&amp;rdquo;；如果axis=1，那么by=&amp;ldquo;行名&amp;rdquo; ascending：布尔型，True则升序，如果by=[&amp;lsquo;列名1&amp;rsquo;,&amp;lsquo;列名2&amp;rsquo;]，则该参数可以是[True, False]， 即第一字段升序，第二个降序 1 2 2 注意：指定多列（多行）排序时，先按排在前面的列（行）排序，如果内部有相同数据，再对相同 数据内部用下一个列（行）排序，以此类推。如何内部无重复数据，则后续排列不执行。即首先满 足排在前面的参数的排序，再排后面参数 inplace：布尔型，是否用排序后的数据框替换现有的数据框 kind：排序方法，{‘quicksort’, ‘mergesort’, ‘heapsort’}, default ‘quicksort’。似 乎不用太关心 na_position：{‘first’, ‘last’}, default ‘last’，默认缺失值排在最后面。 df.sort_index() 功能和sort_values一致，但是它默认根据行标签（是所有行标签本身，而不是行对应的数据）对所有行排序，或根据列标签对所有列排序
sort_index(axis=0, level=None, ascending=True, inplace=False, kind=&amp;lsquo;quicksort&amp;rsquo;, na_position=&amp;lsquo;last&amp;rsquo;, sort_remaining=True, by=None)
import pandas as pd df = pd.DataFrame({&amp;#39;b&amp;#39;:[1,2,3,2],&amp;#39;a&amp;#39;:[4,3,2,1],&amp;#39;c&amp;#39;:[1,3,8,2]},index=[2,0,1,3]) df result: code:
df.sort_values(by=&amp;#34;c&amp;#34;) result: code:
df.sort_values(by=[&amp;#34;a&amp;#34;,&amp;#34;c&amp;#34;],ascending=[True,False]) result: code:
df result: code:</description>
    </item>
    
    <item>
      <title>我的算法学习导航页</title>
      <link>https://example.com/p/%E6%88%91%E7%9A%84%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%88%AA%E9%A1%B5/</link>
      <pubDate>Thu, 29 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E6%88%91%E7%9A%84%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%88%AA%E9%A1%B5/</guid>
      <description> 为什么写这一页？因为中间换电脑忘记把之前关于机器学习和深度学习的个人笔记复制到新的电脑上了，旧laptop被我格式化。属于是无语了，所以特写此页做导航页，方便自己检索知识
机器学习 基础知识：
吴恩达老师的课程 李航老师的统计学习方法 （已学完） 简博士的机器学习课程（学完了当时更新到的知识） 小康老师的机器学习课程（这个实际讲解的李航老师的那本书，当时是靠这个理解的） 刘老师的博客（常用！）： https://www.cnblogs.com/pinard/ 框架方面只学了个sklearn，通过代码实践学习 深度学习 李宏毅老师的课程 （已学完） pytorch 基础课程 小土堆 （已学完） 李沐老师的动手深度学习（已学完） 因为自己笔记全删除了（很痛心），所以找来两个很好的笔记分享（常用）：
https://github.com/ShusenTang/Dive-into-DL-PyTorch （本地安装运行会形成一个知识网页） https://blog.csdn.net/weixin_42306148/article/details/123754540?spm=1001.2014.3001.5501 </description>
    </item>
    
    <item>
      <title>阿里云_ML_02_数据探索</title>
      <link>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_02_%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/</link>
      <pubDate>Sat, 24 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_02_%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/</guid>
      <description>这个post是自己去跟着阿里云天池上的机器学习的一个案例跟着敲了一遍代码，并且加了自己的理解，放到这里来随时回顾
读取数据 import pandas as pd import numpy as np import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import seaborn as sns #scipy 是一个统计学习的库 from scipy import stats train_data = pd.read_csv(&amp;#34;./zhengqi_train.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) test_data = pd.read_csv(&amp;#34;./zhengqi_test.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) 查看训练集特征变量信息 train_data.head() result: code:
train_data.info result 此训练集数据共有2888个样本，数据中有V0-V37共计38个特征变量，变量类型都为数值类型，所有数据特征没有缺失值数据； 数据字段由于采用了脱敏处理，删除了特征数据的具体含义；target字段为标签变量
code:
test_data.info result: 测试集数据共有1925个样本，数据中有V0-V37共计38个特征变量，变量类型都为数值类型
查看数据统计信息 train_data.describe() result: code:
test_data.describe() result: 上面数据显示了数据的统计信息，例如样本数，数据的均值mean，标准差std，最小值，最大值等
查看数据字段信息 code:
train_data.head() result: 上面显示训练集前5条数据的基本信息，可以看到数据都是浮点型数据，数据都是数值型连续型特征
code:
test_data.head() result: 画箱形图探索数据 code:
#指定绘图对象的宽和高 fig = plt.figure(figsize=(4,8)) # orient：&amp;#34;v&amp;#34;|&amp;#34;h&amp;#34; 用于控制图像使水平还是竖直显示 sns.</description>
    </item>
    
    <item>
      <title>阿里云_ML_03_特征工程</title>
      <link>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_03_%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</link>
      <pubDate>Sat, 24 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_03_%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</guid>
      <description>这个post是自己去跟着阿里云天池上的机器学习的一个案例跟着敲了一遍代码，并且加了自己的理解，放到这里来随时回顾
import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) #从scipy中导入stats统计函数 from scipy import stats plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False train_data = pd.read_csv(&amp;#34;./zhengqi_train.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) test_data = pd.read_csv(&amp;#34;./zhengqi_test.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) train_data.describe() result: 异常值分析 plt.figure(figsize=(18,10)) #x传入的每一列的特征值（数值），labels传入的是每个特征值的名字即列名 就是图中的x轴的名字 plt.boxplot(x=train_data.values,labels=train_data.columns) plt.hlines([7.5,-7.5],0,40,colors=&amp;#34;r&amp;#34;) plt.show() result: 删除异常值 train_data = train_data[train_data[&amp;#34;V9&amp;#34;]&amp;gt;-7.5] train_data.describe() result: code:
train_data.head() result: 最大最小值归一化 code:
from sklearn import preprocessing feature_columns = [col for col in train_data.columns if col not in [&amp;#34;target&amp;#34;]] #注意MinScaler传入的是每一列的数据 min_max_scaler = preprocessing.</description>
    </item>
    
    <item>
      <title>阿里云_ML_04_模型训练</title>
      <link>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_04_%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/</link>
      <pubDate>Sat, 24 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_04_%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/</guid>
      <description>这个post是自己去跟着阿里云天池上的机器学习的一个案例跟着敲了一遍代码，并且加了自己的理解，放到这里来随时回顾
import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) from scipy import stats %matplotlib inline 读取数据 train_data = pd.read_csv(&amp;#34;./zhengqi_train.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) test_data = pd.read_csv(&amp;#34;./zhengqi_test.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) train_data.describe() result: 异常值分析 其实就是画给box图看离散的点
plt.figure(figsize=(18,10)) plt.boxplot(x=train_data.values,labels=train_data.columns) plt.hlines([-7.5,7.5],0,40,colors=&amp;#34;Blue&amp;#34;) plt.show() result: 删除异常值 train_data = train_data[train_data[&amp;#34;V9&amp;#34;]&amp;gt;-7.5] train_data.describe() result: code:
test_data.describe() result: 最大值最小值归一化处理 from sklearn import preprocessing features_columns = [col for col in train_data.columns if col not in [&amp;#34;target&amp;#34;]] min_max_scaler = preprocessing.</description>
    </item>
    
    <item>
      <title>阿里云_ML_05_模型验证</title>
      <link>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_05_%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/</link>
      <pubDate>Sat, 24 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_05_%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/</guid>
      <description>这个post是自己去跟着阿里云天池上的机器学习的一个案例跟着敲了一遍代码，并且加了自己的理解，放到这里来随时回顾
过拟合与欠拟合的问题 获取并绘制数据集 import numpy as np import matplotlib.pyplot as plt import pandas as pd np.random.seed(22) x = np.random.uniform(-3.0,3.0,size=100) X = x.reshape(-1,1)#-1表示系统自动计算行 #np.random.normal()产生正态分布的数 y = 0.5 * x**2 + x + 2 + np.random.normal(0,1,size=100) plt.scatter(x,y) plt.show() result: 使用线性回归拟合数据 from sklearn.linear_model import LinearRegression lin_reg = LinearRegression() lin_reg.fit(X,y) lin_reg.score(X,y)#score返回的是准确率 result:
0.4340452690750729 准确率为 0.434，比较低，直线拟合数据的程度较低
使用均方误差判断拟合程度 from sklearn.metrics import mean_squared_error y_predict = lin_reg.predict(X) mean_squared_error(y_predict,y) result:
2.7365298290204287 绘制拟合效果 plt.scatter(x,y) plt.plot(np.sort(x),y_predict[np.argsort(x)],color=&amp;#34;red&amp;#34;) plt.show() result: 使用多项式回归拟合:
封装Pipeline管道 #Pipeline封装算法流 from sklearn.</description>
    </item>
    
    <item>
      <title>Computer-aided design of functional protein interactions</title>
      <link>https://example.com/p/computer-aided-design-of-functional-protein-interactions/</link>
      <pubDate>Thu, 22 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/computer-aided-design-of-functional-protein-interactions/</guid>
      <description>Computer-aided design of functional protein interactions https://www.nature.com/articles/nchembio.251</description>
    </item>
    
    <item>
      <title>《PROTEIN ANATOMY》</title>
      <link>https://example.com/p/protein-anatomy/</link>
      <pubDate>Fri, 16 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/protein-anatomy/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>sklearn中的交叉验证Cross-Validation</title>
      <link>https://example.com/p/sklearn%E4%B8%AD%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81cross-validation/</link>
      <pubDate>Fri, 16 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sklearn%E4%B8%AD%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81cross-validation/</guid>
      <description>sklearn是利用python进行机器学习中一个非常全面和好用的第三方库，用过的都说好。今天主要记录一下sklearn中关于交叉验证的各种用法，主要是对sklearn官方文档 https://scikit-learn.org/stable/modules/cross_validation.html
import numpy as np from sklearn.model_selection import train_test_split from sklearn.datasets import load_iris from sklearn import svm iris = load_iris() iris.data.shape,iris.target.shape result:
((150, 4), (150,)) train_test_split 对数据集进行快速打乱（分为训练集和测试集）, 这里相当于对数据集进行了shuffle后按照给定的test_size进行数据集划分
这里是按照6:4对训练集测试集进行划分 X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target,test_size=.4,random_state=22)
code:
X_train.shape,y_train.shape result:
((90, 4), (90,)) code:
iris.data[:5] result: code:
X_train[:5] result: code:
clf = svm.SVC(kernel=&amp;#34;linear&amp;#34;,C=1) clf.fit(X_train,y_train) result:
SVC(C=1, kernel=&amp;#39;linear&amp;#39;) clf.score(X_test,y_test) result:
0.9833333333333333 cross_val_score 对数据集进行指定次数的交叉验证并为每次验证效果评测 其中，score 默认是以 scoring=&amp;lsquo;f1_macro’进行评测的，余外针对分类或回归还有： 这需要from　sklearn import metrics ,通过在cross_val_score 指定参数来设定评测标准； 当cv 指定为int 类型时，默认使用KFold 或StratifiedKFold 进行数据集打乱，下面会对KFold 和StratifiedKFold 进行介绍</description>
    </item>
    
    <item>
      <title>Obtaining protein foldability information from computational models of AlphaFold2 and RoseTTAFold</title>
      <link>https://example.com/p/obtaining-protein-foldability-information-from-computational-models-of-alphafold2-and-rosettafold/</link>
      <pubDate>Thu, 15 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/obtaining-protein-foldability-information-from-computational-models-of-alphafold2-and-rosettafold/</guid>
      <description>Obtaining protein foldability information from computational models of AlphaFold2 and RoseTTAFold
link:https://www.sciencedirect.com/science/article/pii/S2001037022003683</description>
    </item>
    
    <item>
      <title>Accurate positioning of functional residues with robotics-inspired computational protein design </title>
      <link>https://example.com/p/accurate-positioning-of-functional-residues-with-robotics-inspired-computational-protein-design/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/accurate-positioning-of-functional-residues-with-robotics-inspired-computational-protein-design/</guid>
      <description>Accurate positioning of functional residues with robotics-inspired computational protein design
link:https://www.pnas.org/doi/abs/10.1073/pnas.2115480119</description>
    </item>
    
    <item>
      <title>Robust deep learning–based protein sequence design using ProteinMPNN</title>
      <link>https://example.com/p/robust-deep-learningbased-protein-sequence-design-using-proteinmpnn/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/robust-deep-learningbased-protein-sequence-design-using-proteinmpnn/</guid>
      <description>Robust deep learning–based protein sequence design using ProteinMPNN
link:https://www.science.org/doi/abs/10.1126/science.add2187</description>
    </item>
    
    <item>
      <title>Control of protein signaling using a computationally designed GTPase/GEF orthogonal pair</title>
      <link>https://example.com/p/control-of-protein-signaling-using-a-computationally-designed-gtpase/gef-orthogonal-pair/</link>
      <pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/control-of-protein-signaling-using-a-computationally-designed-gtpase/gef-orthogonal-pair/</guid>
      <description>Control of protein signaling using a computationally designed GTPase/GEF orthogonal pair
link:https://www.pnas.org/cai/doi/10.1073/pnas.1114487109</description>
    </item>
    
    <item>
      <title>pandas的分组取最大多行并求和函数nlargest()</title>
      <link>https://example.com/p/pandas%E7%9A%84%E5%88%86%E7%BB%84%E5%8F%96%E6%9C%80%E5%A4%A7%E5%A4%9A%E8%A1%8C%E5%B9%B6%E6%B1%82%E5%92%8C%E5%87%BD%E6%95%B0nlargest/</link>
      <pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pandas%E7%9A%84%E5%88%86%E7%BB%84%E5%8F%96%E6%9C%80%E5%A4%A7%E5%A4%9A%E8%A1%8C%E5%B9%B6%E6%B1%82%E5%92%8C%E5%87%BD%E6%95%B0nlargest/</guid>
      <description>在pandas库里面，我们常常关心的是最大的前几个，比如销售最好的几个产品，几个店，等。之前讲到的head(), 能够看到看到DF里面的前几行，如果需要看到最大或者最小的几行就需要先进行排序。max()和min()可以看到最大或者最小值，但是只能看到一个值。 所以我们可以使用nlargest()函数，nlargest()的优点就是能一次看到最大的几行，而且不需要排序。缺点就是只能看到最大的，看不到最小的。 单价排在前十的数据
nlargest()的第一个参数就是截取的行数。第二个参数就是依据的列名。
这样就可以筛选出单价最高的前十行，而且是按照单价从最高到最低进行排列的，所以还是按照之前的索引。
还可以按照total_price来进行排名 按照total_price排名
nlargest还有一个参数，keep=&amp;lsquo;first&amp;rsquo;或者&amp;rsquo;last&amp;rsquo;。当出现重复值的时候，keep=&amp;lsquo;first&amp;rsquo;,会选取在原始DataFrame里排在前面的，keep=&amp;lsquo;last&amp;rsquo;则去排后面的。
由于nlagerst()不能去最小的多个值，如果我们一定要使用这个函数进行选取也是可以的.
先设置一个辅助列 然后在进行选取： 以辅助列进行选取
当然了，也可以通过head()加上排序进行选取的。
那以前这些操作都可以通过其它函数来进行替代的话，nlargest()有什么必要介绍吗？或者说学不学这个函数有什么关系吗？
这就是我们今天要重点介绍的，如果说要选择不同location_road下的前五名要怎么操作呢？
很多人可能第一反应会想到先分组然后进行max()操作，但是这样的操作只能选择最大的一列： 使用max()
但是使用max有一个问题，就是选取的是每一列的最大值，而不是选取最大值的那一行，也就是说只能在选取单列的最大值的时候才是准确的。
这个时候我们就要想到apply和lambda的自定义函数了
选取多个指标的TOP(N)
这样就选出了不同loaction_road的price排在前五的行了。
nlargest()函数在这种场景下使用是非常方便的，而且结果也已经默认排好顺序了。
还有一些场景下需要计算分组的前几名，然后在进行求和的，这个我们也可以使用nlargest进行操作： 分组之后进行求和
使用这种方法会出现报错提示，这个因为在列和索引都存在loaction_road，有重复，系统有警告，在实际使用时可以先改列名再操作。我们也可以换一种方式直接按照索引进行求和，这样就没有警告了： </description>
    </item>
    
    <item>
      <title>蛋白结构图片美化</title>
      <link>https://example.com/p/%E8%9B%8B%E7%99%BD%E7%BB%93%E6%9E%84%E5%9B%BE%E7%89%87%E7%BE%8E%E5%8C%96/</link>
      <pubDate>Thu, 20 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E8%9B%8B%E7%99%BD%E7%BB%93%E6%9E%84%E5%9B%BE%E7%89%87%E7%BE%8E%E5%8C%96/</guid>
      <description>这是我在别人的基础上，然后自行调整了很多细节信息，较为满意的结构图片的展示，特写此post来记录分享（take an example），当然了，能帮到大家也是一件极好的事 （主要用的都是cmd的命令，所以本记录不适合零基础）
载入蛋白结构 这里我使用的是PDB code 4MDS
load 4MDS 去除水分子和配体 这一步根据自己的需要去做 （其实做不做都无所谓）
去水 去水（蛋白主体旁边的红点其实就是水分子）
remove solvent 展示序列信息 set seq_view,1 可以看到这里有三个配体，名字分别为23H，DMS
去除配体结构 resn 后面的名字 （23H，DMS）根据自己研究蛋白的配体名字来修改
remove resn 23H remove resn DMS 复制主要参数 这里的参数来源于参考资料[^1]，我略作了修改
select resn HOH remove sele select hydrophobic, (resn ala+gly+val+ile+leu+phe+met) show sticks, (hydrophobic and (!name c+n+o)) color yelloworange, hydrophobic select hydrophilic, !hydrophobic and (!name c+n+o) show sticks, hydrophilic color lightblue, hydrophilic color white, bb. color oxygen, elem o color nitrogen, elem N color sulfur, elem S set ray_trace_mode,3 set stick_radius, 0.</description>
    </item>
    
    <item>
      <title>PyMOL蛋白结美化参数(整合)</title>
      <link>https://example.com/p/pymol%E8%9B%8B%E7%99%BD%E7%BB%93%E7%BE%8E%E5%8C%96%E5%8F%82%E6%95%B0%E6%95%B4%E5%90%88/</link>
      <pubDate>Wed, 12 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pymol%E8%9B%8B%E7%99%BD%E7%BB%93%E7%BE%8E%E5%8C%96%E5%8F%82%E6%95%B0%E6%95%B4%E5%90%88/</guid>
      <description>PyMOL的功能十分强大，特别是命令行的参数，它可以对蛋白结构的细节展示进行许多调整，方便使用，这里集合一些参数，直接复制进pymol的cmd即可（本post会持续更新）
PyMOL-wiki PyMOL官网本身有gallery（https://pymolwiki.org/index.php/Gallery），这里会有一堆大佬去上传自己的展示参数，只不过，我发现似乎有点少 下面的大部分是转载的[^学习来源2],当然了，用到自己的结构上时，可以自行参数调整，比如不喜欢侧链的信息，就可以自行hide起来，自行修改color等
细节侧链美漫风 参数
reinitialize select resn HOH remove sele select hydrophobic, (resn ala+gly+val+ile+leu+phe+met) show sticks, (hydrophobic and (!name c+n+o)) color yelloworange, hydrophobic select hydrophilic, !hydrophobic and (!name c+n+o) show sticks, hydrophilic color lightblue, hydrophilic color white, bb. color oxygen, elem o color nitrogen, elem N color sulfur, elem S set ray_trace_mode,3 set stick_radius, 0.4 set cartoon_loop_radius, 0.4 set cartoon_oval_width, 0.4 set cartoon_rect_width, 0.4 set fog,0 bg_color white set valence, 0 set ray_shadow, 0 zoom orient ray 图片展示（take PDB code:7f52，删除了水分子，图片背景实际上是白色的，放在word中会更明显） 个人很喜欢这个风格，不过我经常会将其他的侧链信息都隐藏起来，从而突出某些位点的sticks</description>
    </item>
    
    <item>
      <title>有意思的卷积运算动画</title>
      <link>https://example.com/p/%E6%9C%89%E6%84%8F%E6%80%9D%E7%9A%84%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97%E5%8A%A8%E7%94%BB/</link>
      <pubDate>Sat, 24 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E6%9C%89%E6%84%8F%E6%80%9D%E7%9A%84%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97%E5%8A%A8%E7%94%BB/</guid>
      <description> 在stackflow上看到了两个生动的卷积运算的动画，感觉很明了，来源：http://ww1.machinelearninguru.com/
Your browser doesn&#39;t support HTML5 video. Here is a link to the video instead. Your browser doesn&#39;t support HTML5 video. Here is a link to the video instead. </description>
    </item>
    
    <item>
      <title>《蛋白质结构导论》</title>
      <link>https://example.com/p/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E5%AF%BC%E8%AE%BA/</link>
      <pubDate>Wed, 07 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E5%AF%BC%E8%AE%BA/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>pd.quantile分位数方法</title>
      <link>https://example.com/p/pd.quantile%E5%88%86%E4%BD%8D%E6%95%B0%E6%96%B9%E6%B3%95/</link>
      <pubDate>Sun, 04 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pd.quantile%E5%88%86%E4%BD%8D%E6%95%B0%E6%96%B9%E6%B3%95/</guid>
      <description>参考资料：
https://www.zhihu.com/question/67763556
https://www.jianshu.com/p/a3cb124679df
首先来了解下什么是分位数，实际上就是用概率作为依据将一批数据分开的那个点
举个实例：
分位数是数据分析中常用的一个统计量，经过抽样得到一个样本值，以学生成成绩为例：
60,70,87,56,35,64,28,84,89,65.
p分位数
如果想在这10位同学中淘汰至少35%,同时让至少65%的同学晋级，你怎么选？
当然的想法是找一个数，小于等于这个数的同学至少有35%,大于等于这个数的同学至少有65%,
要想顺利地找到这个数，需要将数据排序：
28, 35, 56, 60，64, 65, 70, 84, 87, 89
排序后上面十个数分别记为x(1)到x(10).
至少有35%,即至少有10*35%=3.5个学生，所以x_0.35 ≥60=x(4); （从左到右）
至少有65%，即至少有10*65%=6.5个学生，所以x_0.35≤60=x(4); （从右到左）
故二者取交集，令x_0.35 =60.
以上是np不为整数的情况，如果np为整数，不妨设p=0.3
至少有30%,即至少有10*30%=3个学生，所以x_0.3 ≥56=x(3); （从左到右）
至少有70%，即至少有10*70%=7个学生，所以x_0.3≤60=x(4); （从右到左）
二者取交集，有两个值，一个是56,一个是60,如何选取？就取二者的平均值
x_0.3＝（56+60）/2=58.
补充：
常见的四分位数：
四分位数（Quartile) 也称四分位点，是指在统计学中把所有数值由小到大排列并分成四等份，处于三个分割点位置的数值
第一四分位数 (Q1)，又称“较小四分位数”，等于该样本中所有数值由小到大排列后第25%的数字
第二四分位数 (Q2)，又称“中位数”，等于该样本中所有数值由小到大排列后第50%的数字。
第三四分位数 (Q3)，又称“较大四分位数”，等于该样本中所有数值由小到大排列后第75%的数字。
第三四分位数与第一四分位数的差距又称四分位距（InterQuartile Range,IQR）
正如上文所言，四分位数 就是将数据从小到大排成4等分，然后取出3个分割点的数值。百分位数则以此类推，通过分位数 我们可以对数据的分布有更深的了解
分位数的计算方法有两种，以四分位数为例
n+1 方法 n是项数 n+1 算出来的结果会比实际稍高一些
n = 10 Q1 = (n+1) * 0.25 Q2 = (n+1) * 0.50 Q3 = (n+1) * 0.</description>
    </item>
    
    <item>
      <title>De novo design of small beta barrel proteins</title>
      <link>https://example.com/p/de-novo-design-of-small-beta-barrel-proteins/</link>
      <pubDate>Thu, 25 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/de-novo-design-of-small-beta-barrel-proteins/</guid>
      <description>Highly accurate protein structure prediction with AlphaFold
link:https://www.nature.com/articles/s41586-021-03819-2</description>
    </item>
    
    <item>
      <title>《Python Cookbook》第三版中文v2.0.0</title>
      <link>https://example.com/p/python-cookbook%E7%AC%AC%E4%B8%89%E7%89%88%E4%B8%AD%E6%96%87v2.0.0/</link>
      <pubDate>Fri, 19 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/python-cookbook%E7%AC%AC%E4%B8%89%E7%89%88%E4%B8%AD%E6%96%87v2.0.0/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>Accurate prediction of protein structures and interactions using a 3-track neural network</title>
      <link>https://example.com/p/accurate-prediction-of-protein-structures-and-interactions-using-a-3-track-neural-network/</link>
      <pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/accurate-prediction-of-protein-structures-and-interactions-using-a-3-track-neural-network/</guid>
      <description>Accurate prediction of protein structures and interactions using a 3-track neural network
link:https://www.science.org/doi/abs/10.1126/science.abj8754</description>
    </item>
    
    <item>
      <title>Automated Design of Efficient and Functionally Diverse Enzyme Repertoires </title>
      <link>https://example.com/p/automated-design-of-efficient-and-functionally-diverse-enzyme-repertoires/</link>
      <pubDate>Thu, 11 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/automated-design-of-efficient-and-functionally-diverse-enzyme-repertoires/</guid>
      <description>Automated Design of Efficient and Functionally Diverse Enzyme Repertoires
link:https://www.sciencedirect.com/science/article/pii/S1097276518306932</description>
    </item>
    
    <item>
      <title>pandas stack和unstack函数</title>
      <link>https://example.com/p/pandas-stack%E5%92%8Cunstack%E5%87%BD%E6%95%B0/</link>
      <pubDate>Wed, 10 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pandas-stack%E5%92%8Cunstack%E5%87%BD%E6%95%B0/</guid>
      <description> import numpy as np import pandas as pd df = pd.DataFrame(np.arange(6).reshape((2,3)),index=[&amp;#34;street1&amp;#34;,&amp;#34;street2&amp;#34;],columns=[&amp;#34;one&amp;#34;,&amp;#34;two&amp;#34;,&amp;#34;sthree&amp;#34;]) df result: code:
data2 = df.stack() data2 result: code:
data3 = data2.unstack() data3 result: </description>
    </item>
    
    <item>
      <title>Computational Thermostabilization of an Enzyme</title>
      <link>https://example.com/p/computational-thermostabilization-of-an-enzyme/</link>
      <pubDate>Tue, 09 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/computational-thermostabilization-of-an-enzyme/</guid>
      <description>Computational Thermostabilization of an Enzyme
link:https://www.science.org/doi/abs/10.1126/science.1107387</description>
    </item>
    
    <item>
      <title>sklearn.preprocessing.StandardScaler数据标准化</title>
      <link>https://example.com/p/sklearn.preprocessing.standardscaler%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96/</link>
      <pubDate>Mon, 08 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sklearn.preprocessing.standardscaler%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96/</guid>
      <description>sklearn.preprocessing.StandardScaler数据标准化 如果某个特征的方差远大于其它特征的方差，那么它将会在算法学习中占据主导位置，导致我们的学习器不能像我们期望的那样，去学习其他的特征，这将导致最后的模型收敛速度慢甚至不收敛，因此我们需要对这样的特征数据进行标准化/归一化
StandarScaler 标准化数据通过减去均值然后除以方差（或标准差），这种数据标准化方法经过处理后数据符合标准正态分布，即均值为0，标准差为1，转化函数为：x =(x - 𝜇)/𝜎
import numpy as np from sklearn.preprocessing import StandardScaler &amp;#34;&amp;#34;&amp;#34; scale_ : 缩放比列，同时也是标准差 mean_ : 每个特征的平均值 var_ : 每个特征的方差 n_samples_seen_ : 样本数量 &amp;#34;&amp;#34;&amp;#34; x = np.array(range(1,10)).reshape(-1,1) ss = StandardScaler() ss.fit(X=x) print(x) print(ss.n_samples_seen_) print(ss.mean_) print(ss.var_) print(ss.scale_) print(&amp;#34;标准化后的数据：&amp;#34;) y = ss.fit_transform(x) print(y) result: </description>
    </item>
    
    <item>
      <title>《结构生物学》</title>
      <link>https://example.com/p/%E7%BB%93%E6%9E%84%E7%94%9F%E7%89%A9%E5%AD%A6/</link>
      <pubDate>Sat, 09 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%BB%93%E6%9E%84%E7%94%9F%E7%89%A9%E5%AD%A6/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>De Novo Computational Design of Retro-Aldol Enzymes</title>
      <link>https://example.com/p/de-novo-computational-design-of-retro-aldol-enzymes/</link>
      <pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/de-novo-computational-design-of-retro-aldol-enzymes/</guid>
      <description>De Novo Computational Design of Retro-Aldol Enzymes
link:https://www.science.org/doi/abs/10.1126/science.1152692</description>
    </item>
    
    <item>
      <title>《蛋白质结构预测实验指南》</title>
      <link>https://example.com/p/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E9%A2%84%E6%B5%8B%E5%AE%9E%E9%AA%8C%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sun, 12 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E9%A2%84%E6%B5%8B%E5%AE%9E%E9%AA%8C%E6%8C%87%E5%8D%97/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>1_Getting_Started_Menu_Version-2</title>
      <link>https://example.com/p/1_getting_started_menu_version-2/</link>
      <pubDate>Sun, 12 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/1_getting_started_menu_version-2/</guid>
      <description>Part 2 - Molecular Representations and Surfaces Fectch 结构 这次使用的是1d86 （PDB code）,打开后发现是个DNA结构，长这样，Chimera默认对DNA对象展示的标准是：
ribbon 带状 个性化展示核糖核酸和碱基 养成好习惯，把Side View也打开下 如果Fetch时不成功，可以手动去RCSB上下载蛋白的结构文件，再使用Menu去open
Presets: 快速修改表现形式 打开presets的选择 顶部menu 这里选择第二种看看
Presets... Interactive 2 (all atoms) presets 可供选择的套装说明 参考[^学习来源2] presets 总的来说就是已经设定好的一系列配置，它可以一键快速调整你的结构的展现形式，颜色等
Interactive模式 这个模式是为了方便展示”交互作用的“（官方的描述是Interactive presets are meant for interactive manipulation and analysis. They may change which items (atoms, ribbons, surfaces) are displayed and how they are colored.）
Interactive 1 (ribbons) shows most peptide and nucleic acid chains as ribbons, plus atomic detail (excluding hydrogens on carbon atoms) for residues within 3.</description>
    </item>
    
    <item>
      <title>《神经网络与深度学习-邱老师》</title>
      <link>https://example.com/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E9%82%B1%E8%80%81%E5%B8%88/</link>
      <pubDate>Sat, 11 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E9%82%B1%E8%80%81%E5%B8%88/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>protein_class模型修复记录</title>
      <link>https://example.com/p/protein_class%E6%A8%A1%E5%9E%8B%E4%BF%AE%E5%A4%8D%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sat, 11 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/protein_class%E6%A8%A1%E5%9E%8B%E4%BF%AE%E5%A4%8D%E8%AE%B0%E5%BD%95/</guid>
      <description>不久前，别人发给了我github上一个蛋白质分类的深度学习模型，在运行作者的代码时，发现模型似乎有点问题（反正在我的laptop上运行了不了，应该不是电脑的问题，因为我仔细看了后发现作者使用的biLSTM有问题，经过千辛万苦，终于让我改好了hhh）,特此写一篇markdown来记录（其实我对LSTM一点都不熟悉&amp;hellip;属于是误打误撞修好的）
项目地址：https://github.com/jgbrasier/protein-classification 作者还提供了一个PDF（IDL_Projet.pdf）里面有详细说明模型的构造 PDF主要内容 数据的预处理 模型的结构 融合了两个模型的结构，分别是CNN卷积网络和BiLSTM。 超参数的设置 预测的准确率和混淆矩阵 我对代码的bug修改记录 数据读取部分 作者是在google lab上运行的，所以有数据上传部分的代码，但是我发现代码上传的好慢，于是自己手动上传了 作者原code: 我的修改： 直接注释就好了，将dataset下载到本地的目录，再读取
数据加载部分 后面训练时，发现数据的维度对不上，而且我觉得他这里的数据加载器有问题，所以，我自己加了个数据的处理器（主要是加在了Model前面）： CNN_BiLSTM融合模型的问题 发现这里训练是也有问题（当时没截图），作者原代码：
class CNN_BiLSTM(nn.Module): def __init__(self, vocab_size, embedding_size, hidden_size, n_filters, filter_sizes, num_layers, num_classes, batch_size): &amp;#34;&amp;#34;&amp;#34; vocab_size: int, number of words in vocbulary emedding_size: int, embedding dimension hidden_size: int, size of hidden layer num_layers: int, number of LSTM layers num_classes: number of classes batch_size: size of mini batches &amp;#34;&amp;#34;&amp;#34; super(CNN_BiLSTM, self).__init__() self.hidden_size = hidden_size self.</description>
    </item>
    
    <item>
      <title>《PyRosetta Textbook》</title>
      <link>https://example.com/p/pyrosetta-textbook/</link>
      <pubDate>Sun, 22 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pyrosetta-textbook/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>《蛋白质结构预测：支持向量机的应用》</title>
      <link>https://example.com/p/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E9%A2%84%E6%B5%8B%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E5%BA%94%E7%94%A8/</link>
      <pubDate>Fri, 20 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E9%A2%84%E6%B5%8B%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E5%BA%94%E7%94%A8/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>sns.boxplot()简单用法</title>
      <link>https://example.com/p/sns.boxplot%E7%AE%80%E5%8D%95%E7%94%A8%E6%B3%95/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sns.boxplot%E7%AE%80%E5%8D%95%E7%94%A8%E6%B3%95/</guid>
      <description>第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
箱形图（Box-plot）：
又称为盒须图、盒式图或箱线图，是一种用作显示一组数据分散情况资料的统计图。它能显示出一组数据的最大值、最小值、中位数及上下四分位数
参数如下：
seaborn.boxplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, width=0.8, dodge=True, fliersize=5, linewidth=None, whis=1.5, notch=False, ax=None, **kwargs)
x，y：dataframe中的列名（str）或者矢量数据
data：dataframe或者数组
hue（str）：dataframe的列名，按照列名中的值分类形成分类的条形图
palette：调色板，控制图像的色调
order, hue_order (lists of strings)：用于控制条形图的顺序
orient：“v”|“h” 用于控制图像使水平还是竖直显示（这通常是从输入变量的dtype推断出来的，此参数一般当不传入x、y，只传入data的时候使用）
fliersize：float，用于指示离群值观察的标记大小
whis： 确定离群值的上下界（IQR超过低和高四分位数的比例），此范围之外的点将被识别为异常值。IQR指的是上下四分位的差值。
width： float，控制箱型图的宽度
箱型图的作用：
1.直观明了地识别数据批中的异常值 其实箱线图判断异常值的标准以四分位数和四分位距为基础，四分位数具有一定的耐抗性，多达25%的数据可以变得任意远而不会很大地扰动四分位数，所以异常值不会影响箱形图的数据形状，箱线图识别异常值的结果比较客观。由此可见，箱型图在识别异常值方面有一定的优越性。
2.利用箱型图判断数据批的偏态和尾重 对于标准正态分布的样本，只有极少值为异常值。异常值越多说明尾部越重，自由度越小（即自由变动的量的个数）；而偏态表示偏离程度，异常值集中在较小值一侧，则分布呈左偏态；异常值集中在较大值一侧，则分布呈右偏态。 code:
#使用iris数据集作为例子 import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) from sklearn.datasets import load_iris plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; data = pd.</description>
    </item>
    
    <item>
      <title>sns.kdeplot()核密度估计图</title>
      <link>https://example.com/p/sns.kdeplot%E6%A0%B8%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1%E5%9B%BE/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sns.kdeplot%E6%A0%B8%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1%E5%9B%BE/</guid>
      <description> 第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
核密度估计是概率论上用来估计未知的密度函数，属于非参数检验，通过核密度估计图可以比较直观的看出样本数据本身的分布特征
参数如下： sns.kdeplot(data,data2=None,shade=False,vertical=False,kernel=&amp;lsquo;gau&amp;rsquo;,bw=&amp;lsquo;scott&amp;rsquo;,gridsize=100,cut=3,clip=None,legend=True,cumulative=False,shade_lowest=True,cbar=False, cbar_ax=None, cbar_kws=None, ax=None, *kwargs)
主要用来绘制特征变量y值的分布，看看数据符合哪种分布 用的地方不多，了解为主，不需要深入研究
code
import numpy as np import matplotlib.pyplot as plt import seaborn as sns import pandas as pd sns.set() x = np.random.randn(100) plt.plot(x)#这样是无法看出分布 sns.kdeplot(x) result code:
#cumulative ：是否绘制累积分布 sns.kdeplot(x,cumulative=True) result: code:
#shade：若为True，则在kde曲线下面的区域中进行阴影处理，color控制曲线及阴影的颜色 sns.kdeplot(x,shade=True,color=&amp;#34;g&amp;#34;) result: vertical：表示以X轴进行绘制还是以Y轴进行绘制
code:
#y轴画图 import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) sns.kdeplot(x,vertical=True) result: 二元kde图像，很少使用，稍微了解一下即可
code:
#x,y y = np.random.randn(100) sns.kdeplot(x,y) code:
#cbar:参数位True，则会添加一个颜色棒（颜色棒在二元kde图像中才有） sns.kdeplot(x,y,shade=True,cbar=True) </description>
    </item>
    
    <item>
      <title>sns.regplot()的用法</title>
      <link>https://example.com/p/sns.regplot%E7%9A%84%E7%94%A8%E6%B3%95/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sns.regplot%E7%9A%84%E7%94%A8%E6%B3%95/</guid>
      <description>第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
sns.regplot()：绘图数据和线性回归模型拟合
参数 seaborn.regplot(x, y, data=None, x_estimator=None, x_bins=None, x_ci=&amp;lsquo;ci&amp;rsquo;, scatter=True, fit_reg=True, ci=95, n_boot=1000, units=None, order=1, logistic=False, lowess=False, robust=False, logx=False, x_partial=None, y_partial=None, truncate=False, dropna=True, x_jitter=None, y_jitter=None, label=None, color=None, marker=&amp;lsquo;o&amp;rsquo;, scatter_kws=None, line_kws=None, ax=None)
参数说明
x,y：就是x,y轴的值
data：x,y所属的df
x_estimator：将此函数应用于x的每个唯一值并绘制结果估计值。当x是离散变量时，这很有用。如果给定x_ci，则此估计值将自举并绘制置信区间
x_bins：将x分成多少段
code:
#使用定义为numpy数组的两个变量绘制；使用不同的颜色 import numpy as np import seaborn as sns mean,cov = [4,6],[(1.5,.7),(.7,1)] x,y = np.random.multivariate_normal(mean,cov,88).T sns.regplot(x=x,y=y,color=&amp;#34;g&amp;#34;) result: code:
#使用pd.Series的两个变量绘制；使用不同的标记 import pandas as pd x,y = pd.Series(x,name=&amp;#34;x_var&amp;#34;),pd.Series(y,name=&amp;#34;y_var&amp;#34;) sns.regplot(x=x,y=y,marker=&amp;#34;+&amp;#34;) result: code:
#使用68%的置信区间，这与估计的标准误差相对应: sns.regplot(x,y,ci=68) result: code:</description>
    </item>
    
    <item>
      <title>stats.proplot(QQ图）</title>
      <link>https://example.com/p/stats.proplotqq%E5%9B%BE/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/stats.proplotqq%E5%9B%BE/</guid>
      <description>第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
这是一种检验样本数据概率分布(例如正态分布)的方法。 使用方法如下：
code:
import matplotlib.pyplot as plt from scipy import stats fig = plt.figure() res = stats.probplot(train[&amp;#34;SalePrice&amp;#34;], plot=plt) #默认检测是正态分布 plt.show() ![](picture/stats.proplot(QQ图）.png)
红色线条表示正态分布，蓝色线条表示样本数据，蓝色越接近红色参考线，说明越符合预期分布（这是是正态分布）
q-q 图是通过比较数据和正态分布的分位数是否相等来判断数据是不是符合正态分布</description>
    </item>
    
    <item>
      <title>pseaborn.heatmap绘制热图</title>
      <link>https://example.com/p/pseaborn.heatmap%E7%BB%98%E5%88%B6%E7%83%AD%E5%9B%BE/</link>
      <pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pseaborn.heatmap%E7%BB%98%E5%88%B6%E7%83%AD%E5%9B%BE/</guid>
      <description>第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
code：
import numpy as np import seaborn as sns import matplotlib.pyplot as plt #随机创建10行12列的数组，定义一个子图宽高为9和6，应用到热力图中 np.random.seed(22) sns.set() uniform_data = np.random.randn(10,12) f,ax = plt.subplots(figsize=(16,10)) ax = sns.heatmap(uniform_data) plt.show() result: code:
#现在在上图的基础上改变一下色彩图的上下界 ax = sns.heatmap(uniform_data,vmin=0,vmax=1) #和上图对比就会发现色彩图的上下界更明确了 result: 使用发散色图绘制以0为中心的数据的热力图 这里使用的是np.random.randn()函数，和上面的np.random.rand()函数不一样的。因为这个函数可以返回一个或一组服从标准正态分布的随机样本值，上面的np.random.rand()函数返回一个或一组服从0~1均匀分布的随机样本值，随机样本取值范围是[0,1)，不包括1
code:
uniform_data = np.random.randn(10,12) f,ax = plt.subplots(figsize=(9,6)) ax = sns.heatmap(uniform_data,center=0) plt.show() result: 为行和列加上有意义的标签,使用sns.load_dataset(&amp;ldquo;flights&amp;rdquo;)自带的数据集，数据集的部分截图如下,共143行数据: code:
flights = sns.load_dataset(&amp;#34;flights&amp;#34;) 接着使用了一个特别高效的函数pivot()，该函数有三个参数(index,columns,values)，第一个参数index是指新表的索引，第二个参数columns是新表的列名，第三个参数values是指新表中的值，看效果就比较明确了
flights = flights.pivot(&amp;#34;month&amp;#34;,&amp;#34;year&amp;#34;,&amp;#34;passengers&amp;#34;) flights 由表可以看出第一个参数就是行标，第二个参数是列标，第三个参数是表中的值。 显示一下热力图 code:
ax = sns.heatmap(flights) plt.show() result: 使用整型格式的数值为每个单元格注释
heatmap中的参数annot为True时，为每个单元格写入数据值。如果数组具有与数据相同的形状，则使用它来注释热力图而不是原始数据。参数fmt是指添加注释时要使用的字符串格式代码 code:</description>
    </item>
    
    <item>
      <title>seaborn.diverging_palette发散调色板</title>
      <link>https://example.com/p/seaborn.diverging_palette%E5%8F%91%E6%95%A3%E8%B0%83%E8%89%B2%E6%9D%BF/</link>
      <pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/seaborn.diverging_palette%E5%8F%91%E6%95%A3%E8%B0%83%E8%89%B2%E6%9D%BF/</guid>
      <description>第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
seaborn.diverging_palette(h_neg, h_pos, s=75, l=50, sep=10, n=6, center=&amp;lsquo;light&amp;rsquo;, as_cmap=False)
在两个 HUSL 颜色直接建立一个发散调色板。
如果您在使用 IPython notebook，您还可以通过 choose_diverging_palette() 函数交互式选择调色板。
参数：h_neg, h_pos：float in [0, 359]
图的正负范围的锚定色调
s：[0, 100] 范围内的浮点数，可选
图的两个范围的锚定饱和度
l：[0, 100] 范围内的浮点数，可选
图的两个范围的锚定亮度
n：int，可选
调色板中的颜色数（如果为not，返回一个colormap）
center：{“light”, “dark”}, 可选
调色板中心为亮或暗
as_cmap：bool, 可选
如果为 true，返回一个 matplotlib colormap 而不是一个颜色列表。
返回值：palette or cmap：seaborn color palette or matplotlib colormap
类似列表的颜色对象的 RGB 元组，或者可以将连续值映射到颜色的 colormap 对象，具体取决于 as_cmap 参数的值。
另外
创建具有暗值的连续调色板。创建具有亮值的连续调色板
code
#生成一个蓝白红调色板 import seaborn as sns sns.palplot(sns.diverging_palette(240,10,n=9)) result: code:</description>
    </item>
    
    <item>
      <title>sns.distplot()用法</title>
      <link>https://example.com/p/sns.distplot%E7%94%A8%E6%B3%95/</link>
      <pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sns.distplot%E7%94%A8%E6%B3%95/</guid>
      <description>第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
sns.distplot()集合了matplotlib的hist()于sns.kdeplot()功能，增了rugplot分布观测显示与理由scipy库fit拟合参数分布的新颖用途
参数如下 sns.distplot(a, bins=None, hist=True, kde=True, rug=False, fit=None, hist_kws=None, kde_kws=None, rug_kws=None, fit_kws=None, color=None, vertical=False, norm_hist=False, axlabel=None, label=None, ax=None)
直方图：先分箱，然后计算每个分箱频数的数据分布，
和条形图的区别，条形图有空隙，直方图没有，条形图一般用于类别特征，直方图一般用于数字特征（连续型） 多用于y值和数字（连续型）特征的分布画图
code:
import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns sns.set() #切换到sns的默认运行配置 x = np.random.randn(100) sns.distplot(x) result: code:
sns.displot(x) 通过hist和kde参数调节是否显示直方图及核密度估计(默认hist,kde均为True)
import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) fig,axes = plt.subplots(1,3)#创建一个1行三列的图片 sns.displot(x,ax=axes[0]) sns.distplot(x,hist=False,ax=axes[1])#不显示直方图 sns.distplot(x,kde=False,ax=axes[2])#不显示核密度 bins：int或list，控制直方图的划分
#bins fig,axes = plt.subplots(1,2) sns.distplot(x,kde=False,bins=20,ax=axes[0])#分成20个区间 ##以0,1,2,3为分割点，形成区间[0,1],[1,2],[2,3]，区间外的值不计入 sns.distplot(x,kde=False,bins=[x for x in range(4)],ax=axes[1]) code:</description>
    </item>
    
    <item>
      <title>matplotlib.pyplot_contourf 绘制等高线</title>
      <link>https://example.com/p/matplotlib.pyplot_contourf-%E7%BB%98%E5%88%B6%E7%AD%89%E9%AB%98%E7%BA%BF/</link>
      <pubDate>Tue, 10 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/matplotlib.pyplot_contourf-%E7%BB%98%E5%88%B6%E7%AD%89%E9%AB%98%E7%BA%BF/</guid>
      <description>第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
import matplotlib.pyplot as plt matplotlib.pyplot.contourf([X,Y],Z) 是来绘制等高线的，contour和contourf都是画三维等高线图的，不同点在于contour() 是绘制轮廓线，contourf()会填充轮廓。
在传入X,Y时会先进np.meshgrid生成坐标 X,Y对应的网格数据以及此网格对应的高度值，因此我们调用np.meshgrid(x,y)把x,y值转换成网格数据 重要参数说明：
X,Y为数组，是在Z中的坐标值 当 X,Y,Z 都是 2 维数组时，它们的形状必须相同。如果都是 1 维数组时，len(X)是 Z 的列数， 而 len(Y) 是 Z 中的行数。（例如，经由创建numpy.meshgrid()）
Z：类似矩阵
确定轮廓线/区域的数量和位置 其实就是X,Y的函数高度值
c 这里在机器学习中一般会传入y，即输出的类别，因为Colormap用于将数据值（浮点数）从间隔转 换为相应Colormap表示的RGBA颜色。用于将数据缩放到间隔中看 。
无论contour还是contourf，都是绘制三维图，其中前两个参数x和y为两个等长一维数组，第三个参数z为二维数组（表示平面点xi,yi映射的函数值）。
正是由于contourf可以填充等高线之间的空隙颜色，呈现出区域的分划状，所以很多分类机器学习模型的可视化常会借助其展现。
code:
import numpy as np import pandas as pd import matplotlib.pyplot as plt def height(x,y): return(1-x/2+x**5+y**3)*np.exp(-x**2-y**2) x = np.linspace(0, 3, 256) y = np.linspace(0, 3, 256) X,Y = np.meshgrid(x,y)#把X，Y传入网格中 X.shape=256,256 Y.shape=256,256 print(X.shape) result:
(256, 256) code:</description>
    </item>
    
    <item>
      <title>plt_plot&#43;plt_subplot&#43;plt_subplots区别</title>
      <link>https://example.com/p/plt_plot-plt_subplot-plt_subplots%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Tue, 10 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/plt_plot-plt_subplot-plt_subplots%E5%8C%BA%E5%88%AB/</guid>
      <description> 第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
import matplotlib.pyplot as plt plt.plot() fig.add_subplot plt.subplot plt.subplots </description>
    </item>
    
    <item>
      <title>plt.gca()坐标轴移动</title>
      <link>https://example.com/p/plt.gca%E5%9D%90%E6%A0%87%E8%BD%B4%E7%A7%BB%E5%8A%A8/</link>
      <pubDate>Tue, 10 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/plt.gca%E5%9D%90%E6%A0%87%E8%BD%B4%E7%A7%BB%E5%8A%A8/</guid>
      <description> 第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
import numpy as np import matplotlib.pyplot as plt import torch import torch.nn.functional as F x = torch.linspace(-10,10,60) y = torch.sigmoid(x) ax = plt.gca() #将最上方的边框颜色置为none ax.spines[&amp;#34;top&amp;#34;].set_color(&amp;#34;none&amp;#34;) #右边的边框颜色置为none ax.spines[&amp;#34;right&amp;#34;].set_color(&amp;#34;none&amp;#34;) #要移动底部x轴，所以要先锁定x轴 ax.xaxis.set_ticks_position(&amp;#34;bottom&amp;#34;) #data表示按数值挪动，其后数字代表挪动到Y轴的刻度值 ax.spines[&amp;#34;bottom&amp;#34;].set_position((&amp;#34;data&amp;#34;,0)) # #同上 ax.yaxis.set_ticks_position(&amp;#34;left&amp;#34;) #同上 ax.spines[&amp;#34;left&amp;#34;].set_position((&amp;#34;data&amp;#34;,0)) plt.plot(x.numpy(),y.numpy()) plt.show() </description>
    </item>
    
    <item>
      <title>Axes.set_xscale()函数用于设置x轴比例</title>
      <link>https://example.com/p/axes.set_xscale%E5%87%BD%E6%95%B0%E7%94%A8%E4%BA%8E%E8%AE%BE%E7%BD%AEx%E8%BD%B4%E6%AF%94%E4%BE%8B/</link>
      <pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/axes.set_xscale%E5%87%BD%E6%95%B0%E7%94%A8%E4%BA%8E%E8%AE%BE%E7%BD%AEx%E8%BD%B4%E6%AF%94%E4%BE%8B/</guid>
      <description>第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
matplotlib库的axiss模块中的Axes.set_xscale()函数用于设置x轴比例
用法： Axes.set_xscale(self, value, **kwargs)
参数：此方法接受以下参数。
value:此参数是要应用的轴比例类型。
**kwargs:有不同的关键字参数可以接受，并且取决于规模
以下示例说明了matplotlib.axes中的matplotlib.axes.Axes.set_xscale()函数：
实例1 #实例1 import matplotlib.pyplot as plt import numpy as np from matplotlib.ticker import EngFormatter#使用工程工程符号标记刻度线 val = np.random.RandomState(19680801) xs = np.logspace(1,9,100) ys = (0.8 + 4 * val.uniform(size=100)) * np.log10(xs)**2 fig,ax0 = plt.subplots() ax0.set_xscale(&amp;#34;log&amp;#34;) formatter0 = EngFormatter(unit=&amp;#34;Hz&amp;#34;) ax0.xaxis.set_major_formatter(formatter0) ax0.plot(xs,ys) ax0.set_xlabel(&amp;#34;Frequency&amp;#34;) fig.suptitle(&amp;#34;%matplotlib.axes.Axes.set_xscale() \ function Example\n&amp;#34;,fontweight=&amp;#34;bold&amp;#34;) plt.show() 实例2 #实例2 import numpy as np import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) fig,ax4 = plt.</description>
    </item>
    
    <item>
      <title>Matplotlib.colors.ListedColormap</title>
      <link>https://example.com/p/matplotlib.colors.listedcolormap/</link>
      <pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/matplotlib.colors.listedcolormap/</guid>
      <description>第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
matplotlib.colors.ListedColormap类属于matplotlib.colors模块。 matplotlib.colors模块用于将颜色或数字参数转换为RGBA或RGB。此模块用于将数字映射到颜色或以一维颜色数组(也称为colormap)进行颜色规格转换。
matplotlib.colors.ListedColormap类用于从颜色列表创建colarmap对象。这对于直接索引到颜色表中很有用，也可以用于为法线贴图创建特殊的颜色表
用法： class matplotlib.colors.ListedColormap(colors, name=’from_list’, N=None)
参数：
颜色：它是Matplotlib颜色规格的数组或列表，或等于N x 3或N x 4浮点数组(N rgb或rgba值) 名称：它是一个可选参数，它接受一个字符串来标识颜色图。 N:它是一个可选参数，它接受表示映射中条目数的整数值。它的默认值为“无”，其中颜色列表中的每个元素都有一个颜色表条目。如果N小于len(colors)，则列表将在N处截断，而如果N大于len，则列表将重复进行扩展。
该类的方法： 1)reversed()：这用于创建Colormap的反向实例。
用法： reversed(self, name=None)
参数：
name:它是一个可选参数，表示反转的颜色图的名称。如果将其设置为“无”，则名称将为父色图的名称+ “_r”。
返回值：它返回颜色图的反向实例
实例1 import matplotlib.pyplot as plt import numpy as np import matplotlib.colors a = np.linspace(-3,3) A,B = np.meshgrid(a,a) X = np.exp(-(A**2 + B**2)) figure, (axes1,axes2) = plt.subplots(ncols=2) colors = [&amp;#34;green&amp;#34;,&amp;#34;orange&amp;#34;,&amp;#34;gold&amp;#34;,&amp;#34;blue&amp;#34;,&amp;#34;k&amp;#34;,&amp;#34;#550011&amp;#34;,&amp;#34;purple&amp;#34;,&amp;#34;red&amp;#34;] axes1.set_title(&amp;#34;color list&amp;#34;) contour = axes1.contourf(A,B,X,colors=colors) axes2.set_title(&amp;#34;white colormap&amp;#34;) cmap = matplotlib.colors.ListedColormap(colors) contour = axes2.contourf(A,B,X,cmap=cmap) figure.</description>
    </item>
    
    <item>
      <title>PDB文件中氨基酸原子编码的规则</title>
      <link>https://example.com/p/pdb%E6%96%87%E4%BB%B6%E4%B8%AD%E6%B0%A8%E5%9F%BA%E9%85%B8%E5%8E%9F%E5%AD%90%E7%BC%96%E7%A0%81%E7%9A%84%E8%A7%84%E5%88%99/</link>
      <pubDate>Sat, 07 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pdb%E6%96%87%E4%BB%B6%E4%B8%AD%E6%B0%A8%E5%9F%BA%E9%85%B8%E5%8E%9F%E5%AD%90%E7%BC%96%E7%A0%81%E7%9A%84%E8%A7%84%E5%88%99/</guid>
      <description>我发现一直好像对PDB文件中氨基酸的原子编码规则不是很清楚，然后我去看了网上的帖子，发现都好像有点不太对，故整理此post来弄懂
氨基酸的结构通式 注意哪个是α原子 PDB文件中原子编码具体的命令规则 规则 基于PyMOL 和 PDB文件
氨基(NH)和羧基上(CO)的所有原子都采用本名，C, N, O, H，如果一个氨基酸的侧链基团也出现了氨基和羧基，侧链基团R上的氨基和羧基上的原子信息不是采用的本名，否则无法与主链的肽基区分开 侧链基团上的氨基和羧基的原子也采用下面提到的规则 首先α-C被命名为CA，注意生物学上哪个C才能被定义为CA原子，另外，PDB文件中会显示，但是PyMOL中有时候不会显示出CA的标签，其后的C按照成键关系逐级递推，名字后缀依次为 B-G-D-E-Z-H（此为希腊字母表顺序：α(A)，β(B)，γ(G)，δ(D)，ε(E)，ζ(Z)，η(H)……） 注意这个”成键逐级递推“的意思，例如，当一个CD，下面的直接相连的节点若是非H原子，且含有多个其他原子（比如含有两个C），则这多个原子都是隶属于CE的，为了区分要加上不同的数字编号(从1开始)（CE1,CE2） 对于氢原子，命名采用“H+所连上级原子后缀(如有数字也要带上)+数字编号”形式 对于处于与”中间CX(X代表任意字母or数字)原子“相连氢原子，且成键上一级的原子不是成环的，数字编号是从”2“开始的 若成键的上一个原子处于中间C，且这个C一端是H原子，另一端是其他原子，则这个H原子不用写数字，另一端的那个非H原子形成下一个节点的H原子数字编号从1开始 若成键的上一级注意处于环结构中时，因为成键的上一级所属的逐级的字母是同一个字母（环的原子，加上逐级递增的原则），为了区分，H的数字编号是从”1“开始的 CA相连的一个H原子就不用加上最后的数字编号 若成键的上一个原子是最后一个原子，对于处于上末尾的H原子（存在多个H原子时）的数字编号是从1开始的 处于最后末端的H原子（只存在一个H原子时），不管上一级成键的原子是否在环结构中，不用加数字编号，因为就它一个 本质就是标号法，注意H上的那些数字都是为了区分，不同的H才加上去的描述 例子 不含环的氨基酸 按照上面这张图的的绿色线条的箭头方向前进 进行说明
第一处的C、O是位于羧基上（非侧链）的，所以直接写出C、O原子即可 第二处的N、H是位于氨基上（非侧链）的，所以直接写出所有原子N、H即可 HA 右侧其实是CA，前面规则了CA在PyMOL的标签中是不会显示出来的，则这个HA的H原子是与CA相连，所以直接写HA即可 第三处的C，根据逐级递推，这个C写作CB，与它相连的两个H，又因为CB是处于中间的C原子，所以两个H原子写作HB2、HB3 第四处CG同理 第五处CD同理，只是下面成键相连的不是H原子了 第六处的氧原子0E1和第七处的氮原子NE2，因为它成键的上一级是CD，且是本身是氧原子，不是H原子，故按照逐级递推的原则，分别写作OE、NE，但是又因为他们两个成键的都是CD，所以加上个序号，分别为OE1,NE2 第八处和第九处的H原子，成键相连的上一级为NE2，且是H原子，不用逐级递推，又位于侧链的末端所以，写作HE21,HE22 (E2是上一级的编号) 含环的氨基酸 注意逐级递增，特别是那个苯环中的CE1和CE2、（字母的编号是按逐级的顺序来的），HE1和HE2以及最后的HH
最后附上20种氨基酸的相关信息 （下面的信息部分来自于学习来源3作者提供的excel表格）
丙氨酸 英文 Alanine 简写 ALA - A SMILES C[C@H](N)C(O)=O 结构 异亮氨酸 英文 Isoleucine 简写 ILE - I SMILES CC[C@H](C)[C@H](N)C(O)=O 结构式 亮氨酸 英文 Leucine 简写 LEU-L SMILES CC(C)C[C@H](N)C(O)=O 结构式 缬氨酸 英文 Valine 简写 VAL - V SMILES CC(C)[C@H](N)C(O)=O 结构式 甲硫氨酸 英文 Methionine 简写 MET - M SMILES O=C(O)[C@@H](N)CCSC 结构式 苯丙氨酸 英文 Phenylalanine 简写 PHE - F SMILES O=C(O)[C@@H](N)CC1=CC=CC=C1 结构式 色氨酸 英文 Tryptophan 简写 TRP - W SMILES O=C(O)[C@@H](N)CC1=CNC2=CC=CC=C12 结构式 酪氨酸 英文 Tyrosine 简写 TYR - Y SMILES O=C(O)[C@H](CC1=CC=C(O)C=C1)N 结构式 天冬酰胺 英文 Asparagine 简写 ASN - N SMILES O=C(O)[C@H](CC(N)=O)N 结构式 半胱氨酸 英文 Cysteine 简写 CYS - C SMILES O=C(O)[C@H](CS)N 结构式 谷氨酰胺 英文 Glutamine 简写 GLN - Q SMILES O=C(O)[C@H](CCC(N)=O)N 结构式 丝氨酸 英文 Serine 简写 SER - S SMILES O=C(O)[C@H](CO)N 结构式 苏氨酸 英文 Threonine 简写 THR - T SMILES O=C(O)[C@H]([C@H](O)C)N 结构式 精氨酸 英文 Arginine 简写 ARG - R SMILES O=C(O)[C@H](CCCNC(N)=N)N 结构式 组氨酸 英文 Histidine 简写 HIS - H SMILES O=C(O)[C@H](CC1=CNC=N1)N 结构式 赖氨酸 英文 Lysine 简写 LYS - K SMILES O=C([C@@H](N)CCCCN)O 结构式 天冬氨酸 英文 Aspartic acid 简写 ASP - D SMILES O=C(O)[C@H](CC(O)=O)N 结构式 谷氨酸 英文 Glutamic acid 简写 GLU - E SMILES O=C(O)[C@H](CCC(O)=O)N 结构式 甘氨酸 英文 Glycine 简写 GLY - G SMILES O=C(O)CN 结构式 脯氨酸 英文 Proline 简写 PRO - P SMILES O=C([C@@H]1CCCN1)O 结构式 注意下，因为每个氨基酸的3D结构都是在整个蛋白中抽出来展示的，此时氨基酸是残基了，所以不想2d结构式那样是一个真正完整的氨基酸（比如COOH已经形成了肽键）</description>
    </item>
    
    <item>
      <title>对matplotlib.cm.RdYlBu()的理解</title>
      <link>https://example.com/p/%E5%AF%B9matplotlib.cm.rdylbu%E7%9A%84%E7%90%86%E8%A7%A3/</link>
      <pubDate>Sat, 07 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%AF%B9matplotlib.cm.rdylbu%E7%9A%84%E7%90%86%E8%A7%A3/</guid>
      <description>、
第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
matplotlib.cm matplotlib.cm是matplotlib库中内置的色彩映射函数
matplotlib.cm.色彩即对[数据集]应用[色彩] https://matplotlib.org/stable/api/cm_api.html
内置色彩映射的列表 </description>
    </item>
    
    <item>
      <title>annotate(),text()--注释文本</title>
      <link>https://example.com/p/annotatetext--%E6%B3%A8%E9%87%8A%E6%96%87%E6%9C%AC/</link>
      <pubDate>Fri, 06 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/annotatetext--%E6%B3%A8%E9%87%8A%E6%96%87%E6%9C%AC/</guid>
      <description>第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
作用：在图中带有指向型文本注释信息，突显细节
matplotlib.pyplot.annotate() 参数说明：
s : string 内容 xy : (float,float) 箭头点所在的坐标位置 xytext : s内容所在的坐标位置 weight : str/int 设置字体线型，其中字符串从小到大可选项有{&amp;lsquo;ultralight&amp;rsquo;, &amp;rsquo;light&amp;rsquo;, &amp;rsquo;normal&amp;rsquo;, &amp;lsquo;regular&amp;rsquo;, &amp;lsquo;book&amp;rsquo;, &amp;lsquo;medium&amp;rsquo;, &amp;lsquo;roman&amp;rsquo;, &amp;lsquo;semibold&amp;rsquo;, &amp;lsquo;demibold&amp;rsquo;, &amp;lsquo;demi&amp;rsquo;, &amp;lsquo;bold&amp;rsquo;, &amp;lsquo;heavy&amp;rsquo;, &amp;rsquo;extra bold&amp;rsquo;, &amp;lsquo;black&amp;rsquo;} color ： str/tuple 设置字体颜色，单个字符候选项{&amp;lsquo;b&amp;rsquo;, &amp;lsquo;g&amp;rsquo;, &amp;lsquo;r&amp;rsquo;, &amp;lsquo;c&amp;rsquo;, &amp;rsquo;m&amp;rsquo;, &amp;lsquo;y&amp;rsquo;, &amp;lsquo;k&amp;rsquo;, &amp;lsquo;w&amp;rsquo;}，也可以&amp;rsquo;black&amp;rsquo;,&amp;lsquo;red&amp;rsquo;等，tuple时用[0,1]之间的浮点型数据，RGB或者RGBA, 如: (0.1, 0.2, 0.5)、(0.1, 0.2, 0.5, 0.3)等 arrowprops : dict 设置指向箭头的参数，字典中key值有①arrowstyle：设置箭头的样式，其value候选项如&amp;rsquo;-&amp;gt;&amp;rsquo;,&amp;rsquo;|-|&amp;rsquo;,&amp;rsquo;-|&amp;gt;&amp;rsquo;,也可以用字符串&amp;rsquo;simple&amp;rsquo;,&amp;lsquo;fancy&amp;rsquo; ; ②connectionstyle：设置箭头的形状，为直线或者曲线，候选项有&amp;rsquo;arc3&amp;rsquo;,&amp;lsquo;arc&amp;rsquo;,&amp;lsquo;angle&amp;rsquo;,&amp;lsquo;angle3&amp;rsquo;，可以防止箭头被曲线内容遮挡; ③color：设置箭头颜色，见前面的color参数 bbox: dict code:
import matplotlib.pyplot as plt import numpy as np import warnings warnings.</description>
    </item>
    
    <item>
      <title>画图风格定义为ggplot</title>
      <link>https://example.com/p/%E7%94%BB%E5%9B%BE%E9%A3%8E%E6%A0%BC%E5%AE%9A%E4%B9%89%E4%B8%BAggplot/</link>
      <pubDate>Fri, 06 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%BB%E5%9B%BE%E9%A3%8E%E6%A0%BC%E5%AE%9A%E4%B9%89%E4%B8%BAggplot/</guid>
      <description> 第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
import matplotlib.pyplot as plt import matplotlib #用style定义 matplotlib.style.use(&amp;#34;ggplot&amp;#34;) </description>
    </item>
    
    <item>
      <title>配置图形参数</title>
      <link>https://example.com/p/%E9%85%8D%E7%BD%AE%E5%9B%BE%E5%BD%A2%E5%8F%82%E6%95%B0/</link>
      <pubDate>Fri, 06 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E9%85%8D%E7%BD%AE%E5%9B%BE%E5%BD%A2%E5%8F%82%E6%95%B0/</guid>
      <description> 第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
配置图形参数 使用面向对象的绘图接口时会创建figure和axes对象。figure实例可以看成是一个能够容纳各种坐标轴、图形、文字和标签的容器，axes是一个带有刻度和标签的矩形，最终会包含所有可视化的图形元素
import matplotlib.pyplot as plt import matplotlib as mpl import numpy as np import pandas as pd plt.style.use(&amp;#34;seaborn-whitegrid&amp;#34;) fig = plt.figure() ax = plt.axes() 调整图形：线条的颜色和风格 自定义线条的颜色可以设置plot()方法中的color属性。可以使用标准颜色名称，如‘blue’、’red‘等，也可以使用缩写颜色代码（rgbcmyk） 自定义线条的风格可以设置plot()方法中的linestyle属性。可以使用标准风格名称，如‘solid’、‘dashed’、‘dashdot’和‘dotted’，也可以使用简写形式，如‘-’、‘–’、‘-.’或者‘:‘
x = np.linspace(0,10,100) plt.plot(x,np.sin(x-0),color=&amp;#34;blue&amp;#34;, linestyle=&amp;#34;solid&amp;#34;) plt.plot(x,np.cos(x-1),color=&amp;#34;g&amp;#34;,linestyle=&amp;#34;dashdot&amp;#34;) #更加简洁的方式，将linestyle和color编码结合起来，作为plt.plot()函数的一个非关键参数使用 plt.plot(x,x-3,&amp;#34;--r&amp;#34;) plt.show() 调整图形：坐标上下限——axis()方法 荐使用plt.axis()方法。通过传入[xmin, xmax, ymin, ymax]对应的值，plt.axis()方法可以让你用一行代码设置x和y的限值
#设置x轴和y轴的限值 plt.plot(x,np.sin(x)) plt.axis([-1,11,-1.5,1.5]) #按照图形的内容自动收紧坐标轴，不留空白区域 plt.axis(&amp;#34;tight&amp;#34;) #让x轴和y轴单位长度相等，即分辨率相等 plt.axis(&amp;#34;equal&amp;#34;) 设置图形的标签 #简单设置方法 plt.title(&amp;#34;A Sine Curve&amp;#34;) plt.xlabel(&amp;#34;X&amp;#34;) plt.ylabel(&amp;#34;sin(x)&amp;#34;) #当单个坐标轴上显示多条线时，创建图例显示每条线是很有效的方法。Matplotlib内置了一个简单快速的方法——plt.legend() #在plt.plot()方法中显示设置label参数，配合plt.legend()函数可以方便的制作图例 plt.plot(x,np.sin(x),&amp;#34;-g&amp;#34;,label=&amp;#34;sin(x)&amp;#34;) plt.plot(x,np.cos(x),&amp;#34;:b&amp;#34;,label=&amp;#34;cos(x)&amp;#34;) plt.axis(&amp;#34;equal&amp;#34;) plt.legend() plt.title(&amp;#34;triangle function curve&amp;#34;) plt.show() </description>
    </item>
    
    <item>
      <title>Practically Useful: What the Rosetta Protein Modeling Suite Can Do for You</title>
      <link>https://example.com/p/practically-useful-what-the-rosetta-protein-modeling-suite-can-do-for-you/</link>
      <pubDate>Wed, 04 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/practically-useful-what-the-rosetta-protein-modeling-suite-can-do-for-you/</guid>
      <description>Practically Useful: What the Rosetta Protein Modeling Suite Can Do for You</description>
    </item>
    
    <item>
      <title>PyRosetta: a script-based interface for implementing molecular modeling algorithms using Rosetta</title>
      <link>https://example.com/p/pyrosetta-a-script-based-interface-for-implementing-molecular-modeling-algorithms-using-rosetta/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pyrosetta-a-script-based-interface-for-implementing-molecular-modeling-algorithms-using-rosetta/</guid>
      <description>PyRosetta: a script-based interface for implementing molecular modeling algorithms using Rosetta
link:https://academic.oup.com/bioinformatics/article/26/5/689/212442?login=false</description>
    </item>
    
    <item>
      <title>Free-Energy Landscape of Enzyme Catalysis</title>
      <link>https://example.com/p/free-energy-landscape-of-enzyme-catalysis/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/free-energy-landscape-of-enzyme-catalysis/</guid>
      <description>Free-Energy Landscape of Enzyme Catalysis</description>
    </item>
    
    <item>
      <title>Lecture_13_RNN_Classifier</title>
      <link>https://example.com/p/lecture_13_rnn_classifier/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/lecture_13_rnn_classifier/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_01_Overview</title>
      <link>https://example.com/p/ppt_lecture_01_overview/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_01_overview/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_02_Linear_Model</title>
      <link>https://example.com/p/ppt_lecture_02_linear_model/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_02_linear_model/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_03_Gradient_Descent</title>
      <link>https://example.com/p/ppt_lecture_03_gradient_descent/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_03_gradient_descent/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_04_Back_Propagation</title>
      <link>https://example.com/p/ppt_lecture_04_back_propagation/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_04_back_propagation/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_05_Linear_Regression_with_PyTorch</title>
      <link>https://example.com/p/ppt_lecture_05_linear_regression_with_pytorch/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_05_linear_regression_with_pytorch/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_06_Logistic_Regression</title>
      <link>https://example.com/p/ppt_lecture_06_logistic_regression/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_06_logistic_regression/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_07_Multiple_Dimension_Input</title>
      <link>https://example.com/p/ppt_lecture_07_multiple_dimension_input/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_07_multiple_dimension_input/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_08_Dataset_and_Dataloader</title>
      <link>https://example.com/p/ppt_lecture_08_dataset_and_dataloader/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_08_dataset_and_dataloader/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_09_Softmax_Classifier</title>
      <link>https://example.com/p/ppt_lecture_09_softmax_classifier/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_09_softmax_classifier/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_10_Basic_CNN</title>
      <link>https://example.com/p/ppt_lecture_10_basic_cnn/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_10_basic_cnn/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_11_Advanced_CNN</title>
      <link>https://example.com/p/ppt_lecture_11_advanced_cnn/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_11_advanced_cnn/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>ppt_Lecture_12_Basic_RNN</title>
      <link>https://example.com/p/ppt_lecture_12_basic_rnn/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ppt_lecture_12_basic_rnn/</guid>
      <description>这是跟学刘二老师的的课程ppt，特地放这里用来随时随地看</description>
    </item>
    
    <item>
      <title>Sklearn.metrics机器学习各种评价指标</title>
      <link>https://example.com/p/sklearn.metrics%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%90%84%E7%A7%8D%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</link>
      <pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sklearn.metrics%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%90%84%E7%A7%8D%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</guid>
      <description>这是Python sklearn机器学习各种评价指标——sklearn.metrics简介及应用示例 （文中图片来源于知乎，但是因为是很久之前的图片，今天整理起来找不到原作者的知乎账号了）
补充，找到了，但是记错了，不是知乎。。
https://scikit-learn.org/stable/modules/classes.html https://www.cnblogs.com/mindy-snail/p/12445973.html # 有两种方式导入： #方式一： from sklearn.metrics import mean_squared_error from sklearn.metrics import r2_score # 此时的调用方式直接调用即可 mean_squared_error(y_test,y_pred) #方式二： from sklearn import metrics #此时的调用方式 metrics.mean_squared_error(y_test,y_pred) 来看scikit-learn.metrics里各种指标简介
回归指标 1.explained_variance_score(y_true, y_pred, sample_weight=None, multioutput=‘uniform_average’)：回归方差(反应自变量与因变量之间的相关程度) 2.mean_absolute_error(y_true,y_pred,sample_weight=None,multioutput=‘uniform_average’)：平均绝对误差 3.mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=‘uniform_average’)：均方差 4.median_absolute_error(y_true, y_pred) 中值绝对误差 5.r2_score(y_true, y_pred,sample_weight=None,multioutput=‘uniform_average’) ：R平方值 分类指标 1.accuracy_score(y_true,y_pred):精度 2.auc(x,y,reorder=False):ROC曲线下的面积;较大的AUC代表了较好的performance 3.average_precision_score(y_true, y_score, average=‘macro’, sample_weight=None):根据预测得分计算平均精度(AP) 4.brief_score_loss(y_true, y_prob, sample_weight=None, pos_label=None):The smaller the Brier score, the better. 5.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None):通过计算混淆矩阵来评估分类的准确性 返回混淆矩阵 6.f1_score(y_true, y_pred, labels=None, pos_label=1, average=‘binary’, sample_weight=None):F1值 7.</description>
    </item>
    
    <item>
      <title>startwiths&amp;endswith()判断开头&amp;结尾 </title>
      <link>https://example.com/p/startwithsendswith%E5%88%A4%E6%96%AD%E5%BC%80%E5%A4%B4%E7%BB%93%E5%B0%BE/</link>
      <pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/startwithsendswith%E5%88%A4%E6%96%AD%E5%BC%80%E5%A4%B4%E7%BB%93%E5%B0%BE/</guid>
      <description> str.startswith(substr,start,end) 判断substr是否在str中开头 ,当然了可以指定从str哪里开始检索 str.endswith(substr,start,end) 判断substr是否在str中结尾,当然了可以指定从str哪里开始检索 code:
str_long = &amp;#34;This is a test now&amp;#34; str_long.startswith(&amp;#34;This&amp;#34;) result:
True code:
str_long.startswith(&amp;#34;This&amp;#34;,5,9) result:
Flase code:
str_long.endswith(&amp;#34;now&amp;#34;) result:
True code:
str_long.endswith(&amp;#34;test&amp;#34;,0,14) result:
True </description>
    </item>
    
    <item>
      <title>Rational design of a highly efficient catalytic system for the production of PAPS from ATP and its application in the synthesis of chondroitin sulfate</title>
      <link>https://example.com/p/rational-design-of-a-highly-efficient-catalytic-system-for-the-production-of-paps-from-atp-and-its-application-in-the-synthesis-of-chondroitin-sulfate/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/rational-design-of-a-highly-efficient-catalytic-system-for-the-production-of-paps-from-atp-and-its-application-in-the-synthesis-of-chondroitin-sulfate/</guid>
      <description>理性设计提高产量 link:https://onlinelibrary.wiley.com/doi/epdf/10.1002/bit.27919 </description>
    </item>
    
    <item>
      <title>window AutoDock学习笔记</title>
      <link>https://example.com/p/window-autodock%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/window-autodock%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>整理了下 win AutoDock的学习记录（主要方便自己看），看的是blibli和其他网址上别人的做法，因为是很久之前学的，所以暂时没找到链接（找到了再放上来）
对接的完整步骤 修改默认工作目录 工作目录下要有adt.bat/autodock4.exe/autogrid4.exe 以及所要进行对接的受体和配体
导入受体pdb File&amp;mdash;read Mol &amp;ndash;选择 （小红点代表水分子，要去除）
去除受体的水分子 Edit &amp;ndash; delete water
受体加氢 Edit &amp;ndash; Hydro &amp;ndash; add 选为受体 Grid &amp;ndash; Macro &amp;ndash; choose &amp;ndash; 选择 会生成一个受体pdbqt
导入配体 同上
加氢 同上
选为配体 Ligand &amp;ndash; input &amp;ndash;choose
检查下它的扭转键和中心 ligand &amp;ndash; Torsion Tree -Detect Root ligand &amp;ndash; Torsion Tree -Choose Torsion 红色的是不可以被扭转的，绿色的是可以被扭转的
接下来导出为配体的pdbqt ligand &amp;ndash; output &amp;ndash; save as pdbqt (完成后记得删除DM中的对象)
准备对接 导入受体 ： Grid &amp;ndash; Macromolecule &amp;ndash; open &amp;ndash;选择 导入配体： Grid &amp;ndash; Set Map Types &amp;ndash; open ligand &amp;ndash;选择 准备盒子运行的大小： Grid &amp;ndash; Grid Box &amp;ndash; 调整盒子大小（包裹核心位点或者整个protein） 将配体从box中取出 勾去掉后，不要关闭那个GUI，右键拖出小分子，拖出后将勾打上</description>
    </item>
    
    <item>
      <title>AD4_parameters金属离子参数的修改</title>
      <link>https://example.com/p/ad4_parameters%E9%87%91%E5%B1%9E%E7%A6%BB%E5%AD%90%E5%8F%82%E6%95%B0%E7%9A%84%E4%BF%AE%E6%94%B9/</link>
      <pubDate>Thu, 07 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ad4_parameters%E9%87%91%E5%B1%9E%E7%A6%BB%E5%AD%90%E5%8F%82%E6%95%B0%E7%9A%84%E4%BF%AE%E6%94%B9/</guid>
      <description>整理了下 win AutoDock的学习记录（主要方便自己看），看的是blibli和其他网址上别人的做法，因为是很久之前学的，所以暂时没找到链接（找到了再放上来）
在mpl文件夹中找到AD4_parameters.dat文件 并放置到工作目录下
先看下缺乏的情况 顺便提下，在从RCSB PDB中下载pdb时 在下面可以看到一些详情；如什么东西在什么链
去除相关链（可以直接在pymol中操作）
命令行：remove chain B (C/D)
去除水分子： A &amp;ndash; remove water
如有小分子配体则删除 （怎么看是不是小分子配体呢？在seq 不是连续拼接上的，就是小分子配体；金属离子不要去除）
File &amp;ndash; export Molecule &amp;ndash; pdb
在ADT中导入刚才pymol生成的pdb，因为在pymol中去过水了，所以直接加氢就好了
将NI.pdb 选为受体生成pdbqt 可以看出系统会自动提醒这个离子没有电荷（因为AD4_parameters.dat中没有这个金属离子的参数）
然后就可以一波操作（如Grid导入受体/配体/确认对接box的大小）运行autogrid/autodock， 此时会有报错的内容： 报错的解决方案 修改AD4_parameters.dat的离子内容（去网上找一份比较齐全的，然后复制过去） 一定要记得修改gpf/dpf的文件 gpf（盒子的那个文件） / dpf是docking时生成那个文件
在开头新增一行 paramter_file AD4_parameters.dat # force field default paramter_file 再次运行run &amp;ndash; autogrid</description>
    </item>
    
    <item>
      <title>用PYMOL给蛋白质小分子添加标签</title>
      <link>https://example.com/p/%E7%94%A8pymol%E7%BB%99%E8%9B%8B%E7%99%BD%E8%B4%A8%E5%B0%8F%E5%88%86%E5%AD%90%E6%B7%BB%E5%8A%A0%E6%A0%87%E7%AD%BE/</link>
      <pubDate>Thu, 07 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8pymol%E7%BB%99%E8%9B%8B%E7%99%BD%E8%B4%A8%E5%B0%8F%E5%88%86%E5%AD%90%E6%B7%BB%E5%8A%A0%E6%A0%87%E7%AD%BE/</guid>
      <description>整理了下 win AutoDock的学习记录（主要方便自己看），看的是blibli和其他网址上别人的做法，因为是很久之前学的，所以暂时没找到链接（找到了再放上来）
导入 对接结果pdbqt 和 小分子配体的pdbqt PYMOL 背景改成白色
Display &amp;ndash; Background &amp;ndash; White
选一个和对接位点比较远的残基（即和对接位点不太相关的残基）
选中残基 &amp;ndash; 鼠标右键 &amp;ndash; edit label 将其名字改为我们想要告诉别人的残基名字 同理再来一个
将右下角的3-Button 的模式改为Editing
Ctrl 就可以拖动标签了
后面还想修改，先把3-Button改回Viewing模式
如果想删除标签，去点击sele的L &amp;ndash; clear</description>
    </item>
    
    <item>
      <title>用R语言png函数输出高分辨率的图片</title>
      <link>https://example.com/p/%E7%94%A8r%E8%AF%AD%E8%A8%80png%E5%87%BD%E6%95%B0%E8%BE%93%E5%87%BA%E9%AB%98%E5%88%86%E8%BE%A8%E7%8E%87%E7%9A%84%E5%9B%BE%E7%89%87/</link>
      <pubDate>Thu, 07 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8r%E8%AF%AD%E8%A8%80png%E5%87%BD%E6%95%B0%E8%BE%93%E5%87%BA%E9%AB%98%E5%88%86%E8%BE%A8%E7%8E%87%E7%9A%84%E5%9B%BE%E7%89%87/</guid>
      <description> 整理了下 win AutoDock的学习记录（主要方便自己看），看的是blibli和其他网址上别人的做法，因为是很久之前学的，所以暂时没找到链接（找到了再放上来）
引言 scale()数据标准化、中心化处理 使用heatmap画热图函数 heapmap(a)
使用png函数绘制 首先 查看下R的工作目录 getwd()
png(filename= &amp;ldquo;HEATMAP.png&amp;rdquo;,width = 1700, height = 1500, units = &amp;ldquo;px&amp;rdquo;, bg=&amp;ldquo;white&amp;rdquo;,res = 300) 参数值自己调整
heapmap(a)
dev.off() 这就画完了，但是要看看数据是否完整被画出来，再进行png（）命令中的参数进行调整
记得关闭Rstudio </description>
    </item>
    
    <item>
      <title>知道活性中心坐标后怎么确定grid box</title>
      <link>https://example.com/p/%E7%9F%A5%E9%81%93%E6%B4%BB%E6%80%A7%E4%B8%AD%E5%BF%83%E5%9D%90%E6%A0%87%E5%90%8E%E6%80%8E%E4%B9%88%E7%A1%AE%E5%AE%9Agrid-box/</link>
      <pubDate>Thu, 07 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%9F%A5%E9%81%93%E6%B4%BB%E6%80%A7%E4%B8%AD%E5%BF%83%E5%9D%90%E6%A0%87%E5%90%8E%E6%80%8E%E4%B9%88%E7%A1%AE%E5%AE%9Agrid-box/</guid>
      <description> 整理了下 win AutoDock的学习记录（主要方便自己看），看的是blibli和其他网址上别人的做法，因为是很久之前学的，所以暂时没找到链接（找到了再放上来）
Gird &amp;ndash; Grid box &amp;ndash; View &amp;ndash; show box as lines View中还有去掉中心坐标以及修改箱子尺寸的 通过某种软件知道了蛋白质的活性中心后，把这个box尽可能地锁定到那里去 在那个软件中知道了两个 参考点，然后简单运算到 ADT地坐标系上 找原子法： 找到活性中心的一个残基 这就可以看到原子了 注意要输入全称才会锁定上 这就蹦到这了 肉眼法 肉眼观察，自行调整到那里,如果不好看的话，可以调整蛋白模型的表现形式 </description>
    </item>
    
    <item>
      <title>RosettaScripts: A Scripting Language Interface to the Rosetta Macromolecular Modeling Suite</title>
      <link>https://example.com/p/rosettascripts-a-scripting-language-interface-to-the-rosetta-macromolecular-modeling-suite/</link>
      <pubDate>Sat, 19 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/rosettascripts-a-scripting-language-interface-to-the-rosetta-macromolecular-modeling-suite/</guid>
      <description>RosettaScripts: A Scripting Language Interface to the Rosetta Macromolecular Modeling Suite
link:https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0020161</description>
    </item>
    
    <item>
      <title>用scikit-learn进行LDA降维</title>
      <link>https://example.com/p/%E7%94%A8scikit-learn%E8%BF%9B%E8%A1%8Clda%E9%99%8D%E7%BB%B4/</link>
      <pubDate>Mon, 07 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8scikit-learn%E8%BF%9B%E8%A1%8Clda%E9%99%8D%E7%BB%B4/</guid>
      <description>我们首先生成三类三维特征的数据，代码如下：
import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D from sklearn.datasets import make_classification X,y = make_classification(n_samples=1000,n_features=3,n_redundant=0, n_classes=3,n_informative=2,n_clusters_per_class=1,class_sep=0.5, random_state=22) fig = plt.figure(figsize=(15,8)) ax = Axes3D(fig,rect=[0,0,1,1],elev=30,azim=20) ax.scatter(X[:,0],X[:,1],X[:,2],marker=&amp;#34;o&amp;#34;,c=y) 首先我们看看使用PCA降维到二维的情况，注意PCA无法使用类别信息来降维
from sklearn.decomposition import PCA pca = PCA(n_components=2) pca.fit(X) print(pca.explained_variance_ratio_) print(pca.explained_variance_) X_nex = pca.transform(X) plt.scatter(X_nex[:,0],X_nex[:,1],marker=&amp;#34;o&amp;#34;,c=y) plt.show() result: 由于PCA没有利用类别信息，我们可以看到降维后，样本特征和类别的信息关联几乎完全丢失。
现在我们再看看使用LDA的效果
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis lda = LinearDiscriminantAnalysis(n_components=2) lda.fit(X,y) X_new = lda.transform(X) plt.scatter(X_new[:,0],X_new[:,1],marker=&amp;#34;o&amp;#34;,c=y) plt.show() result: 可以看出降维后样本特征和类别信息之间的关系得以保留。
一般来说，如果我们的数据是有类别标签的，那么优先选择LDA去尝试降维；当然也可以使用PCA做很小幅度的降维去消去噪声，然后再使用LDA降维。如果没有类别标签，那么肯定PCA是最先考虑的一个选择了。</description>
    </item>
    
    <item>
      <title>用scikit-learn学习主成分分析(PCA)</title>
      <link>https://example.com/p/%E7%94%A8scikit-learn%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90pca/</link>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8scikit-learn%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90pca/</guid>
      <description>import numpy as np import pandas as pd import matplotlib import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) # matplotlib.style.use(&amp;#34;ggplot&amp;#34;) #这个用来绘制三维图 from mpl_toolkits.mplot3d import Axes3D # from sklearn.datasets.samples_generator import make_blobs from sklearn.datasets import make_blobs # X为样本特征，Y为样本簇类别， 共1000个样本，每个样本3个特征，共4个簇 X,y = make_blobs(n_samples=10000,n_features=3,centers=[[3,3,3],[0,0,0],[1,1,1],[2,2,2]], cluster_std=[0.2,0.1,0.2,0.2],random_state=22) fig = plt.figure(figsize=(15,5))#之所以要这样是为了传给Axes3D一个画布 ax = Axes3D(fig,rect=[0,0,1,1],elev=30,azim=20) plt.scatter(X[:,0],X[:,1],X[:,2],marker=&amp;#34;o&amp;#34;) result: 我们先不降维，只对数据进行投影，看看投影后的三个维度的方差分布，代码如下：
from sklearn.decomposition import PCA pca = PCA(n_components=3) pca.fit(X) print(pca.explained_variance_) print(pca.explained_variance_ratio_) result:
[3.78352072 0.03342374 0.03210098] [0.98297637 0.00868364 0.00833998] 投影后第一个特征占了绝大多数的主成分比例。
现在我们来进行降维，从三维降到2维，代码如下：
pca = PCA(n_components=2) pca.</description>
    </item>
    
    <item>
      <title>用scikit-learn研究局部线性嵌入(LLE)</title>
      <link>https://example.com/p/%E7%94%A8scikit-learn%E7%A0%94%E7%A9%B6%E5%B1%80%E9%83%A8%E7%BA%BF%E6%80%A7%E5%B5%8C%E5%85%A5lle/</link>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8scikit-learn%E7%A0%94%E7%A9%B6%E5%B1%80%E9%83%A8%E7%BA%BF%E6%80%A7%E5%B5%8C%E5%85%A5lle/</guid>
      <description>LLE用于降维可视化实践
下面我们用一个具体的例子来使用scikit-learn进行LLE降维并可视化。
import numpy as np import pandas as pd import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D #manifold是用来导入LLE from sklearn import manifold,datasets from sklearn.utils import check_random_state 我们接着生成随机数据，由于LLE必须要基于流形不能闭合，因此我们生成了一个缺一个口的三维球体。生成数据并可视化的代码如下：
n_samples = 500 #check_random_state 的作用是 Turn seed into a np.random.RandomState instance random_state = check_random_state(0) print(random_state) result:
RandomState(MT19937) #作用体现在这里了 p = random_state.rand(n_samples)*(2*np.pi-0.55) t = random_state.rand(n_samples)*np.pi print(p,t) result: # 让球体不闭合，符合流形定义 indices = ((t &amp;lt; (np.pi - (np.pi / 8))) &amp;amp; (t &amp;gt; ((np.pi / 8)))) colors = p[indices] x, y, z = np.</description>
    </item>
    
    <item>
      <title>《动手学深度学习》</title>
      <link>https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>Python中的itertools.product</title>
      <link>https://example.com/p/python%E4%B8%AD%E7%9A%84itertools.product/</link>
      <pubDate>Wed, 02 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/python%E4%B8%AD%E7%9A%84itertools.product/</guid>
      <description>itertools包中的方法product 函数
product(A, B)函数，返回A、B中的元素的笛卡尔积的元组
code:
from itertools import product A = [1,2,3,4] B = [5,6,7,8] list(product(A,B)) result:
[(1, 5), (1, 6), (1, 7), (1, 8), (2, 5), (2, 6), (2, 7), (2, 8), (3, 5), (3, 6), (3, 7), (3, 8), (4, 5), (4, 6), (4, 7), (4, 8)] 可以看出返回的是A和B中每一个元素的元组组合
就是说它会将A中的第一个元素与B中的每一个元素构成一个元组组合，以此类推下去</description>
    </item>
    
    <item>
      <title>pytorch基本模型12_循环神经网路（基础篇）</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B12_%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E8%B7%AF%E5%9F%BA%E7%A1%80%E7%AF%87/</link>
      <pubDate>Mon, 28 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B12_%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E8%B7%AF%E5%9F%BA%E7%A1%80%E7%AF%87/</guid>
      <description>这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
注意几个参数
输入和隐层（输出）维度 序列长度 批处理大小 注 调用RNNCell这个需要循环，循环长度就是序列长度 import torch batch_size = 1 seq_len = 3 #序列长度 input_size = 4 #输入维度 hidden_size = 2 #隐层维度 cell = torch.nn.RNNCell(input_size=input_size,hidden_size=hidden_size) dataset = torch.randn(seq_len,batch_size,input_size) hidden = torch.zeros(batch_size,hidden_size) #for循环处理seq_len长度的数据 for idx,data in enumerate(dataset): print(&amp;#34;=&amp;#34;*20,idx,&amp;#34;=&amp;#34;*20) print(&amp;#34;Input size:&amp;#34;,data.shape,data) hidden = cell(data,hidden) print(&amp;#34;hidden size:&amp;#34;,hidden.shape,hidden) print(hidden) result:
==================== 0 ==================== Input size: torch.Size([1, 4]) tensor([[-0.5352, 1.8843, -0.0926, 0.5294]]) hidden size: torch.Size([1, 2]) tensor([[ 0.3160, -0.5305]], grad_fn=&amp;lt;TanhBackward0&amp;gt;) tensor([[ 0.3160, -0.</description>
    </item>
    
    <item>
      <title>Protein structure prediction and analysis using the Robetta server</title>
      <link>https://example.com/p/protein-structure-prediction-and-analysis-using-the-robetta-server/</link>
      <pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/protein-structure-prediction-and-analysis-using-the-robetta-server/</guid>
      <description>Protein structure prediction and analysis using the Robetta server
link:https://academic.oup.com/nar/article/32/suppl_2/W526/1040731?login=false</description>
    </item>
    
    <item>
      <title>py_os方法总结</title>
      <link>https://example.com/p/py_os%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</link>
      <pubDate>Fri, 25 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_os%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</guid>
      <description>教程看的是这里的 https://www.runoob.com/python/os-file-methods.html
os.access(path,mode) 用来检验权限模式 os.access() 方法使用当前的uid/gid尝试访问路径。大部分操作使用有效的 uid/gid, 因此运行环境可以在 suid/sgid 环境尝试
参数
path &amp;ndash; 要用来检测是否有访问权限的路径
mode &amp;ndash; mode为F_OK，测试存在的路径，或者它可以是包含R_OK, W_OK和X_OK或者R_OK, W_OK和X_OK其中之一或者更多
os.F_OK: 作为access()的mode参数，测试path是否存在 os.R_OK: 包含在access()的mode参数中 ， 测试path是否可读 os.W_OK 包含在access()的mode参数中 ， 测试path是否可写 os.X_OK 包含在access()的mode参数中 ，测试path是否可执行 code:
import os #文件是否存在 os.access(&amp;#34;./os_test.txt&amp;#34;,mode=os.F_OK) result:
True code:
#文件是否可读 os.access(&amp;#34;./os_test.txt&amp;#34;,mode=os.R_OK) result:
True code
#文件是否可写 os.access(&amp;#34;./os_test.txt&amp;#34;,mode=os.W_OK) result:
True code:
#文件是否可执行 os.access(&amp;#34;./os_test.txt&amp;#34;,mode=os.X_OK) result:
True os.chdir() os.chdir() 方法用于改变当前工作目录到指定的路径
参数： path &amp;ndash; 要切换到的新路径 返回值 如果允许访问返回 True , 否则返回False code:
#先看看看当前目录在哪里 os.getcwd() result:</description>
    </item>
    
    <item>
      <title>pytorch基本模型11_卷积神经网络（高级篇）</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B11_%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%AB%98%E7%BA%A7%E7%AF%87/</link>
      <pubDate>Fri, 25 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B11_%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%AB%98%E7%BA%A7%E7%AF%87/</guid>
      <description>这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
1、卷积核超参数选择困难，自动找到卷积的最佳组合。 2、1x1卷积核，不同通道的信息融合。使用1x1卷积核虽然参数量增加了，但是能够显著的降低计算量(operations) 3、Inception Moudel由4个分支组成，要分清哪些是在Init里定义，哪些是在forward里调用。4个分支在dim=1(channels)上进行concatenate。24+16+24+24 = 88 4、GoogleNet的Inception(Pytorch实现) 5、1乘28乘28 → 10乘24乘24 → 10乘12乘12 → 88乘12乘12 → 20乘8乘8 → 88乘4乘4=1408 代码说明：
1、先使用类对Inception Moudel进行封装
2、先是1个卷积层(conv,maxpooling,relu)，然后inceptionA模块(输出的channels是24+16+24+24=88)，接下来又是一个卷积层(conv,mp,relu),然后inceptionA模块，最后一个全连接层(fc)。
3、1408这个数据可以通过x = x.view(in_size, -1)后调用x.shape得到。
import torch import torch.nn as nn from torchvision import datasets from torchvision import transforms from torch.utils.data import DataLoader import torch.nn.functional as F batch_size = 64 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307),(0.3081,))]) train_dataset = datasets.MNIST(root=&amp;#34;../dataset/minis/&amp;#34;,train=True,transform=transform) train_loader = DataLoader(dataset=train_dataset,shuffle=True,batch_size=batch_size) test_dataset = datasets.MNIST(root=&amp;#34;../dataset/minis/&amp;#34;,train=False,transform=transform) test_loader = DataLoader(dataset=test_dataset,shuffle=True,batch_size=batch_size) class InceptionA(torch.</description>
    </item>
    
    <item>
      <title>pytorch基本模型10_卷积神经网络（基础篇）</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B10_%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%AF%87/</link>
      <pubDate>Thu, 24 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B10_%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%AF%87/</guid>
      <description>这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
1、每一个卷积核它的通道数量要求和输入通道是一样的。这种卷积核的总数有多少个和你输出通道的数量是一样的
2 卷积(convolution)后，C(Channels)变，W(width)和H(Height)可变可不变，取决于是否padding。subsampling(或pooling)后，C不变，W和H变
3 卷积层：保留图像的空间信息。
4 卷积层要求输入输出是四维张量(B,C,W,H)，全连接层的输入与输出都是二维张量(B,Input_feature)
5 卷积(线性变换)，激活函数(非线性变换)，池化；这个过程若干次后，view打平，进入全连接层 1、torch.nn.Conv2d(1,10,kernel_size=3,stride=2,bias=False)
1是指输入的Channel，灰色图像是1维的；10是指输出的Channel，也可以说第一个卷积层需要10个卷积核；kernel_size=3,卷积核大小是3x3；stride=2进行卷积运算时的步长，默认为1；bias=False卷积运算是否需要偏置bias，默认为False。padding = 0，卷积操作是否补0。
2、self.fc = torch.nn.Linear(320, 10)，这个320获取的方式，可以通过x = x.view(batch_size, -1) # print(x.shape)可得到(64,320),64指的是batch，320就是指要进行全连接操作时，输入的特征维度。
import torch from torchvision import datasets from torchvision import transforms from torch.utils.data import DataLoader import torch.nn.functional as F batch_size = 64 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))]) #简单来说就是使用datasets读取数据 #DataLoader来处理加入batch train_dataset = datasets.MNIST(root=&amp;#34;../dataset/minis/&amp;#34;,train=True,transform=transform) train_loader = DataLoader(train_dataset,shuffle=True,batch_size=batch_size) test_dataset = datasets.MNIST(root=&amp;#34;../dataset/minis/&amp;#34;,train=False,transform=transform) test_loader = DataLoader(test_dataset,shuffle=True,batch_size=batch_size) class Net(torch.nn.Module): def __init__(self): super(Net,self).__init__() self.conv1 = torch.</description>
    </item>
    
    <item>
      <title>pytorch基本模型07_处理多维特征的输入</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B07_%E5%A4%84%E7%90%86%E5%A4%9A%E7%BB%B4%E7%89%B9%E5%BE%81%E7%9A%84%E8%BE%93%E5%85%A5/</link>
      <pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B07_%E5%A4%84%E7%90%86%E5%A4%9A%E7%BB%B4%E7%89%B9%E5%BE%81%E7%9A%84%E8%BE%93%E5%85%A5/</guid>
      <description>这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
import torch import numpy as np xy = np.loadtxt(&amp;#34;../ppt&amp;amp;vedio/diabetes.csv.gz&amp;#34;,delimiter=&amp;#34;,&amp;#34;,dtype=np.float32) x_data = torch.from_numpy(xy[:,:-1]) # [-1] 最后得到的是个矩阵 y_data = torch.from_numpy(xy[:,[-1]]) x_data result:
tensor([[-0.2941, 0.4874, 0.1803, ..., 0.0015, -0.5312, -0.0333], [-0.8824, -0.1457, 0.0820, ..., -0.2072, -0.7669, -0.6667], [-0.0588, 0.8392, 0.0492, ..., -0.3055, -0.4927, -0.6333], ..., [-0.4118, 0.2161, 0.1803, ..., -0.2191, -0.8574, -0.7000], [-0.8824, 0.2663, -0.0164, ..., -0.1028, -0.7686, -0.1333], [-0.8824, -0.0653, 0.1475, ..., -0.0939, -0.7976, -0.9333]]) In [11]: 1 class Model(torch.nn.Module): code</description>
    </item>
    
    <item>
      <title>pytorch基本模型08_加载数据集</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B08_%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86/</link>
      <pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B08_%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86/</guid>
      <description>这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
import numpy as np import torch from torch.utils.data import Dataset,DataLoader #DiabetesDataset集成了Dataset的属性 class DiabetesDataset(Dataset): def __init__(self,filepath): xy = np.loadtxt(filepath,delimiter=&amp;#34;,&amp;#34;,dtype=np.float32) self.len = xy.shape[0] #from_numpy 可以将numpy对象转为Tensor self.x_data = torch.from_numpy(xy[:,:-1]) self.y_data = torch.from_numpy(xy[:,[-1]]) def __getitem__(self,index): return self.x_data[index],self.y_data[index] def __len__(self): return self.len dataset = DiabetesDataset(&amp;#34;../ppt&amp;amp;vedio/diabetes.csv.gz&amp;#34;) train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=0) class Model(torch.nn.Module): def __init__(self): super(Model,self).__init__() self.linear1 = torch.nn.Linear(8,6) self.linear2 = torch.nn.Linear(6,4) self.linear3 = torch.nn.Linear(4,1) self.sigmoid = torch.nn.Sigmoid() def forward(self,x): x = self.sigmoid(self.linear1(x)) x = self.</description>
    </item>
    
    <item>
      <title>pytorch基本模型09_多分类问题</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B09_%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B09_%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/</guid>
      <description>这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
import torch import numpy as np y = np.array([1,0,0]) z = np.array([0.2,0.1,-0.1]) y_pred = np.exp(z) / np.exp(z).sum() loss = (-y * np.log(y_pred)).sum() print(loss) import torch y = torch.LongTensor([0]) z = torch.Tensor([[0.2,0.1,-0.1]]) criterion = torch.nn.CrossEntropyLoss() loss = criterion(z,y) print(loss) import torch criterion = torch.nn.CrossEntropyLoss() Y = torch.LongTensor([2,0,1]) Y_pred1 = torch.Tensor([[0.1,0.2,0.9], [1.1,0.1,0.2], [0.2,2.1,0.1]]) Y_pred2 = torch.Tensor(([[0.8,0.2,0.3], [0.2,0.3,0.5], [0.2,0.2,0.5]])) l1 = criterion(Y_pred1,Y) l2 = criterion(Y_pred2,Y) print(&amp;#34;Batch Loss1 = &amp;#34;,l1.data,&amp;#34;\nBatch Loss2=&amp;#34;,l2.data) #transfrom是用来处理数据的，如改变维度之类的 import torch from torchvision import transforms from torchvision import datasets from torch.</description>
    </item>
    
    <item>
      <title>pytorch基本模型05用PyTorch实现线性回归</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B05%E7%94%A8pytorch%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Sat, 19 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B05%E7%94%A8pytorch%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description>这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
准备数据 设计计算单元 构建代价和优化函数 训练 import torch x_data = torch.Tensor([[1.0],[2.0],[3.0]]) y_data = torch.Tensor([[2.0],[4.0],[6.0]]) #计算单元 class LinerarModel(torch.nn.Module): def __init__(self): #super中传入类名 super(LinerarModel,self).__init__() self.linear = torch.nn.Linear(1,1)#weight and bias def forward(self,x): y_pred = self.linear(x) return y_pred #实例化 model = LinerarModel() #代价函数 实例化torch中的MSELoss criterion = torch.nn.MSELoss() #参数优化函数 实例化torch中的optim.SGD optimizer = torch.optim.SGD(model.parameters(),lr=0.01) print(model.parameters) result
&amp;lt;bound method Module.parameters of LinerarModel( (linear): Linear(in_features=1, out_features=1, bias=True) )&amp;gt; code
for epoch in range(1000): y_pred = model(x_data)#forward #这里model就已经构建了一个计算图了，又因为事用loss去求偏导，所以下面用loss.backward #loss这里会自动拼接上去上面的那个计算图 loss = criterion(y_pred,y_data) print(epoch,loss) optimizer.</description>
    </item>
    
    <item>
      <title>pytorch基本模型06._logistics回归</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B06._logistics%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Sat, 19 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B06._logistics%E5%9B%9E%E5%BD%92/</guid>
      <description>这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
code
import torch x_data = torch.Tensor([[1.0],[2.0],[3.0]]) y_data = torch.Tensor([[0],[1],[0]]) class LogisticRegressionModel(torch.nn.Module): def __init__(self): super(LogisticRegressionModel,self).__init__() self.linear = torch.nn.Linear(1,1) def forward(self,x): #加了个激活函数 F.sigmoid() y_pred = torch.sigmoid(self.linear(x)) return y_pred model = LogisticRegressionModel() criterion = torch.nn.BCELoss() optimizer = torch.optim.SGD(model.parameters(),lr=0.01) for epoch in range(100): y_pred = model(x_data) loss = criterion(y_pred,y_data) print(epoch,loss.item()) optimizer.zero_grad() loss.backward() optimizer.step() print(&amp;#34;w=&amp;#34;,model.linear.weight.item()) print(&amp;#34;b=&amp;#34;,model.linear.bias.item()) result:
0 0.6860817074775696 1 0.6860291957855225 2 0.6859772801399231 3 0.6859259605407715 4 0.6858751177787781 5 0.6858246922492981 6 0.6857749819755554 7 0.6857255101203918 8 0.</description>
    </item>
    
    <item>
      <title>pytorch基本模型04_反向传播</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B04_%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</link>
      <pubDate>Tue, 15 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B04_%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</guid>
      <description>这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
Tensor对象包含了data和grad import torch x_data = [1.0, 2.0, 3.0] y_data = [2.0, 4.0, 6.0] #记得用[]装起来 w = torch.Tensor([1.0]) w.requires_grad = True #参数requires_grad = True/False 是用来设置是否计算梯度（求导）,默认是True #定义一个线性的计算单元 def forward(x): return x*w #定义损失函数 def loss(x,y): y_pred = forward(x) return (y_pred - y) ** 2 #forward(4).item 注意这里是将w（tensor）中的值取出，由于它是tensor对象，所以用item获取 print(&amp;#34;predict (before training)&amp;#34;,4,forward(4).item) for epoch in range(100): for x,y in zip(x_data,y_data): #这里的loss就会自动构建一个计算图(正向)了 l = loss(x,y) #用tenor本身有的backward l.backward() #要这样取出w.grad.item()权重导数的值 print(&amp;#34;\tgrad:&amp;#34;,x,y,w.grad.item()) #SGB w.data = w.data -0.01*w.grad.data #记得每次循环将此轮反向传播的梯度清零 要不然会累加 w.</description>
    </item>
    
    <item>
      <title>《分子模拟的理论与实践》</title>
      <link>https://example.com/p/%E5%88%86%E5%AD%90%E6%A8%A1%E6%8B%9F%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Mon, 14 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%86%E5%AD%90%E6%A8%A1%E6%8B%9F%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>pytorch基本模型01_版本demo</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B01_%E7%89%88%E6%9C%ACdemo/</link>
      <pubDate>Sun, 13 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B01_%E7%89%88%E6%9C%ACdemo/</guid>
      <description> 这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
code
import torch torch.randn(*sizes, out=None) → Tensor
等同于np.randn返回的是均值0，方差为1的正态分布 的张量
code
x = torch.randn(1,10) x result: code:
prev_h = torch.randn(1,20) prev_h result: code:
W_h = torch.randn(20,20) W_h result: W_x = torch.randn(20,10) W_x 查看pytorch版本
import torch print(torch.__version__) </description>
    </item>
    
    <item>
      <title>pytorch基本模型02_线性模型</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B02_%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Sun, 13 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B02_%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</guid>
      <description>这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
import numpy as np import matplotlib.pyplot as plt x_data = [1.0,2.0,3.0] y_data = [2.0,4.0,6.0] #正向传播，预测y def forward(x): return x*w #计算损失 def loss(x,y): y_pred = forward(x) return (y_pred-y) * (y_pred-y) #权重更新存储 w_list = [] #mse均误差cunc mse_list = [] #产生不同的权重，用于计算 左闭右开 for w in np.arange(0.0,4.1,0.1): print(&amp;#34;w=&amp;#34;,w) l_sum = 0 #依次传入每个样本 for x_val,y_val in zip(x_data,y_data): y_pred_val = forward(x_val) #注意定义的loss中本身会计算产生一个正向传播的计算图 loss_val = loss(x_val,y_val) #mse这里是三个样本的损失之和 l_sum+=loss_val #t制表符会使得输出更好看 print(&amp;#34;\t&amp;#34;,x_val,y_val,y_pred_val,loss_val) print(&amp;#34;MSE=&amp;#34;,l_sum/3) w_list.append(w) mse_list.append(l_sum/3) result
w= 0.</description>
    </item>
    
    <item>
      <title>pytorch基本模型03_梯度下降算法</title>
      <link>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B03_%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sun, 13 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pytorch%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B03_%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/</guid>
      <description>这是学习pytorch基本使用的记录（我记得看的是B站刘二老师的视频）
import numpy as np import matplotlib.pyplot as plt import matplotlib import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import seaborn as sns plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False x_data = [1.0,2.0,3.0] y_data = [2.0,4.0,6.0] #初始化个权重值 w = 1.0 #正向传播 def forward(x): return w*x #代价 def cost(xs,ys): cost = 0 for x,y in zip(xs,ys): y_pred = forward(x) cost += (y_pred-y)**2 return cost/len(xs) #梯度求导部分 def gradient(xs,ys): grad = 0 for x,y in zip(xs,ys): grad += 2*x*(x*w-y) return grad / len(xs) print(&amp;#34;Predict (before training)&amp;#34;,4,forward(4)) cost_list = [] for epoch in range(100): cost_val = cost(x_data,y_data) cost_list.</description>
    </item>
    
    <item>
      <title>py_占位符运用</title>
      <link>https://example.com/p/py_%E5%8D%A0%E4%BD%8D%E7%AC%A6%E8%BF%90%E7%94%A8/</link>
      <pubDate>Fri, 11 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_%E5%8D%A0%E4%BD%8D%E7%AC%A6%E8%BF%90%E7%94%A8/</guid>
      <description>这里来学习一下Python中的_Underscore的用处 总的来说可以提高编码效率,教程原文：https://www.datacamp.com/community/tutorials/role-underscore-python
存储作用 Python automatically stores the value of the last expression in the interpreter to a particular variable called &amp;ldquo;_.&amp;rdquo; You can also assign these value to another variable if you want.
简单来说就是存储上一次未指定变量名字的结果，并且可以通过变量赋值 占位作用 Ignoring Values Underscore() is also used to ignore the values. If you don&amp;rsquo;t want to use specific values while unpacking, just assign that value to underscore().
Ignoring means assigning the values to special variable underscore().</description>
    </item>
    
    <item>
      <title>Native protein sequences are close to optimal for their structures</title>
      <link>https://example.com/p/native-protein-sequences-are-close-to-optimal-for-their-structures/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/native-protein-sequences-are-close-to-optimal-for-their-structures/</guid>
      <description>Native protein sequences are close to optimal for their structures
link:https://www.pnas.org/doi/abs/10.1073/pnas.97.19.10383</description>
    </item>
    
    <item>
      <title>The Backrub Motion: How Protein Backbone Shrugs When a Sidechain Dances</title>
      <link>https://example.com/p/the-backrub-motion-how-protein-backbone-shrugs-when-a-sidechain-dances/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/the-backrub-motion-how-protein-backbone-shrugs-when-a-sidechain-dances/</guid>
      <description>The Backrub Motion: How Protein Backbone Shrugs When a Sidechain Dances
link:https://www.cell.com/fulltext/S0969-2126(06)00040-2</description>
    </item>
    
    <item>
      <title>sklearn.datasets中的几个函数make_moons,make_circles,make_classification</title>
      <link>https://example.com/p/sklearn.datasets%E4%B8%AD%E7%9A%84%E5%87%A0%E4%B8%AA%E5%87%BD%E6%95%B0make_moonsmake_circlesmake_classification/</link>
      <pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sklearn.datasets%E4%B8%AD%E7%9A%84%E5%87%A0%E4%B8%AA%E5%87%BD%E6%95%B0make_moonsmake_circlesmake_classification/</guid>
      <description>make_moons() sklearn.datasets.make_moons(n_samples=100, shuffle=True, noise=None, random_state=None)
制作月亮型数据
重要参数：n_samples：设置样本数量、noise:设置噪声、random_state：设置随机参数（嘿嘿，无所谓，随便设），我们主要讲参数noise
from sklearn.datasets import make_moons import matplotlib.pyplot as plt # plt.style.use(&amp;#34;seaborn-whitegrid&amp;#34;) a,b = make_moons(noise=0) plt.scatter(a[:,0],a[:,1],c=b) result: ![](picture/sklearn.datasets中的几个函数make_moons,%20make_circles(,make_classification.png)
#将noise设置为0.1 a,b = make_moons(noise=0.1) plt.scatter(a[:,0],a[:,1],c=b) #发现这个noise设置的越大，那么噪声就越大 result: make_circles() sklearn.datasets.make_circles(n_samples=100, shuffle=True, noise=None, random_state=None, factor=0.8)
重要参数：n_samples：设置样本数量、noise:设置噪声、factor：0 &amp;lt; double &amp;lt; 1 默认值0.8，内外圆之间的比例因子、random_state：设置随机参数（嘿嘿，无所谓，随便设），我们主要讲参数noise、factor
from sklearn.datasets import make_circles #将moise设置为0，factor设置为0.1 a,b = make_circles(noise=0,factor=0.1) plt.scatter(a[:,0],a[:,1],c=b) result: code:
#将noise设置为0.1，factor设置为0.5 a,b = make_circles(noise=0.1,factor=0.5) plt.scatter(a[:,0],a[:,1],c=b) #发现这个noise设置的越大，那么噪声就越大，factor设置的越大，两个环就越近 result: make_classfication sklearn.datasets.make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.</description>
    </item>
    
    <item>
      <title>《GROMACS中文手册》</title>
      <link>https://example.com/p/gromacs%E4%B8%AD%E6%96%87%E6%89%8B%E5%86%8C/</link>
      <pubDate>Sun, 30 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gromacs%E4%B8%AD%E6%96%87%E6%89%8B%E5%86%8C/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>《GROMACS教程_漏斗网蜘蛛毒素肽的溶剂化研究_Amber99SB-ILDN力场_Jerkwin》</title>
      <link>https://example.com/p/gromacs%E6%95%99%E7%A8%8B_%E6%BC%8F%E6%96%97%E7%BD%91%E8%9C%98%E8%9B%9B%E6%AF%92%E7%B4%A0%E8%82%BD%E7%9A%84%E6%BA%B6%E5%89%82%E5%8C%96%E7%A0%94%E7%A9%B6_amber99sb-ildn%E5%8A%9B%E5%9C%BA_jerkwin/</link>
      <pubDate>Sun, 30 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gromacs%E6%95%99%E7%A8%8B_%E6%BC%8F%E6%96%97%E7%BD%91%E8%9C%98%E8%9B%9B%E6%AF%92%E7%B4%A0%E8%82%BD%E7%9A%84%E6%BA%B6%E5%89%82%E5%8C%96%E7%A0%94%E7%A9%B6_amber99sb-ildn%E5%8A%9B%E5%9C%BA_jerkwin/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>《GROMACS教程_蛋白质配体复合物_Jerkwin》</title>
      <link>https://example.com/p/gromacs%E6%95%99%E7%A8%8B_%E8%9B%8B%E7%99%BD%E8%B4%A8%E9%85%8D%E4%BD%93%E5%A4%8D%E5%90%88%E7%89%A9_jerkwin/</link>
      <pubDate>Sun, 30 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gromacs%E6%95%99%E7%A8%8B_%E8%9B%8B%E7%99%BD%E8%B4%A8%E9%85%8D%E4%BD%93%E5%A4%8D%E5%90%88%E7%89%A9_jerkwin/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>《GROMACS文件类型_Jerkwin》</title>
      <link>https://example.com/p/gromacs%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B_jerkwin/</link>
      <pubDate>Sun, 30 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gromacs%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B_jerkwin/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>GROMACS教程_DPPC膜中的KALP_sub_15__sub__Jerkwin</title>
      <link>https://example.com/p/gromacs%E6%95%99%E7%A8%8B_dppc%E8%86%9C%E4%B8%AD%E7%9A%84kalp_sub_15__sub__jerkwin/</link>
      <pubDate>Sun, 30 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gromacs%E6%95%99%E7%A8%8B_dppc%E8%86%9C%E4%B8%AD%E7%9A%84kalp_sub_15__sub__jerkwin/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>GROMACS教程之水中的溶菌酶_Jerkwin</title>
      <link>https://example.com/p/gromacs%E6%95%99%E7%A8%8B%E4%B9%8B%E6%B0%B4%E4%B8%AD%E7%9A%84%E6%BA%B6%E8%8F%8C%E9%85%B6_jerkwin/</link>
      <pubDate>Sun, 30 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gromacs%E6%95%99%E7%A8%8B%E4%B9%8B%E6%B0%B4%E4%B8%AD%E7%9A%84%E6%BA%B6%E8%8F%8C%E9%85%B6_jerkwin/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>cannot import name &#39;cross_validation&#39; </title>
      <link>https://example.com/p/cannot-import-name-cross_validation/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/cannot-import-name-cross_validation/</guid>
      <description>想从 sklearn 包中导入模块 cross_validation，调用 cross_validation 里面别的函数，例如 交叉验证数据 使用到的 cross_val_score 函数，但是 from sklearn import cross_validation 运行报错 code:
from sklearn import corss_validation result:
--------------------------------------------------------------------------- ImportError Traceback (most recent call last) ~\AppData\Local\Temp/ipykernel_6408/3988079335.py in &amp;lt;module&amp;gt; ----&amp;gt; 1 from sklearn import corss_validation ImportError: cannot import name &amp;#39;corss_validation&amp;#39; from &amp;#39;sklearn&amp;#39; (F:\anaconda3\lib\site-packages\sklearn\__init__.py) 这是因为 sklearn 0.21.1 版本的已经移除 cross_validation 模块 从 sklearn.model_selection 模块直接导入 cross_val_score 即
from sklearn.model_selection import cross_val_score </description>
    </item>
    
    <item>
      <title>ccannot import name ‘cross_validation’ from ‘sklearn’ </title>
      <link>https://example.com/p/ccannot-import-name-cross_validation-from-sklearn/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ccannot-import-name-cross_validation-from-sklearn/</guid>
      <description>code:
from sklearn import cross_validation result:
--------------------------------------------------------------------------- ImportError Traceback (most recent call last) ~\AppData\Local\Temp/ipykernel_19376/266941855.py in &amp;lt;module&amp;gt; ----&amp;gt; 1 from sklearn import cross_validation ImportError: cannot import name &amp;#39;cross_validation&amp;#39; from &amp;#39;sklearn&amp;#39; (F:\anaconda3\lib\site-packages\sklearn\__init__.py) ‘cross_validation’ from ‘sklearn’”，后来百度才知道sklearn在0.18版本中，cross_validation被废弃了，原来在 cross_validation 里面的函数现在在 model_selection 里面，所以只要将cross_validation替换为model_selection就可以使用，数据信息都是一样的
from sklearn.model_selection import cross_validate </description>
    </item>
    
    <item>
      <title>No module named &#39;sklearn.datasets.samples_generator&#39;’ </title>
      <link>https://example.com/p/no-module-named-sklearn.datasets.samples_generator/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/no-module-named-sklearn.datasets.samples_generator/</guid>
      <description>code:
from sklearn.datasets.samples_generator import make_blobs result:
--------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) ~\AppData\Local\Temp/ipykernel_14680/1800722232.py in &amp;lt;module&amp;gt; ----&amp;gt; 1 from sklearn.datasets.samples_generator import make_blobs ModuleNotFoundError: No module named &amp;#39;sklearn.datasets.samples_generator&amp;#39; 新版的sklearn中改为了这种用法：
from sklearn.datasets import make_blobs </description>
    </item>
    
    <item>
      <title>No module named &#39;sklearn.grid_search&#39;</title>
      <link>https://example.com/p/no-module-named-sklearn.grid_search/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/no-module-named-sklearn.grid_search/</guid>
      <description>code:
from sklearn.grid_search import GridSearchCV result:
ModuleNotFoundError Traceback (most recent call last) ~\AppData\Local\Temp/ipykernel_7712/1716585072.py in &amp;lt;module&amp;gt; ----&amp;gt; 1 from sklearn.grid_search import GridSearchCV ModuleNotFoundError: No module named &amp;#39;sklearn.grid_search&amp;#39; 检查Scikit-Learn的版本conda list scikit-learn如果高于等于0.20说明是grid_search模块已被弃用。
改成这样了：
from sklearn.model_selection import GridSearchCV </description>
    </item>
    
    <item>
      <title>metrics.accuracy_score()计算分类的准确率</title>
      <link>https://example.com/p/metrics.accuracy_score%E8%AE%A1%E7%AE%97%E5%88%86%E7%B1%BB%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87/</link>
      <pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/metrics.accuracy_score%E8%AE%A1%E7%AE%97%E5%88%86%E7%B1%BB%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87/</guid>
      <description>sklearn中提供了计算准确率的accurccy_score函数 from sklearn import metrics metrics.accuracy_score? 输入参数：
y_true：真是标签。二分类和多分类情况下是一列，多标签情况下是标签的索引。
y_pred：预测标签。二分类和多分类情况下是一列，多标签情况下是标签的索引。
normalize:bool, optional (default=True)，如果是false，正确分类的样本的数目(int)；如果为true，返回正确分类的样本的比例，必须严格匹配真实数据集中的label，才为1，否则为0。
sample_weight：array-like of shape (n_samples,), default=None。Sample weights.
输出：
如果normalize == True,返回正确分类的样本的比例，否则返回正确分类的样本的数目(int)</description>
    </item>
    
    <item>
      <title>yield的作用</title>
      <link>https://example.com/p/yield%E7%9A%84%E4%BD%9C%E7%94%A8/</link>
      <pubDate>Tue, 25 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/yield%E7%9A%84%E4%BD%9C%E7%94%A8/</guid>
      <description>简介 python中，yield关键字的作用：1、将一个函数修改为生成器，利用生成器可以有效地节约系统资源，避免不必要的内存占用；2、用于定义上下文管理器；3、协程；4、配合from形成yield from用于消费子生成器并传递消息。
常见的情况 生成器 生成器函数（generation function） 和 生成器（generation） 生成器函数是一种特殊的函数，它的函数内部含有yield表达式，调用它会返回一个特殊的迭代器，称生成器。
具体情况 def foo(): print(&amp;#34;starting&amp;#34;) yield g = foo() g #&amp;lt;generator object foo at 0x000001B77CB6C350&amp;gt; #没有任何输出。这是因为有yield，函数并没有被执行。只是将foo()指向了g。 #函数2 def foo(): print(&amp;#34;starting&amp;#34;) yield 1 print(&amp;#34;ending&amp;#34;) g = foo() g #&amp;lt;generator object foo at 0x000001B77CB6C820&amp;gt; print(next(g)) #starting #1 print(next(g)) #ending #--------------------------------------------------------------------------- #StopIteration Traceback (most recent call last) #~\AppData\Local\Temp/ipykernel_22044/2604396719.py in &amp;lt;module&amp;gt; #----&amp;gt; 1 print(next(g)) #StopIteration: 运行：输出了starting和1，并没有输出ending，这是因为next(g)只调用了一次，运行到了yield就返回了，print函数打印了返回值：1。这个时候函数停止了，等待下一次的next(g)调用。 迭代器是一个对象，这种对象每次只能调取一个数据元素。对迭代器不断调用 next() 方法（将迭代起变量放入next()中当参数），则可以依次获取下一个元素；当迭代器中没有元素时，调用 next() 方法会抛出 StopIteration（停止迭代） 异常。迭代器的 iter() 方法返回迭代器自身；因此迭代器也是可迭代的。 运行：接着上面的，第二个next(g)运行，报错是因为遍历结束了，无yield了。解决方法就是在最好加一个yield。</description>
    </item>
    
    <item>
      <title>GMX10ppt_分析概讲</title>
      <link>https://example.com/p/gmx10ppt_%E5%88%86%E6%9E%90%E6%A6%82%E8%AE%B2/</link>
      <pubDate>Mon, 24 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gmx10ppt_%E5%88%86%E6%9E%90%E6%A6%82%E8%AE%B2/</guid>
      <description>此post用来存放一些ppt上的内容，仅方便学习用途
这里就放了100个分析的命令（看手册）</description>
    </item>
    
    <item>
      <title>GMX7ppt_简单建模</title>
      <link>https://example.com/p/gmx7ppt_%E7%AE%80%E5%8D%95%E5%BB%BA%E6%A8%A1/</link>
      <pubDate>Mon, 24 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gmx7ppt_%E7%AE%80%E5%8D%95%E5%BB%BA%E6%A8%A1/</guid>
      <description>此post用来存放一些ppt上的内容，仅方便学习用途
高斯这里的教程我跳过了。。</description>
    </item>
    
    <item>
      <title>GMX8ppt_标准残基甲基化</title>
      <link>https://example.com/p/gmx8ppt_%E6%A0%87%E5%87%86%E6%AE%8B%E5%9F%BA%E7%94%B2%E5%9F%BA%E5%8C%96/</link>
      <pubDate>Mon, 24 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gmx8ppt_%E6%A0%87%E5%87%86%E6%AE%8B%E5%9F%BA%E7%94%B2%E5%9F%BA%E5%8C%96/</guid>
      <description>此post用来存放一些ppt上的内容，仅方便学习用途</description>
    </item>
    
    <item>
      <title>GMX9ppt_非标准残基</title>
      <link>https://example.com/p/gmx9ppt_%E9%9D%9E%E6%A0%87%E5%87%86%E6%AE%8B%E5%9F%BA/</link>
      <pubDate>Mon, 24 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gmx9ppt_%E9%9D%9E%E6%A0%87%E5%87%86%E6%AE%8B%E5%9F%BA/</guid>
      <description> 此post用来存放一些ppt上的内容，仅方便学习用途
top删除了（每一部分属性中的都只保留残基的）
第一行的那个删除了
JSMOL
TPPMKTOP </description>
    </item>
    
    <item>
      <title>GMX6ppt_蛋白模拟</title>
      <link>https://example.com/p/gmx6ppt_%E8%9B%8B%E7%99%BD%E6%A8%A1%E6%8B%9F/</link>
      <pubDate>Sun, 23 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gmx6ppt_%E8%9B%8B%E7%99%BD%E6%A8%A1%E6%8B%9F/</guid>
      <description>此post用来存放一些ppt上的内容，仅方便学习用途
rtp文件 原子缺失 spdbv可以去补充缺失的原子
残基突变
真空中的模拟 （NVT平衡）
xtc和gro可以看轨迹运动
加溶剂</description>
    </item>
    
    <item>
      <title>collections的namedtuple命名元组知识</title>
      <link>https://example.com/p/collections%E7%9A%84namedtuple%E5%91%BD%E5%90%8D%E5%85%83%E7%BB%84%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/collections%E7%9A%84namedtuple%E5%91%BD%E5%90%8D%E5%85%83%E7%BB%84%E7%9F%A5%E8%AF%86/</guid>
      <description>collections的namedtuple使用 元组中的元素值是不能被更改的，由于元组不像字典那样可以为内部的元素命名，因此我们并不知道元组内的元素所表达的意义，在访问元组的时候也只能通过索引访问其中的元素。 于是Python标准库collections引入了namedtuple函数，它可以创建一个和元组类似但更为强大的类型——具名元组（namedtuple），也就是构造一个带字段名的元组
基础语法 #导入 from collections import namedtuple #创建一个namedtuple对象 collections.namedtuple(typename=&amp;#34;&amp;#34;, field_names=[&amp;#34;&amp;#34;], *, verbose=False, rename=False, module=None) 参数说明 1.typename: 创建的元组名称，实际上是赋予对象类名，看后面的例子就知道了
2.field_names:新创建的元组中的元素名称，可以类比与字典的key，这就是为什么可以通过键值去命名元组创建新或者取出已有元素的原因了 ；可以[&amp;ldquo;key1&amp;rdquo;,&amp;ldquo;key2&amp;rdquo;]或者空格隔开的形式&amp;quot;key1 key2&amp;quot;
3.rename:为True时，不能不能包含有非Python标识符、Python中的关键字以及重复的name，如果有则会默认重命名成_index的形式，如&amp;quot;def abc&amp;quot;变成&amp;quot;_0 abc&amp;quot;
简单的用法 1.创建好后可以通过实例化，直接传值
2.可以通过index或者key访问value
3.fields:可以访问指定namedtuple的所有键值名
4.make：可以以list的方式赋值，与1略不同
5.asdict:可以将namedtuple转为字典对象
具体例子 code:
#创建一个namedtuple对象,并实例化 tmp = namedtuple(&amp;#34;test&amp;#34;,[&amp;#34;id&amp;#34;,&amp;#34;name&amp;#34;,&amp;#34;word&amp;#34;]) #直接赋值 tmp1 = tmp(&amp;#34;0&amp;#34;,&amp;#34;yeyuhao&amp;#34;,&amp;#34;hahaha&amp;#34;) #make赋值 tmp2 = tmp._make([&amp;#34;1&amp;#34;,&amp;#34;miles&amp;#34;,&amp;#34;hehehe&amp;#34;]) print(tmp1) print(tmp2) print(&amp;#34;---------分割线-------------&amp;#34;) #index取值 print(tmp1[1]) #key取值 print(tmp1.name) #fileds返回所有key print(tmp1._fields)#不用加（） #转字典 print(tmp2._asdict()) result:
test(id=&amp;#39;0&amp;#39;, name=&amp;#39;yeyuhao&amp;#39;, word=&amp;#39;hahaha&amp;#39;) test(id=&amp;#39;1&amp;#39;, name=&amp;#39;miles&amp;#39;, word=&amp;#39;hehehe&amp;#39;) ---------分割线------------- yeyuhao yeyuhao (&amp;#39;id&amp;#39;, &amp;#39;name&amp;#39;, &amp;#39;word&amp;#39;) {&amp;#39;id&amp;#39;: &amp;#39;1&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;miles&amp;#39;, &amp;#39;word&amp;#39;: &amp;#39;hehehe&amp;#39;} </description>
    </item>
    
    <item>
      <title>GMX1ppt_基本概念ppt整理</title>
      <link>https://example.com/p/gmx1ppt_%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5ppt%E6%95%B4%E7%90%86/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gmx1ppt_%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5ppt%E6%95%B4%E7%90%86/</guid>
      <description> 此post用来存放一些ppt上的内容，仅方便学习用途
时间尺度与研究方法 注意下复杂性的问题. 空间尺度越小，研究尺度也就越小（就是说空间尺度越小呢，它在单位时间内跑的距离就越小）. 上面说是分子上的，现在我们关心的是蛋白上的，来说说蛋白运动的时间尺度问题
氢键之类的那些跑到fs就可以看见了，但是蛋白那些至少要到ns才能看见
相关概念 分子模拟 力场 成键相互作用 库仑力 VDW范德华力 L-J势能曲线 Buckingham势能曲线 1-4相互作用 粒子的运动 PBC 系综 初始速度 MD基本算法流程 VDM截断 库伦Ewald 预平衡 EM EM最小点 梯度下降-最陡下降 梯度下降-共轭梯度法 梯度下降 L-BFGC法 理论书籍推荐 问题部分： 这个就是pbc </description>
    </item>
    
    <item>
      <title>GMX2ppt_基本配置说明</title>
      <link>https://example.com/p/gmx2ppt_%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gmx2ppt_%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/</guid>
      <description> 此post用来存放一些ppt上的内容，仅方便学习用途
这里实际上开始讲的就是运行环境的配置
PATH配置 xplorer2 msys2 可能要自己去编译配置下
Notepad2 xplore中也要修改
GMX2019 amber VMD spdbv4 Gview分子编辑 qtgrace APBS1.5 irfanview+pymol Jmol gunplot </description>
    </item>
    
    <item>
      <title>GMX3ppt_mdp文件</title>
      <link>https://example.com/p/gmx3ppt_mdp%E6%96%87%E4%BB%B6/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gmx3ppt_mdp%E6%96%87%E4%BB%B6/</guid>
      <description>此post用来存放一些ppt上的内容，仅方便学习用途
这些参数去手册上找（2019版本的）</description>
    </item>
    
    <item>
      <title>GMX4ppt_Notepad使用</title>
      <link>https://example.com/p/gmx4ppt_notepad%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gmx4ppt_notepad%E4%BD%BF%E7%94%A8/</guid>
      <description> 此post用来存放一些ppt上的内容，仅方便学习用途
alt + shfit 可以选中列
文件选择框
编码的问题？ 一般建议用这个字体~ </description>
    </item>
    
    <item>
      <title>GMX5ppt_GROMACS入门</title>
      <link>https://example.com/p/gmx5ppt_gromacs%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gmx5ppt_gromacs%E5%85%A5%E9%97%A8/</guid>
      <description> 此post用来存放一些ppt上的内容，仅方便学习用途
gmx dump命令 其他的例子也是 尿素的问题 Qtgrade </description>
    </item>
    
    <item>
      <title>collection.Counter()计数的使用</title>
      <link>https://example.com/p/collection.counter%E8%AE%A1%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Fri, 21 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/collection.counter%E8%AE%A1%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      <description>collection.Counter()的方法，可以将传入的对象的出现次数返回来，
Counter() 以字典的形式返回，数：出现次数 Counter().items() 以元组的形式返回，按数在传入的顺序中的顺序 （数：出现次数） Counter().keys() 以list的整体返回，数 Counter().values() 以list的整体返回，出现次数 code:
from collections import Counter list_test = [2,7,4,5,6,0,6,6,6,4] Counter(list_test) result:
Counter({2: 1, 7: 1, 4: 2, 5: 1, 6: 4, 0: 1}) code:
Counter(list_test).items() result:
dict_items([(2, 1), (7, 1), (4, 2), (5, 1), (6, 4), (0, 1)]) code:
Counter(list_test)[6] result:
4 code:
Counter(list_test).keys() result:
dict_keys([2, 7, 4, 5, 6, 0]) code:
Counter(list_test).values() result:
dict_values([1, 1, 2, 1, 4, 1]) </description>
    </item>
    
    <item>
      <title>argparse参数个性化的用法整理</title>
      <link>https://example.com/p/argparse%E5%8F%82%E6%95%B0%E4%B8%AA%E6%80%A7%E5%8C%96%E7%9A%84%E7%94%A8%E6%B3%95%E6%95%B4%E7%90%86/</link>
      <pubDate>Thu, 20 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/argparse%E5%8F%82%E6%95%B0%E4%B8%AA%E6%80%A7%E5%8C%96%E7%9A%84%E7%94%A8%E6%B3%95%E6%95%B4%E7%90%86/</guid>
      <description>整理 下关于 argparse的用法，主要用于参数提示
#coding=utf-8 import argparse from ast import Store, parse from cgi import test from email import parser from itertools import count from pydoc import describe from ssl import ALERT_DESCRIPTION_UNEXPECTED_MESSAGE from this import s from tokenize import group from turtle import Turtle import turtle from numpy import False_ 使用前要实例化一个ArgumentParser对象
parser = argparse.ArgumentParser(description=&amp;#34;这是ArugementParser中的description&amp;#34;) parser.parse_args() 这上面当你运行
python test.py -h 注意要加上-h参数，就是出现主要的decsription中的str
parser = argparse.ArgumentParser() parser.add_argument(&amp;#34;test&amp;#34;) args = parser.parse_args() print(&amp;#34;输出的内容是%s&amp;#34; % args.test) 这个其实就是添加了cmd中一个位置，将获取到的值存入到test这个变量中 要取变量的值先通过parse_args()获取到args对象</description>
    </item>
    
    <item>
      <title>Python对axis的理解</title>
      <link>https://example.com/p/python%E5%AF%B9axis%E7%9A%84%E7%90%86%E8%A7%A3/</link>
      <pubDate>Tue, 18 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/python%E5%AF%B9axis%E7%9A%84%E7%90%86%E8%A7%A3/</guid>
      <description>千万不要用行和列的思维去想axis，因为行和列是没有方向的，这样想会在遇到不同的例子时感到困惑。
二维的理解 轴用来为超过一维的数组定义的属性，二维数据拥有两个轴：第0轴沿着行的垂直往下，第1轴沿着列的方向水平延伸。 注意看，官方对于0和1的解释是轴，也就是坐标轴。而坐标轴是有方向的，所以千万不要用行和列的思维去想axis，因为行和列是没有方向的，这样想会在遇到不同的例子时感到困惑。
根据官方的说法，1表示横轴，方向从左到右；0表示纵轴，方向从上到下。当axis=1时，数组的变化是横向的，而体现出来的是列的增加或者减少。
其实axis的重点在于方向，而不是行和列。具体到各种用法而言也是如此。当axis=1时，如果是求平均，那么是从左到右横向求平均；如果是拼接，那么也是左右横向拼接；如果是drop，那么也是横向发生变化，体现为列的减少。
当考虑了方向，即axis=1为横向，axis=0为纵向，而不是行和列，那么所有的例子就都统一了。
code:
import numpy as np a = np.array([[1,2,3],[4,5,6]]) a result:
array([[1, 2, 3], [4, 5, 6]]) code:
a.sum(axis=0) result:
array([5, 7, 9]) code:
a.sum(axis=1) result:
array([ 6, 15]) code:
a.sum(axis=-1) result:
array([ 6, 15]) 高维的理解 这里解释一下三维，更高维也就都能理解了 地址：https://www.jianshu.com/p/93317c0dca6a
什么意思呢？就是比如：
当axis=0时，此时就时要找除了第一个下标，其他下标相同的放在一起，比如a000、a100、a200这个为一组，a001、a101、a201为一组&amp;hellip;. 最终为(4，5) 当axis=1时，此时就时要找除了第二个下标，其他下标相同的放在一起，比如a000、a010、a020、a030 这个为一组，a001、a011、a021、a031为一组&amp;hellip;.（3，5）
当axis=-1（即为2时，解释下-1是什么，是找到最近的一个数，因为我们这里的下标就只有axxx，三位即0，1，2所以-1即为axis=2 a000,a001,a002,a003为一组。。。。 (3,4) image.png 总的来说就是 先分组处理，再根据要求合并</description>
    </item>
    
    <item>
      <title>pprint.pformat数据读写</title>
      <link>https://example.com/p/pprint.pformat%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99/</link>
      <pubDate>Sat, 15 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pprint.pformat%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99/</guid>
      <description>pprint.pprint和 pprint.pformat 实现数据读写功能 pprint模块中使用的格式化可以按照一种格式正确的显示数据, 这种格式即可被解析器解析, 又很易读. 输出保存在一个单行内, 但如果有必要, 在分割多行数据时也可使用缩进表示.
Python 的 pprint.pformat() 函数会以字符串形式，返回列表或字典中的内容。可以将其保存为一个 py 文件，以便将来读取使用
具体例子 pprint的美化 code:
#导入包 import pprint data_test = { &amp;#34;a&amp;#34;:{&amp;#34;1&amp;#34;:&amp;#34;dsad&amp;#34;,&amp;#34;2&amp;#34;:&amp;#34;hehehee&amp;#34;}, &amp;#34;b&amp;#34;:{&amp;#34;3&amp;#34;:&amp;#34;fdsff&amp;#34;,&amp;#34;4&amp;#34;:&amp;#34;rtdfd&amp;#34;,&amp;#39;f&amp;#39;: &amp;#39;F&amp;#39;, &amp;#39;g&amp;#39;: &amp;#39;G&amp;#39;, &amp;#39;h&amp;#39;: &amp;#39;H&amp;#39;}, &amp;#34;c&amp;#34;:{&amp;#39;e&amp;#39;: &amp;#39;E&amp;#39;, &amp;#39;f&amp;#39;: &amp;#39;F&amp;#39;, &amp;#39;g&amp;#39;: &amp;#39;G&amp;#39;, &amp;#39;h&amp;#39;: &amp;#39;H&amp;#39;,&amp;#39;i&amp;#39;: &amp;#39;I&amp;#39;, &amp;#39;j&amp;#39;: &amp;#39;J&amp;#39;, &amp;#39;k&amp;#39;: &amp;#39;K&amp;#39;, &amp;#39;l&amp;#39;: &amp;#39;L&amp;#39;} } print(data_test) print(&amp;#34;美化后&amp;#34;) #当元素超过大于等于8，才会真正展现pprint的美化用处 #具体来说就是每个行占据一个元素对象全部数据或者竖列展示 pprint.pprint(data_test) result:
{&amp;#39;a&amp;#39;: {&amp;#39;1&amp;#39;: &amp;#39;dsad&amp;#39;, &amp;#39;2&amp;#39;: &amp;#39;hehehee&amp;#39;}, &amp;#39;b&amp;#39;: {&amp;#39;3&amp;#39;: &amp;#39;fdsff&amp;#39;, &amp;#39;4&amp;#39;: &amp;#39;rtdfd&amp;#39;, &amp;#39;f&amp;#39;: &amp;#39;F&amp;#39;, &amp;#39;g&amp;#39;: &amp;#39;G&amp;#39;, &amp;#39;h&amp;#39;: &amp;#39;H&amp;#39;}, &amp;#39;c&amp;#39;: {&amp;#39;e&amp;#39;: &amp;#39;E&amp;#39;, &amp;#39;f&amp;#39;: &amp;#39;F&amp;#39;, &amp;#39;g&amp;#39;: &amp;#39;G&amp;#39;, &amp;#39;h&amp;#39;: &amp;#39;H&amp;#39;, &amp;#39;i&amp;#39;: &amp;#39;I&amp;#39;, &amp;#39;j&amp;#39;: &amp;#39;J&amp;#39;, &amp;#39;k&amp;#39;: &amp;#39;K&amp;#39;, &amp;#39;l&amp;#39;: &amp;#39;L&amp;#39;}} 美化后 {&amp;#39;a&amp;#39;: {&amp;#39;1&amp;#39;: &amp;#39;dsad&amp;#39;, &amp;#39;2&amp;#39;: &amp;#39;hehehee&amp;#39;}, &amp;#39;b&amp;#39;: {&amp;#39;3&amp;#39;: &amp;#39;fdsff&amp;#39;, &amp;#39;4&amp;#39;: &amp;#39;rtdfd&amp;#39;, &amp;#39;f&amp;#39;: &amp;#39;F&amp;#39;, &amp;#39;g&amp;#39;: &amp;#39;G&amp;#39;, &amp;#39;h&amp;#39;: &amp;#39;H&amp;#39;}, &amp;#39;c&amp;#39;: {&amp;#39;e&amp;#39;: &amp;#39;E&amp;#39;, &amp;#39;f&amp;#39;: &amp;#39;F&amp;#39;, &amp;#39;g&amp;#39;: &amp;#39;G&amp;#39;, &amp;#39;h&amp;#39;: &amp;#39;H&amp;#39;, &amp;#39;i&amp;#39;: &amp;#39;I&amp;#39;, &amp;#39;j&amp;#39;: &amp;#39;J&amp;#39;, &amp;#39;k&amp;#39;: &amp;#39;K&amp;#39;, &amp;#39;l&amp;#39;: &amp;#39;L&amp;#39;}} ppformat保存作用 code</description>
    </item>
    
    <item>
      <title>env添加到Jupyter中</title>
      <link>https://example.com/p/env%E6%B7%BB%E5%8A%A0%E5%88%B0jupyter%E4%B8%AD/</link>
      <pubDate>Thu, 13 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/env%E6%B7%BB%E5%8A%A0%E5%88%B0jupyter%E4%B8%AD/</guid>
      <description>将Python虚拟环境添加到Jupyter Notebook中
将利用conda自定义的python虚拟环境添加到jupyter notebook中
在activate env后运行(安装ipkernel)
conda install ipkernel 添加到Jupyter
python -m ipkernel install --name env名字 最后重启Jupyter即可</description>
    </item>
    
    <item>
      <title>Macromolecular Modeling with Rosetta</title>
      <link>https://example.com/p/macromolecular-modeling-with-rosetta/</link>
      <pubDate>Wed, 12 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/macromolecular-modeling-with-rosetta/</guid>
      <description>Macromolecular Modeling with Rosetta
link:https://www.annualreviews.org/doi/abs/10.1146/annurev.biochem.77.062906.171838</description>
    </item>
    
    <item>
      <title>ROSETTALIGAND Docking with Full Ligand and Receptor Flexibility </title>
      <link>https://example.com/p/rosettaligand-docking-with-full-ligand-and-receptor-flexibility/</link>
      <pubDate>Wed, 12 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/rosettaligand-docking-with-full-ligand-and-receptor-flexibility/</guid>
      <description>ROSETTALIGAND Docking with Full Ligand and Receptor Flexibility
link:https://www.sciencedirect.com/science/article/abs/pii/S0022283608014289</description>
    </item>
    
    <item>
      <title>&#39;GridSearchCV&#39; object has no attribute &#39;grid_scores_&#39;</title>
      <link>https://example.com/p/gridsearchcv-object-has-no-attribute-grid_scores_/</link>
      <pubDate>Tue, 11 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gridsearchcv-object-has-no-attribute-grid_scores_/</guid>
      <description>原因在于grid_scores_在sklearn0.20版本中已被删除，取而代之的是cv_results_</description>
    </item>
    
    <item>
      <title>《深度学习入门：基于Python的理论与实现》高清中文版</title>
      <link>https://example.com/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E5%9F%BA%E4%BA%8Epython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%B8%85%E4%B8%AD%E6%96%87%E7%89%88/</link>
      <pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E5%9F%BA%E4%BA%8Epython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%B8%85%E4%B8%AD%E6%96%87%E7%89%88/</guid>
      <description>! </description>
    </item>
    
    <item>
      <title>Anaconda创建env环境</title>
      <link>https://example.com/p/anaconda%E5%88%9B%E5%BB%BAenv%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/anaconda%E5%88%9B%E5%BB%BAenv%E7%8E%AF%E5%A2%83/</guid>
      <description>这里记录下anaconda常用的命名
1.创建虚拟环境
conda create -n 虚拟环境env的名字 python=X.X(可选)
或者同时安装一些包
conda create -n 虚拟环境env的名字 numpy pandas(等包名) python=X.X(可选)
2.激活虚拟环境
Linux: source activate env名字
Window: activate env名字
3.退出虚拟环境
Linux: source deactivate env名字
Window：deactivate env名字
4.删除虚拟环境
删除整个环境
conda remove -n env名字 &amp;ndash;all
删除环境中的某个包
conda remove -n env名字 包名
5.其他
查看安装了哪些包
conda list
安装包
conda install
查看当前存在哪些env
conda env list
检查更新当前conda
conda update conda</description>
    </item>
    
    <item>
      <title>使用Image在notebook中展示图片</title>
      <link>https://example.com/p/%E4%BD%BF%E7%94%A8image%E5%9C%A8notebook%E4%B8%AD%E5%B1%95%E7%A4%BA%E5%9B%BE%E7%89%87/</link>
      <pubDate>Thu, 06 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E4%BD%BF%E7%94%A8image%E5%9C%A8notebook%E4%B8%AD%E5%B1%95%E7%A4%BA%E5%9B%BE%E7%89%87/</guid>
      <description>#从Ipython.display 导入 Image from IPython.display import Image Image(&amp;#34;./47ce630c275ddfe89fa3c49ffaa767ce.jpg&amp;#34;) 可以使用个循环去封装，但是此时Image前记得加上display 即写成display(Image())</description>
    </item>
    
    <item>
      <title>到底什么是句柄</title>
      <link>https://example.com/p/%E5%88%B0%E5%BA%95%E4%BB%80%E4%B9%88%E6%98%AF%E5%8F%A5%E6%9F%84/</link>
      <pubDate>Thu, 06 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%B0%E5%BA%95%E4%BB%80%E4%B9%88%E6%98%AF%E5%8F%A5%E6%9F%84/</guid>
      <description>一般说来，你可以把句柄想象成一个对文本信息的“封装”。 相比普通文本信息，使用句柄至少有两个好处：
对于以不同方式存储的信息，句柄提供了一个标准的处理方法。这些文本信息可能来自文件、内存中的一个字符串、命令行指令的输出或者来自于远程网站信息，但是句柄提供了一种通用的方式处理这些不同格式和来源的文本信息。 句柄可以依次读取文本信息，而不是一次读取所有信息。这点在处理超大文件时尤为有用，因为一次载入一个大文件可能会占去你所有的内存。 不论是从文件读取文本信息还是将文本信息写入文件，句柄都能胜任。在读取文件时，常用的函数有 read() 和 readline() , 前者可以通过句柄读取所有文本信息，而后者则每次读取一行；对于文本信息的写入，则通常使用 write() 函数。 句柄最常见的使用就是从文件读取信息，这可以通过Python内置函数 open 来完成。 下面示例中，我们打开一个指向文件 m_cold.fasta （可通过网址 http://biopython.org/DIST/docs/tutorial/examples/m_cold.fasta 获取）的句柄：
&amp;gt;&amp;gt;&amp;gt; handle = open(&amp;#34;m_cold.fasta&amp;#34;, &amp;#34;r&amp;#34;) &amp;gt;&amp;gt;&amp;gt; handle.readline() &amp;#34;&amp;gt;gi|8332116|gb|BE037100.1|BE037100 MP14H09 MP Mesembryanthemum ...\n&amp;#34; Biopython中句柄常用来向解析器（parsers）传递信息。比如说，自Biopython1.54版本后， Bio.SeqIO 和 Bio.AlignIO 模块中的主要函数都可以使用文件名来代替句柄使用：
from Bio import SeqIO for record in SeqIO.parse(&amp;#34;m_cold.fasta&amp;#34;, &amp;#34;fasta&amp;#34;): print record.id, len(record) 在比较早的BioPython版本中，必须使用句柄：
from Bio import SeqIO handle = open(&amp;#34;m_cold.fasta&amp;#34;, &amp;#34;r&amp;#34;) for record in SeqIO.parse(handle, &amp;#34;fasta&amp;#34;): print record.id, len(record) handle.close() 这种操作方式仍有其用武之地，比如在解析一个gzip压缩的FASTA文件中：
import gzip from Bio import SeqIO handle = gzip.</description>
    </item>
    
    <item>
      <title>Learned protein embeddings for machine learning</title>
      <link>https://example.com/p/learned-protein-embeddings-for-machine-learning/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/learned-protein-embeddings-for-machine-learning/</guid>
      <description>理解蛋白质序列在机器学习模型的编码 link:https://academic.oup.com/bioinformatics/article/34/15/2642/4951834</description>
    </item>
    
    <item>
      <title>if__name__==___main___的作用</title>
      <link>https://example.com/p/if__name_____main___%E7%9A%84%E4%BD%9C%E7%94%A8/</link>
      <pubDate>Sun, 02 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/if__name_____main___%E7%9A%84%E4%BD%9C%E7%94%A8/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>机器学习助力酶定向进化</title>
      <link>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A9%E5%8A%9B%E9%85%B6%E5%AE%9A%E5%90%91%E8%BF%9B%E5%8C%96/</link>
      <pubDate>Wed, 29 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A9%E5%8A%9B%E9%85%B6%E5%AE%9A%E5%90%91%E8%BF%9B%E5%8C%96/</guid>
      <description>机器学习助力酶定向进化 link:http://www.cqvip.com/qk/92127x/202004/7102480996.html</description>
    </item>
    
    <item>
      <title>《百面机器学习_算法工程师带你去面试》</title>
      <link>https://example.com/p/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%B8%A6%E4%BD%A0%E5%8E%BB%E9%9D%A2%E8%AF%95/</link>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%B8%A6%E4%BD%A0%E5%8E%BB%E9%9D%A2%E8%AF%95/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>numpy基础练习13_Statistics</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A013_statistics/</link>
      <pubDate>Tue, 21 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A013_statistics/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
__author__ = &amp;#34;kyubyong. kbpark.linguist@gmail.com&amp;#34; import numpy as np np.__version__ &amp;#39;1.11.3&amp;#39; Order statistics Q1. Return the minimum value of x along the second axis.
x = np.arange(4).reshape((2, 2)) print(&amp;#34;x=\n&amp;#34;, x) print(&amp;#34;ans=\n&amp;#34;, np.amin(x, 1)) x= [[0 1] [2 3]] ans= [0 2] Q2. Return the maximum value of x along the second axis. Reduce the second axis to the dimension with size one.
x = np.arange(4).reshape((2, 2)) print(&amp;#34;x=\n&amp;#34;, x) print(&amp;#34;ans=\n&amp;#34;, np.</description>
    </item>
    
    <item>
      <title>numpy基础练习12_Soring, searching, and counting</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A012_soring-searching-and-counting/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A012_soring-searching-and-counting/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
import numpy as np np.__version__ &amp;#39;1.11.2&amp;#39; author = &amp;#39;kyubyong. longinglove@nate.com&amp;#39; Sorting Q1. Sort x along the second axis.
x = np.array([[1,4],[3,1]]) out = np.sort(x, axis=1) x.sort(axis=1) assert np.array_equal(out, x) print out [[1 4] [1 3]] Q2. Sort pairs of surnames and first names and return their indices. (first by surname, then by name).
surnames = (&amp;#39;Hertz&amp;#39;, &amp;#39;Galilei&amp;#39;, &amp;#39;Hertz&amp;#39;) first_names = (&amp;#39;Heinrich&amp;#39;, &amp;#39;Galileo&amp;#39;, &amp;#39;Gustav&amp;#39;) print np.lexsort((first_names, surnames)) [1 2 0] Q3.</description>
    </item>
    
    <item>
      <title>numpy基础练习10_Random Sampling</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A010_random-sampling/</link>
      <pubDate>Sun, 19 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A010_random-sampling/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
import numpy as np np.__version__ &amp;#39;1.11.2&amp;#39; __author__ = &amp;#39;kyubyong. longinglove@nate.com&amp;#39; Simple random data Q1. Create an array of shape (3, 2) and populate it with random samples from a uniform distribution over [0, 1).
np.random.rand(3, 2) # Or np.random.random((3,2)) array([[ 0.13879034, 0.71300174], [ 0.08121322, 0.00393554], [ 0.02349471, 0.56677474]]) Q2. Create an array of shape (1000, 1000) and populate it with random samples from a standard normal distribution. And verify that the mean and standard deviation is close enough to 0 and 1 repectively.</description>
    </item>
    
    <item>
      <title>numpy基础练习11_Set routines</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A011_set-routines/</link>
      <pubDate>Sun, 19 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A011_set-routines/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
import numpy as np np.__version__ &amp;#39;1.11.2&amp;#39; author = &amp;#39;kyubyong. longinglove@nate.com&amp;#39; Making proper sets Q1. Get unique elements and reconstruction indices from x. And reconstruct x.
x = np.array([1, 2, 6, 4, 2, 3, 2]) out, indices = np.unique(x, return_inverse=True) print &amp;#34;unique elements =&amp;#34;, out print &amp;#34;reconstruction indices =&amp;#34;, indices print &amp;#34;reconstructed =&amp;#34;, out[indices] unique elements = [1 2 3 4 6] reconstruction indices = [0 1 4 3 1 2 1] reconstructed = [1 2 6 4 2 3 2] Boolean operations Q2.</description>
    </item>
    
    <item>
      <title>numpy基础练习9_Mathematical functions</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A09_mathematical-functions/</link>
      <pubDate>Sun, 19 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A09_mathematical-functions/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
import numpy as np np.__version__ &amp;#39;1.11.2&amp;#39; __author__ = &amp;#34;kyubyong. kbpark.linguist@gmail.com. https://github.com/kyubyong&amp;#34; Trigonometric functions Q1. Calculate sine, cosine, and tangent of x, element-wise.
x = np.array([0., 1., 30, 90]) print &amp;#34;sine:&amp;#34;, np.sin(x) print &amp;#34;cosine:&amp;#34;, np.cos(x) print &amp;#34;tangent:&amp;#34;, np.tan(x) sine: [ 0. 0.84147098 -0.98803162 0.89399666] cosine: [ 1. 0.54030231 0.15425145 -0.44807362] tangent: [ 0. 1.55740772 -6.4053312 -1.99520041] Q2. Calculate inverse sine, inverse cosine, and inverse tangent of x, element-wise.
x = np.</description>
    </item>
    
    <item>
      <title>numpy基础练习7_number</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A07_number/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A07_number/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
from __future__ import print_function import numpy as np import matplotlib.pyplot as plt %matplotlib inline from datetime import date date.today() datetime.date(2017, 11, 2) author = &amp;#34;kyubyong. https://github.com/Kyubyong/numpy_exercises&amp;#34; np.__version__ &amp;#39;1.13.1&amp;#39; Complex Numbers Q1. Return the angle of a in radian.
a = 1+1j output = np.angle(a, deg=False) print(output) 0.785398163397 Q2. Return the real part and imaginary part of a.
a = np.array([1+2j, 3+4j, 5+6j]) real = a.real imag = a.imag print(&amp;#34;real part=&amp;#34;, real) print(&amp;#34;imaginary part=&amp;#34;, imag) real part= [ 1.</description>
    </item>
    
    <item>
      <title>numpy基础练习8_Logic functions</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A08_logic-functions/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A08_logic-functions/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
import numpy as np np.__version__ &amp;#39;1.11.2&amp;#39; Truth value testing Q1. Let x be an arbitrary array. Return True if none of the elements of x is zero. Remind that 0 evaluates to False in python.
x = np.array([1,2,3]) print np.all(x) x = np.array([1,0,3]) print np.all(x) True False Q2. Let x be an arbitrary array. Return True if any of the elements of x is non-zero.
x = np.array([1,0,0]) print np.</description>
    </item>
    
    <item>
      <title>python中的append和expend</title>
      <link>https://example.com/p/python%E4%B8%AD%E7%9A%84append%E5%92%8Cexpend/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/python%E4%B8%AD%E7%9A%84append%E5%92%8Cexpend/</guid>
      <description>code:
test = [1,2,3,4] test_go = [6,6,6] test.append(test_go) test result:
[1, 2, 3, 4, [6, 6, 6]] code:
len(test) result:
5 可以看出append(a)，会将a作为一个大整体传入
code:
test = [1,2,3,4] test_go = [6,6,6] test.extend(test_go) test result:
[1, 2, 3, 4, 6, 6, 6] code:
len(test) result:
7 但是，可以看出extend(a)，会将a中的一个一个元素去取出融合到要extend的对象中</description>
    </item>
    
    <item>
      <title>numpy基础练习6_Linear algebra</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A06_linear-algebra/</link>
      <pubDate>Fri, 17 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A06_linear-algebra/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
import numpy as np np.__version__ &amp;#39;1.11.2&amp;#39; Matrix and vector products Q1. Predict the results of the following code.
x = [1,2] y = [[4, 1], [2, 2]] print np.dot(x, y) print np.dot(y, x) print np.matmul(x, y) print np.inner(x, y) print np.inner(y, x) [8 5] [6 6] [8 5] [6 6] [6 6] Q2. Predict the results of the following code.
x = [[1, 0], [0, 1]] y = [[4, 1], [2, 2], [1, 1]] print np.</description>
    </item>
    
    <item>
      <title>numpy基础练习5_Input and Output</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A05_input-and-output/</link>
      <pubDate>Thu, 16 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A05_input-and-output/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
from __future__ import print_function import numpy as np author = &amp;#34;kyubyong. https://github.com/Kyubyong/numpy_exercises&amp;#34; np.__version__ &amp;#39;1.12.0&amp;#39; from datetime import date print(date.today()) 2017-04-01 NumPy binary files (NPY, NPZ) Q1. Save x into temp.npy and load it.
x = np.arange(10) np.save(&amp;#39;temp.npy&amp;#39;, x) # Actually you can omit the extension. If so, it will be added automatically. # Check if there exists the &amp;#39;temp.npy&amp;#39; file. import os if os.path.exists(&amp;#39;temp.npy&amp;#39;): x2 = np.load(&amp;#39;temp.npy&amp;#39;) print(np.array_equal(x, x2)) True Q2.</description>
    </item>
    
    <item>
      <title>numpy基础练习4_info</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A04_info/</link>
      <pubDate>Wed, 15 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A04_info/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
import numpy as np np.__version__ &amp;#39;1.11.2&amp;#39; Q1. Search for docstrings of the numpy functions on linear algebra.
np.lookfor(&amp;#39;linear algebra&amp;#39;) Search results for &amp;#39;linear algebra&amp;#39; ----------------------------------- numpy.linalg.solve Solve a linear matrix equation, or system of linear scalar equations. numpy.poly Find the coefficients of a polynomial with the given sequence of roots. numpy.restoredot Restore `dot`, `vdot`, and `innerproduct` to the default non-BLAS numpy.linalg.eig Compute the eigenvalues and right eigenvectors of a square array.</description>
    </item>
    
    <item>
      <title>numpy基础练习3_String</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A03_string/</link>
      <pubDate>Tue, 14 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A03_string/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
String operations from __future__ import print_function import numpy as np author = &amp;#34;kyubyong. https://github.com/Kyubyong/numpy_exercises&amp;#34; np.__version__ &amp;#39;1.11.3&amp;#39; Q1. Concatenate x1 and x2.
x1 = np.array([&amp;#39;Hello&amp;#39;, &amp;#39;Say&amp;#39;], dtype=np.str) x2 = np.array([&amp;#39; world&amp;#39;, &amp;#39; something&amp;#39;], dtype=np.str) out = np.char.add(x1, x2) print(out) [&amp;#39;Hello world&amp;#39; &amp;#39;Say something&amp;#39;] Q2. Repeat x three time element-wise.
x = np.array([&amp;#39;Hello &amp;#39;, &amp;#39;Say &amp;#39;], dtype=np.str) out = np.char.multiply(x, 3) print(out) [&amp;#39;Hello Hello Hello &amp;#39; &amp;#39;Say Say Say &amp;#39;] Q3-1.</description>
    </item>
    
    <item>
      <title>numpy基础练习2_Array manipulation routines</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A02_array-manipulation-routines/</link>
      <pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A02_array-manipulation-routines/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
import numpy as np np.__version__ &amp;#39;1.11.2&amp;#39; Q1. Let x be a ndarray [10, 10, 3] with all elements set to one. Reshape x so that the size of the second dimension equals 150.
x = np.ones([10, 10, 3]) out = np.reshape(x, [-1, 150]) print out assert np.allclose(out, np.ones([10, 10, 3]).reshape([-1, 150])) [[ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.</description>
    </item>
    
    <item>
      <title>numpy基础练习1_Array creation routines</title>
      <link>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A01_array-creation-routines/</link>
      <pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/numpy%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A01_array-creation-routines/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/fengdu78/Data-Science-Notes/tree/master/2.numpy/numpy_exercises
Ones and zeros import numpy as np Create a new array of 2*2 integers, without initializing entries.
np.empty([2,2], int) array([[0, 0], [0, 0]]) Let X = np.array([1,2,3], [4,5,6], np.int32).
Create a new array with the same shape and type as X.
X = np.array([[1,2,3], [4,5,6]], np.int32) np.empty_like(X) array([[1, 2, 3], [4, 5, 6]]) Create a 3-D array with ones on the diagonal and zeros elsewhere.
np.eye(3) array([[ 1., 0.</description>
    </item>
    
    <item>
      <title>100道numpy练习</title>
      <link>https://example.com/p/100%E9%81%93numpy%E7%BB%83%E4%B9%A0/</link>
      <pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/100%E9%81%93numpy%E7%BB%83%E4%B9%A0/</guid>
      <description>这是为了熟悉并加强numpy而找来做的练习，来源：https://github.com/rougier/numpy-100
100 numpy exercises with hint This is a collection of exercises that have been collected in the numpy mailing list, on stack overflow and in the numpy documentation. The goal of this collection is to offer a quick reference for both old and new users but also to provide a set of exercises for those who teach.
If you find an error or think you&amp;rsquo;ve a better way to solve some of them, feel free to open an issue at https://github.</description>
    </item>
    
    <item>
      <title>刘建平老师Pinard博客的XGBoost类库代码学习记录</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84xgboost%E7%B1%BB%E5%BA%93%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84xgboost%E7%B1%BB%E5%BA%93%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>原生XGBoost需要先把数据集按输入特征部分，输出部分分开，然后放到一个DMatrix数据结构里面，这个DMatrix我们不需要关心里面的细节，使用我们的训练集X和y初始化即可。
import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt matplotlib.style.use(&amp;#34;ggplot&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False plt.rcParams[&amp;#34;figure.figsize&amp;#34;] = (15,5) import xgboost as xgb from sklearn.model_selection import GridSearchCV from sklearn.model_selection import train_test_split # from sklearn.datasets.samples_generator import make_classification from sklearn.datasets import make_classification # X为样本特征，y为样本类别输出， 共10000个样本，每个样本20个特征，输出有2个类别，没有冗余特征，每个类别一个簇 X,y = make_classification(n_samples=10000,n_features=20,n_classes=2, n_clusters_per_class=1,n_redundant=0,flip_y=0.1) #flip_y 随机分配的样本的比例，增大会加大噪声，加大分类难度 X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=22) dtrain = xgb.DMatrix(X_train,y_train) dtest = xgb.DMatrix(X_test,y_test) 上面的代码中，我们随机初始化了一个二分类的数据集，然后分成了训练集和验证集。使用训练集和验证集分别初始化了一个DMatrix，有了DMatrix，就可以做训练和预测了。简单的示例代码如下：
# param = {&amp;#39;max_depth&amp;#39;:5, &amp;#39;eta&amp;#39;:0.5, &amp;#39;verbosity&amp;#39;:1, &amp;#39;objective&amp;#39;:&amp;#39;binary:logistic&amp;#39;} param = {&amp;#34;max_depth&amp;#34;:5,&amp;#34;eta&amp;#34;:0.</description>
    </item>
    
    <item>
      <title>刘建平老师Pinard博客的AdaBoostClassifier代码学习记录</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84adaboostclassifier%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84adaboostclassifier%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>import numpy as np import pandas as pd import matplotlib.pyplot as plt import matplotlib # matplotlib.style.use(&amp;#34;ggplot&amp;#34;) matplotlib.line_width = 5000 matplotlib.max_columns = 60 plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) from sklearn.ensemble import AdaBoostClassifier from sklearn.tree import DecisionTreeClassifier #用make_gaussian_quantiles生成分组多维正态分布的数据 from sklearn.datasets import make_gaussian_quantiles 接着我们生成一些随机数据来做二元分类
#生成一些随机数据按位数分为两类，500个样本，2个样本特征，协方差系数为2 X1, y1 = make_gaussian_quantiles(cov=2.0,n_samples=500,n_features=2, n_classes=2,random_state=23) #生成的两个样本特征均值都为3 X2, y2 = make_gaussian_quantiles(cov=1.5,n_samples=400,n_features=2,n_classes=2, random_state=23,mean=(3,3)) X1[:5],y1[:5],X2[:5],y2[:5] result: #合并两组数据 #记得用一个()装 X = np.concatenate((X1,X2)) y = np.concatenate((y1,y2)) X[:5],y[:5] result: 我们通过可视化看看我们的分类数据，它有两个特征，两个输出类别，用颜色区别</description>
    </item>
    
    <item>
      <title>刘建平老师Pinard博客的sklearnGBDT代码学习记录</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84sklearngbdt%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84sklearngbdt%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>import pandas as pd import numpy as np import matplotlib.pyplot as plt import matplotlib matplotlib.style.use(&amp;#34;ggplot&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False from sklearn.ensemble import GradientBoostingClassifier # from sklearn import cross_validation, metrics cross_validation 换成了 cross_val_score from sklearn.model_selection import GridSearchCV,cross_val_score from sklearn import metrics 接着，我们把解压的数据用下面的代码载入，顺便看看数据的类别分布。
train = pd.read_csv(&amp;#34;./train_modified.csv&amp;#34;) train result: code:
target = &amp;#34;Disbursed&amp;#34; IDcol = &amp;#34;ID&amp;#34; train[&amp;#34;Disbursed&amp;#34;].value_counts() # 可以看到类别输出如下，也就是类别0的占大多数。 result: 现在我们得到我们的训练集。最后一列Disbursed是分类输出。前面的所有列（不考虑ID列）都是样本特征 code:
x_columns = [x for x in train.columns if x not in [target,IDcol]] X = train[x_columns] y = train[&amp;#34;Disbursed&amp;#34;] X.</description>
    </item>
    
    <item>
      <title>刘建平老师Pinard博客的随机森林代码学习记录</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description># 导包 import numpy as np import pandas as pd import matplotlib.pyplot as plt plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = [&amp;#34;SimHei&amp;#34;] plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) #从集成中导入RF from sklearn.ensemble import RandomForestClassifier #导入网格调参 # from sklearn.grid_search import GridSearchCV 旧版的sklearn from sklearn.model_selection import GridSearchCV # from sklearn import cross_validation,metrics 旧版写法 from sklearn.model_selection import cross_validate from sklearn import metrics #数据 train = pd.read_csv(&amp;#34;./train_modified.csv&amp;#34;) train result: code:
target = &amp;#34;Disbursed&amp;#34;#Disbursed的值就是二元分类的输出 IDcol = &amp;#34;ID&amp;#34; train[&amp;#34;Disbursed&amp;#34;].value_counts()#查看类别的数量 result:
0 19680 1 320 Name: Disbursed, dtype: int64 可以看到类别输出如上，也就是类别0的占大多数。</description>
    </item>
    
    <item>
      <title>数据集的创建make_classification的参数详情</title>
      <link>https://example.com/p/%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%9B%E5%BB%BAmake_classification%E7%9A%84%E5%8F%82%E6%95%B0%E8%AF%A6%E6%83%85/</link>
      <pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%9B%E5%BB%BAmake_classification%E7%9A%84%E5%8F%82%E6%95%B0%E8%AF%A6%E6%83%85/</guid>
      <description>这里来记录下make_classification的参数详情 import numpy as np import pandas as pd import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import matplotlib.pyplot as plt from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split X,y = make_classification(n_samples=1000,#1000个样本 n_features=2,#两个特征，方便画图 n_informative=2,#信息特征(有用特征) n_redundant=0,#冗余特征，它是信息特征的线性组合 n_repeated=0,#重复特征 n_classes=2,#分类特征 random_state=None, n_clusters_per_class=2,#每个类别两簇 shuffle=True, class_sep=1,#将每个簇分隔开来，较大的值将使分类任务更加容易 shift = 10, scale = 3, flip_y = 0)#无噪声 #训练集与测试集分割函数 x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=22) data = np.concatenate((X,y.reshape(1000,1)),axis=1) x0 = [] x1 = [] y0 = [] y1 = [] for d in data: if d[2]==0: x0.</description>
    </item>
    
    <item>
      <title>机器学习算法的随机数据生成</title>
      <link>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90/</link>
      <pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90/</guid>
      <description>numpy生成 import numpy as np np.random.rand(2,2,2) result: np.random.randn(3,2) result: #只需要在randn上每个生成的值x上做变换σx+μ即可 2*np.random.randn(3,2) + 1 result: np.random.randint(3,6,[2,3,4]) result: np.random.random_integers(3,6,[2,3,4]) result: np.random.random_sample([2,2]) result: #如果是其他区间[a,b),可以加以转换(b - a) * random_sample([size]) + a (5-2)*np.random.random_sample([3]) + 2 result: 回归模型随机数据 这里我们使用make_regression生成回归模型数据。几个关键参数有n_samples（生成样本数）， n_features（样本特征数），noise（样本随机噪音）和coef（是否返回回归系数）。例子代码如下：
import matplotlib.pyplot as plt from sklearn.datasets import make_regression #X为样本特征，y为样本输出， coef为回归系数，共1000个样本，每个样本1个特征 X,y,coef = make_regression(n_samples=1000,n_features=1,noise=10,coef=True) plt.scatter(X,y,color=&amp;#34;black&amp;#34;) #看来coef是不包含bias print(coef) plt.plot(X,X*coef,color=&amp;#34;blue&amp;#34;,linewidth=3) plt.xticks(()) plt.yticks(()) plt.show() result: 分类模型随机数据 这里我们用make_classification生成三元分类模型数据。几个关键参数有n_samples（生成样本数）， n_features（样本特征数）， n_redundant（冗余特征数）和n_classes（输出的类别数），例子代码如下
from sklearn.datasets import make_classification # X1为样本特征，Y1为样本类别输出， 共400个样本，每个样本2个特征，输出有3个类别，没有冗余特征，每个类别一个簇 X1,Y1 = make_classification(n_samples=400,n_classes=3,n_clusters_per_class=1,n_features=2,n_redundant=0) plt.scatter(X1[:,0],X1[:,1],marker=&amp;#34;o&amp;#34;,c=Y1) plt.</description>
    </item>
    
    <item>
      <title>WZU_集成学习算法代码学习记录</title>
      <link>https://example.com/p/wzu_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Fri, 19 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>机器学习练习8 集成学习 课程完整代码：https://github.com/fengdu78/WZU-machine-learning-course
代码修改并注释：黄海广，haiguang2000@wzu.edu.cn
import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import pandas as pd from sklearn.model_selection import train_test_split 生成数据 生成12000行的数据，训练集和测试集按照3:1划分
from sklearn.datasets import make_hastie_10_2 data, target = make_hastie_10_2() X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=123) X_train.shape, X_test.shape result:
((9000, 10), (3000, 10)) 模型对比 对比六大模型，都使用默认参数，因为数据是
from sklearn.linear_model import LogisticRegression from sklearn.ensemble import RandomForestClassifier from sklearn.ensemble import AdaBoostClassifier from sklearn.ensemble import GradientBoostingClassifier from xgboost import XGBClassifier from lightgbm import LGBMClassifier from sklearn.model_selection import cross_val_score import time clf1 = LogisticRegression() clf2 = RandomForestClassifier() clf3 = AdaBoostClassifier() clf4 = GradientBoostingClassifier() clf5 = XGBClassifier() clf6 = LGBMClassifier() for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6], [ &amp;#39;Logistic Regression&amp;#39;, &amp;#39;Random Forest&amp;#39;, &amp;#39;AdaBoost&amp;#39;, &amp;#39;GBDT&amp;#39;, &amp;#39;XGBoost&amp;#39;, &amp;#39;LightGBM&amp;#39; ]): start = time.</description>
    </item>
    
    <item>
      <title>《统计学习方法_李航》</title>
      <link>https://example.com/p/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95_%E6%9D%8E%E8%88%AA/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95_%E6%9D%8E%E8%88%AA/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>山东大生信_Linux_Perl_note</title>
      <link>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_linux_perl_note/</link>
      <pubDate>Thu, 04 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_linux_perl_note/</guid>
      <description>写在前面的话：这个笔记不过多深入知识，因为做入门有，大概知道什么时候该用哪个，以及现在有什么技术
Linux {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;2.6345844269466316in&amp;rdquo;}
有一定的基础所以不做笔记了
Perl 可以去看其他的课程</description>
    </item>
    
    <item>
      <title>山东大生信note</title>
      <link>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1note/</link>
      <pubDate>Thu, 04 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1note/</guid>
      <description>写在前面的话：这个笔记不过多深入知识，因为做入门有，大概知道什么时候该用哪个，以及现在有什么技术
教程地址：https://www.bilibili.com/video/BV13t411372E?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click
写在前面的话：这个笔记不过多深入知识，因为做入门有，大概知道什么时候该用哪个，以及现在有什么技术
生物数据库 PubMed的使用（原核生物） PubMed 是拥有超过两百六十万生物医学文献的数据库。这些文献来源于 MEDLINE， 也就是生物医学文献数据库、生命科学领域学术杂志以及在线的专业书籍。他们大部分提供 全文链接。注意，提供的是链接，你有没有权限通过这个链接打开或者下载全文另当别论。 不管怎么说，看上去还不错。PubMed 主页（http://www.ncbi.nlm.nih.gov/pubmed）上有个搜 索条。不管三七二十一，先把家说的 dUTPase 敲到搜索条里，点搜索。找到了五百多条文 献。每个文献有题目，作者，刊物，出版时间等等。如果列出的这些信息还不够，或者无法 满足你的要求，你从页面上方设置每个文献是要显示内容、总结、摘要，还是其他。还可以 控制每页显示几个文献，以及按照你期望的顺序进行排序
如果找到的文献太多，一时看不完，可以把他们保存到本地。只要选中你要保存的文献， 然后通过发送按钮，选择文件，再选择保存的内容以及顺序，最后点创建文件。这样你选中 文章的信息就以纯文本文件的形式保存到本地电脑上了。
Pubmed 提供文 献的摘要和全文链接。这里有两个全文链接。其中一个链接的图标上有 free 字样。Jim 很幸 运，这篇文章是 open access 的，也就是免费阅读的。两个链接，第一个是期刊提供的全文 链接，第二个是 PubMed 中心提供的全文链接。点其中一个链接，就可以在线浏览文献全文 了，或者下载全文的 PDF 文件到本地。至此，JIM 总算找到了些许有用的信息
回到 PUBMED 搜索结果页面，在显示内容格式这个下拉菜单里，除了总结，摘要，还 有个叫 MEDLINE 的项目。你可以把它简单的理解为数据库中文献记录的内部结构。每条 文献都是以这样的内部结构存储在数据库中的。一篇文献的所以信息被分割成小节，每个小 节都有自己的索引名，比如 TI 代表题目，AB 代表摘要，AU 代表作者等等。这些由几个字 母组成的索引名是规定好的。
了解了 MEDLINE 结构，我们就可以在搜索条中通过引入索引名，来按照不同的规则 搜索。比如搜索 Down 这个词。我们在 Down 的后面加上空格，中括号 AU（Down [AU]）， 就会返回所有作者名里有 Down 这个词的文献。如果加上[TI]，则返回题目中有 Down 的 文献。中括号 AD 是搜索发表单位。如果什么限制都没有，只写 Down 的话是在任意地方搜 索。我们看到，引入不同索引名后，搜索到的文献数量是不相同的</description>
    </item>
    
    <item>
      <title>山东大生信_序列比较_note</title>
      <link>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E5%BA%8F%E5%88%97%E6%AF%94%E8%BE%83_note/</link>
      <pubDate>Wed, 03 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E5%BA%8F%E5%88%97%E6%AF%94%E8%BE%83_note/</guid>
      <description>写在前面的话：这个笔记不过多深入知识，因为做入门有，大概知道什么时候该用哪个，以及现在有什么技术
序列比较 基础概念 {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.3103608923884513in&amp;rdquo;}
序列相似性 {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.227069116360455in&amp;rdquo;}
相似的序列说明可能来自同一祖先而且可能具有相似的结构和功能
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.3227121609798775in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.3592727471566053in&amp;rdquo;}
例子的一致度为：50%；
替换计分矩阵 {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.4233748906386703in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.468004155730534in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.2975951443569556in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.382060367454068in&amp;rdquo;}
PAM后面的数体现的是序列差异度，而BLOSUM后面的数字体现的是相似性
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.6440846456692912in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.0868766404199475in&amp;rdquo;}
其他两种蛋白质序列比对的替换计分矩阵
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;2.353906386701662in&amp;rdquo;}
那现在来解决下前面遗留的相似度问题：
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.4432042869641295in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.406619641294838in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.5194849081364827in&amp;rdquo;}
（2+1）:代表两对相同的，一对相似的
那么问题来了，两个序列的长度不相同怎么办呢？
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.5037270341207347in&amp;rdquo;}
先学习下两个序列的比较方法
序列两两比较的方法 打点法 {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.021797900262467in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.142396106736658in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.716813210848644in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.3695647419072614in&amp;rdquo;}
打点法在线软件 Dotlet [http://myhits.isb-sib.ch/cgi-bin/dotlet]
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.3341786964129483in&amp;rdquo;}
Input中复制序列进去
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.0793339895013125in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.550419947506562in&amp;rdquo;}
如果选其他的， 比如选择 15，那就是一次比较 15 个字母，也就是看 15 个字母长度的序列整体的相似度如 何来确定打不打点。注意这里不是比较完前 15 个字母，然后再从第 16 个字母开始比较后面 的 15 个字母，而是第 1 次比较第 1 到第 15 个字母，然后再比较第 2 到第 16 个字母，再是 第 3 到第 17 个字母，依次类推；</description>
    </item>
    
    <item>
      <title>山东大生信_生物数据库_note</title>
      <link>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E7%94%9F%E7%89%A9%E6%95%B0%E6%8D%AE%E5%BA%93_note/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E7%94%9F%E7%89%A9%E6%95%B0%E6%8D%AE%E5%BA%93_note/</guid>
      <description>写在前面的话：这个笔记不过多深入知识，因为做入门有，大概知道什么时候该用哪个，以及现在有什么技术
教程地址：https://www.bilibili.com/video/BV13t411372E?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click
写在前面的话：这个笔记不过多深入知识，因为做入门有，大概知道什么时候该用哪个，以及现在有什么技术
生物数据库 PubMed的使用（原核生物） PubMed 是拥有超过两百六十万生物医学文献的数据库。这些文献来源于 MEDLINE， 也就是生物医学文献数据库、生命科学领域学术杂志以及在线的专业书籍。他们大部分提供 全文链接。注意，提供的是链接，你有没有权限通过这个链接打开或者下载全文另当别论。 不管怎么说，看上去还不错。PubMed 主页（http://www.ncbi.nlm.nih.gov/pubmed）上有个搜 索条。不管三七二十一，先把家说的 dUTPase 敲到搜索条里，点搜索。找到了五百多条文 献。每个文献有题目，作者，刊物，出版时间等等。如果列出的这些信息还不够，或者无法 满足你的要求，你从页面上方设置每个文献是要显示内容、总结、摘要，还是其他。还可以 控制每页显示几个文献，以及按照你期望的顺序进行排序
如果找到的文献太多，一时看不完，可以把他们保存到本地。只要选中你要保存的文献， 然后通过发送按钮，选择文件，再选择保存的内容以及顺序，最后点创建文件。这样你选中 文章的信息就以纯文本文件的形式保存到本地电脑上了。
Pubmed 提供文 献的摘要和全文链接。这里有两个全文链接。其中一个链接的图标上有 free 字样。Jim 很幸 运，这篇文章是 open access 的，也就是免费阅读的。两个链接，第一个是期刊提供的全文 链接，第二个是 PubMed 中心提供的全文链接。点其中一个链接，就可以在线浏览文献全文 了，或者下载全文的 PDF 文件到本地。至此，JIM 总算找到了些许有用的信息
回到 PUBMED 搜索结果页面，在显示内容格式这个下拉菜单里，除了总结，摘要，还 有个叫 MEDLINE 的项目。你可以把它简单的理解为数据库中文献记录的内部结构。每条 文献都是以这样的内部结构存储在数据库中的。一篇文献的所以信息被分割成小节，每个小 节都有自己的索引名，比如 TI 代表题目，AB 代表摘要，AU 代表作者等等。这些由几个字 母组成的索引名是规定好的。
了解了 MEDLINE 结构，我们就可以在搜索条中通过引入索引名，来按照不同的规则 搜索。比如搜索 Down 这个词。我们在 Down 的后面加上空格，中括号 AU（Down [AU]）， 就会返回所有作者名里有 Down 这个词的文献。如果加上[TI]，则返回题目中有 Down 的 文献。中括号 AD 是搜索发表单位。如果什么限制都没有，只写 Down 的话是在任意地方搜 索。我们看到，引入不同索引名后，搜索到的文献数量是不相同的</description>
    </item>
    
    <item>
      <title>山东大生信_生物数据挖掘_note</title>
      <link>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E7%94%9F%E7%89%A9%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98_note/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E7%94%9F%E7%89%A9%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98_note/</guid>
      <description>写在前面的话：这个笔记不过多深入知识，因为做入门有，大概知道什么时候该用哪个，以及现在有什么技术
生物数据挖掘（这章讲的有点水） 大数据有四字箴言：大、快、杂、 疑，即大数据资料量庞大、变化飞快、种类繁杂、以及真伪存疑
数据库系统 数据挖掘涉及三个领域：统计、数据库系统和机器学习。关于统计，有专门的统计课程 不属于这门课的主要讲授内容。这一章主要从数据库系统和机器学习这两部分入手来掌握数 据挖掘的基本方法。 数据库系统就是存放数据的数据库和管理数据库的管理软件加在一起，即，数据库+数 据库管理系统=数据库系统。这就像一个图书馆，除了书籍以外，还要有图书管理员，否则 书放不进去也拿不出来
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.278423009623797in&amp;rdquo;}
数据库有很多类型，比如传统的关系型数据库，是以表格的形式存储数据的。还有近些 年越来越流行的面向对象型数据库，比如 XML 数据库。它是以 XML 格式存储数据的。Xml 格式的数据都是以尖括号括起来的标签开始，在标签名前加个斜线结束。标签中还可以再包 含子一级的标签。比如病人资料这个标签下就有两个病人标签，每个病人标签下还有四个记 录病人信息的标签。如果需要的话，疾病这个标签下还可以再加入更深一层的标签，比如疾 病的名字、分型等等。这样一层一层的，结构非常清晰而且灵活，特别适合存储复杂的生物 数据。这是传统的关系型数据库无法比拟的
机器学习 主要任务 机器学习主要是设计和分析一些让计算机可以自动&amp;quot;学习&amp;quot;的算法。这些算法是一类从 数据中获得规律，并利用这些规律对未知数据进行预测的算法。比如有台电脑，我们想让他 学会辨认各种球，那么我们就拿来很多球让电脑学习，告诉它这样的球足球、这样的球是排 球，这样的球是篮球，这样的球是棒球。经过大量的学习后，电脑说，我已经学会了，可以 分清这四种球了。好，我们来考考他。学过的都能掌握，没学过的打死也不会，这就是机器 学习。如果机器学习到了一个很高的境界，能够主动学习了，并能正确掌握学习到的东西， 那就走向人工智能了。目前市面上比较火的公子小白就具备机器学习的功能，但可惜仍然是 比较初级的被动学习，还没有智能到主动学习
现在回到最初的问题上，看看这个电脑是怎么学会识别各种球的。电脑没有眼睛，所以 我们也不是真的把球摆到电脑面前让他看。我们实际上是把电脑学习的物体转化成了向量， 让电脑读取向量值，也就是用向量来描述物体。我们可以用一个 5 维的向量来描述一个球。 这五个维度分别描述了球的直径、重量、颜色、材质和纹路。这样一个向量足够将各种球区 分开了。几乎所有物体我们都可以把他转化成多维向量。比如图片可以转换成颜色柱状图， 并由此创建一个 36 维的向量，一个维度对应一种颜色，每一维度上的值代表这种颜色在图 片中出现的频率。再比如，基因表达水平，可以用描述基因芯片上每个点的颜色及深浅的向 量来表示。甚至我们教室里的每一个人都可以向量化
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;2.9564643482064743in&amp;rdquo;}
机器都能学些什么，也就是机器学习的任务。常见的机器学习的任务 有分类、聚类和回归。分类和聚类虽然名字很像，但他们的区别还是巨大的。之前教给小电 脑完成的任务就是分类任务
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.4433650481189852in&amp;rdquo;}
分类任务要有足够的背景知识去训练电脑，告诉电脑这个样的都是篮球，这个样的都是 足球，这样的都是排球。然后拿学习过的这些球以外的球，让电脑判断是哪一种球，这就是 分类
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.098248031496063in&amp;rdquo;}
再来看聚类，要理解聚类可以设想这样一个场景，一个外星人来到地球，对球状物体非 常痴迷，从地球上搜集了大量的球状物体。它不知道这些球状物都是什么，为了更好的研究 它们，外星人把长得差不多的球都放在了一起，并且将它们命名为球 1、 球 2 和球 3。这个 过程就叫聚类。由此可见，聚类和分类最大的区别就是聚类不需要背景知识，而分类需要
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.219550524934383in&amp;rdquo;}</description>
    </item>
    
    <item>
      <title>山东大生信_进化树_note_</title>
      <link>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E8%BF%9B%E5%8C%96%E6%A0%91_note_/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E8%BF%9B%E5%8C%96%E6%A0%91_note_/</guid>
      <description>写在前面的话：这个笔记不过多深入知识，因为做入门有，大概知道什么时候该用哪个，以及现在有什么技术
进化树 引言 Nothing in Biology Makes Sense Except in the Light of Evolution（如果生物学没有了进化， 那么一切都将黯然无光）
分子进化概念 {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.1352602799650042in&amp;rdquo;}
所谓变异速度是指一定时间内不同碱基或氨基酸突变的个数。这个 进化变异速度被认为是恒定的，跟物种没有关系。所以，拿蛋白质来说，两个蛋白质在序列 上越相似，他们距离共同祖先就越近。分子钟理论是进化研究领域被普遍认可的理论，但是至今也没有直接的证据证实。
一些基本概念 同源（Homologs），相同来源。没错，但是它的确切定义是，来源于共同祖先的相似序 列为同源序列。也就是说，相似序列有两种，一种是来源于共同祖先的，那么他们可以叫同 源，另一种不是来源于共同祖先的，那么他们尽管相似也不能叫同源。 &amp;lt;!-- --&amp;gt; 第二种情况出现的概 率虽然低，但还是存在的，所以相似序列并不一定是同源序列。同源又分为三种，直系同源， 旁系同源和异同源。
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;4.80228237095363in&amp;rdquo;}
&amp;lt;!-- --&amp;gt; 直系同源（Orthologs）是指，来自于不同物种的由垂直家系，也就是物种形成，进化而 来的基因，并且典型的保留与原始基因相同的功能。也就是说，随着进化分支，一个基因进 入了不同的物种，并保留了原有功能。这时，不同物种中的这个基因就属于直系同源 &amp;lt;!-- --&amp;gt; {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;5.332113954505687in&amp;rdquo;} &amp;lt;!-- --&amp;gt; 旁系同源（Paralogs）是指在同一物种中的来源于基因复制的基因，可能会进化出新的 但与原功能相关的功能来。基因复制产生了两个重复的基因，多出来的这个有几种命运，一 个是又丢了。复制出来发现没有用，又删了。另一种命运是演化出了新的功能。如果这个新 功能是往好的方向发展，就会被保留下了，如果是往不好的方面发展，就会被自然选择淘汰。 还有一种命运，就是被放置不用。复制出来以后，又加了个终止子，既不表达，也不删除， 搁那里搁着不管，成了伪基因。被保留下来的具有新功能的基因与另一个复制出来的基因之 间就是旁系同源。 &amp;lt;!-- --&amp;gt; {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;5.564267279090114in&amp;rdquo;} &amp;lt;!-- --&amp;gt; 异同源（Xenologs）是指通过水平基因转移，来源于共生或病毒侵染所产生的相似基因。 异同源的产生不是垂直进化而来的，也不是平行复制产生的，而是由于原核生物与真核生物 的接触，比如病毒感染，在跨度巨大的物种间跳跃转移产生的 &amp;lt;!-- --&amp;gt; {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;5.4842333770778655in&amp;rdquo;} &amp;lt;!-- --&amp;gt; 不同的同源，概念很容易混淆。图 1 清楚的描述了各种同源之间的关系。首先，有个早 期的球蛋白基因，它通过基因复制，形成了α球蛋白基因和β球蛋白基因。后来随着进化，这 两种复制产生的基因也存在于不同的物种中。其中某一物种里的，比如老鼠里的α球蛋白基 因和β球蛋白基因就属于旁系同源。而某一个基因在不同物种中，比如青蛙里的α球蛋白基因 和鸡里的α球蛋白基因就属于直系同源。再比如，某个细菌，它没有早期的球蛋白基因，也 自然没有β球蛋白基因，但是通过与青蛙的共生，发生了基因水平转移。于是它从某一天就 起有了β球蛋白基因。那么这个细菌的β球蛋白基因和青蛙的β球蛋白基因就属于异同源 &amp;lt;!</description>
    </item>
    
    <item>
      <title>山东大生信_简单的生物统计应用以及序列算法</title>
      <link>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E7%AE%80%E5%8D%95%E7%9A%84%E7%94%9F%E7%89%A9%E7%BB%9F%E8%AE%A1%E5%BA%94%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%BA%8F%E5%88%97%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E7%AE%80%E5%8D%95%E7%9A%84%E7%94%9F%E7%89%A9%E7%BB%9F%E8%AE%A1%E5%BA%94%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%BA%8F%E5%88%97%E7%AE%97%E6%B3%95/</guid>
      <description>写在前面的话：这个笔记不过多深入知识，因为做入门有，大概知道什么时候该用哪个，以及现在有什么技术
简单的生物统计应用以及序列算法 Bayesj基础 {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;8.125433070866142in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.6918602362204727in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.400382764654418in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.6757983377077865in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.5953871391076118in&amp;rdquo;}
Bayes在生物学的应用 {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;2.822579833770779in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.0538134295713038in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.2251596675415573in&amp;rdquo;}
二元预测的灵敏度和特异度 基本介绍 {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.2344356955380578in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.480990813648294in&amp;rdquo;}
A的灵敏度达到100%，说明它对发生很敏感，只要有发生就会探测到；A的特异度60%说明所引起的探测不一定是由于地震引起的
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.3598140857392824in&amp;rdquo;}
在生物学上的应用 {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.343495188101487in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.2347659667541557in&amp;rdquo;}
位点特异性加权矩阵 每一行是一个LRR的序列（长度为11）（上半部分）, 来看看每一个氨基酸即20个氨基酸出现的概率（下半部分）；如第一行A在第一列（1）中 代表A这个氨基酸出现在第一个序列中的占比为0.3%
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.0606332020997375in&amp;rdquo;}
当作打分矩阵用来预测是哪里出现了LRR序列
如：构造一个长度为11的小窗口，一个一个位置往后面扫描，每一次都打一次分，
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;2.589207130358705in&amp;rdquo;}
如何打分：
比如这个 LTVLMLLHNQL
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.5772353455818022in&amp;rdquo;}
在矩阵中第一列找到L中出现的百分比为： 75% 即 0.75；同样的方法找到后面的氨基酸的百分比之和，转为小数，相加求和
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.8992311898512684in&amp;rdquo;}
量化的标准（阈值）的确定，即低于这个分值的不是LRR序列
怎么找到一个合理的阈值（即灵敏度和特异性高）
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.0096095800524933in&amp;rdquo;}
看这两个的交点 （ 或者将这两条曲线叠加起来，纯数学求和，取最高值 ） {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.1744925634295713in&amp;rdquo;}
基本序列算法 基本概念 {width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.188888888888889in&amp;rdquo;}</description>
    </item>
    
    <item>
      <title>《生物化学_上》</title>
      <link>https://example.com/p/%E7%94%9F%E7%89%A9%E5%8C%96%E5%AD%A6_%E4%B8%8A/</link>
      <pubDate>Sat, 30 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%9F%E7%89%A9%E5%8C%96%E5%AD%A6_%E4%B8%8A/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>山东大生信_高通量测序_note</title>
      <link>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E9%AB%98%E9%80%9A%E9%87%8F%E6%B5%8B%E5%BA%8F_note/</link>
      <pubDate>Sat, 30 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E9%AB%98%E9%80%9A%E9%87%8F%E6%B5%8B%E5%BA%8F_note/</guid>
      <description> 写在前面的话：这个笔记不过多深入知识，因为做入门有，大概知道什么时候该用哪个，以及现在有什么技术
高通量测序 （对于我，这章了解就好了) 基因组学与测序技术 Sanger 测序
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;5.018454724409449in&amp;rdquo;}
高通量测序
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.314882983377078in&amp;rdquo;}
得到一个整个的DNA，将其捣碎，加入测序相关的试剂进去，体系放在一个槽里，每个槽里就是每个测序反应（可加入荧光观察）； 会有个拍照系统，每个反应中每隔一段时间拍一张；
测序在医学中有大作用
数据本身的复杂性
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;4.381519028871391in&amp;rdquo;}
测序本身都会有错误，所以在进行之前，要排查出来；
海量数据的计算和挖掘成为主要瓶颈；用内存计算拼接；
从头测序 de novo sequencing 片段化、零碎的信息拼接成染色体水平
Overlap Graph : 基于read重叠区的，去找到他们的重合，然后再末端延申去获得这些片段;也就是说这里是将两两的序列作比较
De Bruijn Graph: 把read切成特定大小的长度
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.6531977252843393in&amp;rdquo;}
都很难解决重复区域
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.4084962817147857in&amp;rdquo;}
重测序 转录组测序 测序对象是不是DNA序列，而是 DNA转录的产物
表观基因组学 在DNA上的修饰，DNA上本身的甲基化（甲基化可以沉默基因的表达）、组蛋白的修饰，组蛋白的promoting的打开与否，
来测试这种打开的信号
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.331119860017498in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;3.464051837270341in&amp;rdquo;}
{width=&amp;ldquo;5.833333333333333in&amp;rdquo; height=&amp;ldquo;4.072636701662292in&amp;rdquo;}
猛犸象基因组测序计划 </description>
    </item>
    
    <item>
      <title>山东大生信_蛋白结构预测_note</title>
      <link>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E8%9B%8B%E7%99%BD%E7%BB%93%E6%9E%84%E9%A2%84%E6%B5%8B_note/</link>
      <pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E7%94%9F%E4%BF%A1_%E8%9B%8B%E7%99%BD%E7%BB%93%E6%9E%84%E9%A2%84%E6%B5%8B_note/</guid>
      <description>写在前面的话：这个笔记不过多深入知识，因为做入门有，大概知道什么时候该用哪个，以及现在有什么技术
蛋白质结构预测
蛋白质的结构 你将洞悉一个蛋白质到 底长什么样子（蛋白质三维结构），它和它的闺蜜手拉手拍合影的样子（蛋白质和蛋白质分 子对接），它嘴巴里塞满食物的样子（蛋白质和小分子分子对接），以及它在你身体里活动的 样子（分子动力学模拟)
一级结构也就是氨基酸序列， 二 级结构是周期性的结构构象，比如α螺旋β折叠等 三 级结构是整条多肽链的三维空间结构 四级结构是几 个蛋白质分子形成的复合体结构，比如三聚体，四聚体等 蛋白质是由氨基酸组成的，前一个氨基酸的羧基和后一个氨基酸的氨基脱去一分子的水，缩合形成的肽键。肽键将氨基酸连接起来形成肽链。成熟的肽链 并不是一根松散的毛线，它要经过折叠变成一个线团，即，形成空间立体结构。拥有了空间立体结之后，蛋白质才能上岗工作。 蛋白质的二级结构 DSSP指认 蛋白质经过折叠后会形成规则的片段，这些规则的片段构成了蛋白质的二级结构单元 （图 1）。三种常见的二级结构单元包括螺旋、β折叠、和转角。螺旋中最常见的就是α螺旋， 但不只有α螺旋，还有其他的螺旋，比如 3 转角螺旋，5 转角螺旋等。β折叠由平行排列的β 折片组成。这些折片在序列上可能相隔很远，但是在空间结构上并排在一起，彼此间形成氢 键。除了螺旋和折叠外，蛋白质结构中还存在大量的无规律松散结构 coil。如果这些无规律 的肽链突然发生了急转弯，这个转弯结构就叫做β转角
蛋白质的二级结构经常用图形来形象的描述。比如黄色的箭头代表对应的氨基酸 具有β折片结构。波浪线代表螺旋结构，小鼓包是转角。此外，以字母形式书写的二级结构 序列能够更加精准的描述。其中，E 代表β折叠，H 代表α螺旋，T 代表转角。没有写任何字 母的地方是松散的 coil 结构
研究人员根据 DSSP，也就是蛋白质二级结构定义词典，将三级结构里的二级结构单元指认出来的
然后再按照规定的格式，记录下蛋白质中每个氨基酸处于哪种二级结构单元。这样一 个记录蛋白质二级结构信息的文件叫做 DSSP 文件。蛋白质结构数据库 PDB 中的每一个蛋 白质三级结构都有自己对应的 DSSP 文件。DSSP 文件里不同字母所代表的不同二级结构单 元和 PDB 里面的记录方式是统一的
DSSP 的主页上，Introduction 部分有一个 Web server 链接，这个链接很容易让人误以为 可以通过它预测某条氨基酸序列的二级结构。这是不对的。DSSP 网站的 Web Server 可以指 认蛋白质结构文件，也就是 PDB 文件中的二级结构，并创建出相应的 DSSP 文件。提交的 PDB 文件可以是用实验方法刚刚解析出来，还没有提交 PDB 数据库的蛋白质三级结构，也 可以是用计算方法预测出来的蛋白质三级结构模型。总之，输入值必须是三级结构，而不是 一级的氨基酸序列（PDB ID 必须是小写的）</description>
    </item>
    
    <item>
      <title>pd.pct_change()计算变化率</title>
      <link>https://example.com/p/pd.pct_change%E8%AE%A1%E7%AE%97%E5%8F%98%E5%8C%96%E7%8E%87/</link>
      <pubDate>Wed, 27 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pd.pct_change%E8%AE%A1%E7%AE%97%E5%8F%98%E5%8C%96%E7%8E%87/</guid>
      <description>首先明确啥是变化率
（后一个值-前一个值）／前一个值
pandas 中的方法pct_change()方法可以用来计算变化率
import pandas as pd test = pd.Series([1,2,3,4,5]) test result: test.pct_change() result: code:
import numpy as np d = np.random.randint(0,20,(5,5)) test2 = pd.DataFrame(d) test2 result: code:
test2.pct_change() result: </description>
    </item>
    
    <item>
      <title>pd.findna函数详解</title>
      <link>https://example.com/p/pd.findna%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/</link>
      <pubDate>Tue, 19 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pd.findna%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/</guid>
      <description>fillna（）是用来填充NaN值的 参数：
inplace True/False 是否在直接修改元原对象，False的话会创建一个副本 method 填充方法; {‘pad’, ‘ffill’,‘backfill’, ‘bfill’, None}, default None pad/ffill：用前一个非缺失值去填充该缺失值 backfill/bfill：用下一个非缺失值填充该缺失值 -None：指定一个值去替换缺失值（缺省默认这种方式） -limit参数：限制填充个数 -axis参数 ：修改填充方向 code:
import pandas as pd import numpy as np from numpy import nan as NAN df1 = pd.DataFrame([[1,2,3],[NAN,NAN,2],[NAN,NAN,NAN],[8,8,NAN]]) df1 result: code:
df1.fillna(22) result: code:
df1.fillna(method=&amp;#34;pad&amp;#34;) result: code:
df1.fillna(method=&amp;#34;ffill&amp;#34;) result: code:
df1 result: code:
df1.fillna(method=&amp;#34;bfill&amp;#34;) result: </description>
    </item>
    
    <item>
      <title>pd.Categorical类别对应用法</title>
      <link>https://example.com/p/pd.categorical%E7%B1%BB%E5%88%AB%E5%AF%B9%E5%BA%94%E7%94%A8%E6%B3%95/</link>
      <pubDate>Sun, 17 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pd.categorical%E7%B1%BB%E5%88%AB%E5%AF%B9%E5%BA%94%E7%94%A8%E6%B3%95/</guid>
      <description>先看示例：
import pandas as pd import numpy as np test = pd.Categorical([&amp;#39;a&amp;#39;,&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;c&amp;#39;,&amp;#39;c&amp;#39;]) test result:
[&amp;#39;a&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;c&amp;#39;] Categories (3, object): [&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;] code:
test.dtype result:
CategoricalDtype(categories=[&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;], ordered=False) code:
test.codes result:
array([0, 0, 1, 2, 2], dtype=int8) code:
test.categories result:
Index([&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;], dtype=&amp;#39;object&amp;#39;) 由上面的例子可以看出pandas的Categorical对象，实际上是计算一个列表型数据中的类别数，即不重复项，它返回的是一个CategoricalDtype 类型的对象，相当于在原来数据上附加上类别信息
codes可以使得数据中相同的值的index变成一样的，返回一个新的index categories 可以返回类别的值 </description>
    </item>
    
    <item>
      <title>使用pd.merge实现数据合并</title>
      <link>https://example.com/p/%E4%BD%BF%E7%94%A8pd.merge%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%90%88%E5%B9%B6/</link>
      <pubDate>Fri, 08 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E4%BD%BF%E7%94%A8pd.merge%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%90%88%E5%B9%B6/</guid>
      <description>pd.merge()
pandas.merge(left, right, how=&amp;#39;inner&amp;#39;, on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=(&amp;#39;_x&amp;#39;, &amp;#39;_y&amp;#39;), copy=True, indicator=False, validate=None) how : {‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘inner’（设置数据连接的集合操作规则） left: 返回的结果只包含左列 right: 返回的结果只包含右列 inner: 交集 outer: 并集 on ：label or list（此参数只有在两个DataFrame有共同列名的时候才可以使用） left_on与right_on: label or list, or array-like（合并两个列名不同的数据集） left_index与right_index : bool, default False（合并索引） suffixes : tuple of (str, str), default (&amp;rsquo;_x&amp;rsquo;, &amp;lsquo;_y&amp;rsquo;)（为重复列名自定义后缀） # 简单连接 # 只有一个共同列名时参数 on 可省略 import pandas as pd df1 = pd.DataFrame({&amp;#39;Warframe&amp;#39;:[&amp;#39;saryn&amp;#39;,&amp;#39;volt&amp;#39;,&amp;#39;trinity&amp;#39;,&amp;#39;loki&amp;#39;], &amp;#39;group&amp;#39;:[&amp;#39;A&amp;#39;,&amp;#39;B&amp;#39;,&amp;#39;C&amp;#39;,&amp;#39;D&amp;#39;]}) df2 = pd.</description>
    </item>
    
    <item>
      <title>pd.resample()对给定的时间单位内重取样</title>
      <link>https://example.com/p/pd.resample%E5%AF%B9%E7%BB%99%E5%AE%9A%E7%9A%84%E6%97%B6%E9%97%B4%E5%8D%95%E4%BD%8D%E5%86%85%E9%87%8D%E5%8F%96%E6%A0%B7/</link>
      <pubDate>Mon, 04 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pd.resample%E5%AF%B9%E7%BB%99%E5%AE%9A%E7%9A%84%E6%97%B6%E9%97%B4%E5%8D%95%E4%BD%8D%E5%86%85%E9%87%8D%E5%8F%96%E6%A0%B7/</guid>
      <description>resample与groupby的区别：
resample：在给定的时间单位内重取样
groupby：对给定的数据条目进行统计
函数原型：
DataFrame.resample(rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention=&amp;lsquo;start&amp;rsquo;, kind=None, loffset=None, limit=None, base=0)
其中，参数how已经废弃了。
附：常见时间频率
A year
M month
W week
D day
H hour
T minute
S second
import pandas as pd import numpy as np index = pd.date_range(&amp;#34;15/1/2021&amp;#34;,periods=9,freq=&amp;#34;T&amp;#34;) index result: code:
series = pd.Series(range(9),index=index) series result: code:
series.resample(&amp;#34;3T&amp;#34;).sum() #在给定的时间单位内重取样 result: series.resample(&amp;#34;3T&amp;#34;,label=&amp;#34;right&amp;#34;,closed=&amp;#34;right&amp;#34;).sum() result: </description>
    </item>
    
    <item>
      <title>pd.shift()函数可以把数据移动指定的位数</title>
      <link>https://example.com/p/pd.shift%E5%87%BD%E6%95%B0%E5%8F%AF%E4%BB%A5%E6%8A%8A%E6%95%B0%E6%8D%AE%E7%A7%BB%E5%8A%A8%E6%8C%87%E5%AE%9A%E7%9A%84%E4%BD%8D%E6%95%B0/</link>
      <pubDate>Mon, 04 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pd.shift%E5%87%BD%E6%95%B0%E5%8F%AF%E4%BB%A5%E6%8A%8A%E6%95%B0%E6%8D%AE%E7%A7%BB%E5%8A%A8%E6%8C%87%E5%AE%9A%E7%9A%84%E4%BD%8D%E6%95%B0/</guid>
      <description>pandas DataFrame.shift()函数可以把数据移动指定的位数
period参数指定移动的步幅,可以为正为负.axis指定移动的轴
import pandas as pd data1 = pd.DataFrame({ &amp;#34;a&amp;#34;:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], &amp;#39;b&amp;#39;: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0] }) data1 result: 如果想让 a和b的数据都往下移动一位:
没有的话，会以NAN填充
data2 = data1.shift(axis=0) data2 result: code:
data1 result: code:
data3 = data1.shift(axis=1) data3 result: data1 result: 如果想往上或者往左移动,可以指定(periods=-1): 因为periods是用来指定步长
data4 = data1.shift(periods=-1,axis=0) data4 result: 一个例子:
这里有一组某车站各个小时的总进站人数和总出站人数的数据:
entries_and_exits = pd.DataFrame({ &amp;#39;ENTRIESn&amp;#39;: [3144312, 3144335, 3144353, 3144424, 3144594, 3144808, 3144895, 3144905, 3144941, 3145094], &amp;#39;EXITSn&amp;#39;: [1088151, 1088159, 1088177, 1088231, 1088275, 1088317, 1088328, 1088331, 1088420, 1088753] }) entries_and_exits result: 要求计算每个小时该车站进出站人数</description>
    </item>
    
    <item>
      <title>pd.aggregate聚类作用</title>
      <link>https://example.com/p/pd.aggregate%E8%81%9A%E7%B1%BB%E4%BD%9C%E7%94%A8/</link>
      <pubDate>Sat, 02 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pd.aggregate%E8%81%9A%E7%B1%BB%E4%BD%9C%E7%94%A8/</guid>
      <description>Dataframe.aggregate()函数用于在一个或多个列上应用某些聚合。使用callable，string，dict或string /callables列表进行聚合。最常用的聚合是
sum:返回所请求轴的值之和 min:返回所请求轴的最小值 max:返回所请求轴的最大值 用法：DataFrame.aggregate(func, axis=0, *args, **kwargs)
参数：
func:可调用，字符串，字典或字符串/可调用列表，用于汇总数据的函数 如果是函数，则必须在传递DataFrame或传递给DataFrame.apply时起作用 对于DataFrame，如果键是DataFrame列名，则可以传递dict axis:(默认0){0或“索引”，1或“列”} 0或“索引”：将函数应用于每个列。 1或“列”：将函数应用于每一行 范例1： 汇总 DataFrame 中所有列的“和”和“最小”函数 范例2 在Pandas中，我们还可以在不同的列上应用不同的聚合函数。为此，我们需要传递一个字典，该字典的键包含列名称，值包含任何特定列的聚合函数列表 </description>
    </item>
    
    <item>
      <title>WZU_scikit_learn_代码学习记录</title>
      <link>https://example.com/p/wzu_scikit_learn_%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_scikit_learn_%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>机器学习练习 5 Scikit-learn的介绍
整理编译：黄海广 haiguang2000@wzu.edu.cn,光城
在本节教程中将会绘制几个图形，于是我们激活matplotlib,使得在notebook中显示内联图。
%matplotlib inline import matplotlib.pyplot as plt 为什么要出这个教程？ scikit-learn 提供最先进的机器学习算法。 但是，这些算法不能直接用于原始数据。 原始数据需要事先进行预处理。 因此，除了机器学习算法之外，scikit-learn还提供了一套预处理方法。此外，scikit-learn 提供用于流水线化这些估计器的连接器(即转换器，回归器，分类器，聚类器等)。
在本教程中,将介绍scikit-learn 函数集，允许流水线估计器、评估这些流水线、使用超参数优化调整这些流水线以及创建复杂的预处理步骤。
基本用例：训练和测试分类器 对于第一个示例，我们将在数据集上训练和测试一个分类器。 我们将使用此示例来回忆scikit-learn的API。
我们将使用digits数据集，这是一个手写数字的数据集。
from sklearn.datasets import load_digits X, y = load_digits(return_X_y=True) X.shape result:
(1797, 64) X中的每行包含64个图像像素的强度。 对于X中的每个样本，我们得到表示所写数字对应的y。
plt.imshow(X[0].reshape(8, 8), cmap=&amp;#39;gray&amp;#39;);# 下面完成灰度图的绘制 # 灰度显示图像 plt.axis(&amp;#39;off&amp;#39;)# 关闭坐标轴 print(&amp;#39;The digit in the image is {}&amp;#39;.format(y[0]))# 格式化打印 result:
在机器学习中，我们应该通过在不同的数据集上进行训练和测试来评估我们的模型。train_test_split 是一个用于将数据拆分为两个独立数据集的效用函数。stratify参数可强制将训练和测试数据集的类分布与整个数据集的类分布相同。
code:
y result:
array([0, 1, 2, ..., 8, 9, 8]) code:
from sklearn.</description>
    </item>
    
    <item>
      <title>pandas中的date_range可用于生成指定长度的DatetimeIndex</title>
      <link>https://example.com/p/pandas%E4%B8%AD%E7%9A%84date_range%E5%8F%AF%E7%94%A8%E4%BA%8E%E7%94%9F%E6%88%90%E6%8C%87%E5%AE%9A%E9%95%BF%E5%BA%A6%E7%9A%84datetimeindex/</link>
      <pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pandas%E4%B8%AD%E7%9A%84date_range%E5%8F%AF%E7%94%A8%E4%BA%8E%E7%94%9F%E6%88%90%E6%8C%87%E5%AE%9A%E9%95%BF%E5%BA%A6%E7%9A%84datetimeindex/</guid>
      <description>有时候我们的数据是按某个频率收集的，比如每日、每月、每15分钟，那么我们怎么产生对应频率的索引呢？pandas中的date_range可用于生成指定长度的DatetimeIndex。
我们先看一下怎么生成日期范围：pd.date_range(startdate,enddate)
1.生成指定开始日期和结束日期的时间范围：
import pandas as pd #月日年 index = pd.date_range(&amp;#34;4/1/2021&amp;#34;,&amp;#34;5/2/2021&amp;#34;) print(index) result: 也可以只指定开始日期或结束日期，但这时必须要输入一个时间长度，并且指定输入的是开始时间还是结束时间，如果不指定默认是开始时间。
code:
#periods指定时间长度 pd.date_range(start=&amp;#34;4/1/2021&amp;#34;,periods=10) result: 现在我们已经知道怎么生成日期范围了，但是上面我们生成的日期的时间间隔都是天，接下来告诉大家怎么生成其他时间频率的日期范围。
要生成按某个频率计算的日期范围，只需要在date_range后加上freq就可以了。比如，生成每小时间隔的时间：
pd.date_range(&amp;#34;4/1/2021&amp;#34;,periods=10,freq=&amp;#34;h&amp;#34;) result: 生成时间间隔为1小时30分的时间：
pd.date_range(&amp;#34;4/1/2021&amp;#34;,periods=10,freq=&amp;#34;1h30min&amp;#34;) result:
python还可以生成其他不规则频率的时间，比如每月的第一个工作日，每月的第一个日历日等
生成每月的第一个工作日：
pd.date_range(&amp;#34;1/1/2021&amp;#34;,periods=12,freq=&amp;#34;BMS&amp;#34;) result: 生成每月的第一个日历日： code:
pd.date_range(&amp;#34;1/1/2021&amp;#34;,periods=12,freq=&amp;#34;MS&amp;#34;) result: 有一种很实用的频率类，为“WOM”，即每月的几个星期几。比如每月的第三个星期五。如果我们每月的第三个星期五发工资，这样就可以很方便的知道今年每个月的工资日了。
pd.date_range(&amp;#34;1/1/2021&amp;#34;,periods=12,freq=&amp;#34;WOM-3FRI&amp;#34;) result: </description>
    </item>
    
    <item>
      <title>学习Pandas_第十一课</title>
      <link>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E5%8D%81%E4%B8%80%E8%AF%BE/</link>
      <pubDate>Sat, 25 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E5%8D%81%E4%B8%80%E8%AF%BE/</guid>
      <description>从多个 Excel 文件中读取数据并且在一个 dataframe 将这些数据合并在一起。
import pandas as pd import numpy as np import matplotlib.pyplot as plt plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import os 创建 3 个 Excel 文件
#创建DataFrame #一个key就对应一个columns d = {&amp;#34;Channel&amp;#34;:[1],&amp;#34;Number&amp;#34;:[255]} df = pd.DataFrame(d) df result: # 导出到 Excel 文件中 df.to_excel(&amp;#34;./test1.xlsx&amp;#34;,sheet_name=&amp;#34;test1&amp;#34;,index=False) df.to_excel(&amp;#34;./test2.xlsx&amp;#34;,sheet_name=&amp;#34;test2&amp;#34;,index=False) df.to_excel(&amp;#34;./test3.xlsx&amp;#34;,sheet_name=&amp;#34;test3&amp;#34;,index=False) print(&amp;#34;Done&amp;#34;) result:
Done 把 3 个 Excel 文件数据读入一个 DataFrame
把 Excel 文件名读入到一个 list 中，并确保目录下没有其他 Excel 文件。
#存放文件名的list FileNames = [] os.</description>
    </item>
    
    <item>
      <title>学习Pandas_第七课</title>
      <link>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E4%B8%83%E8%AF%BE/</link>
      <pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E4%B8%83%E8%AF%BE/</guid>
      <description>import pandas as pd import numpy as np import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False 这里来讲下离群值Outlier
#创建一个dataframe，用日期做索引 States = [&amp;#39;NY&amp;#39;, &amp;#39;NY&amp;#39;, &amp;#39;NY&amp;#39;, &amp;#39;NY&amp;#39;, &amp;#39;FL&amp;#39;, &amp;#39;FL&amp;#39;, &amp;#39;GA&amp;#39;, &amp;#39;GA&amp;#39;, &amp;#39;FL&amp;#39;,&amp;#39;FL&amp;#39;] data = [1.0, 2, 3, 4, 5, 6, 7, 8, 9, 10] idx = pd.date_range(&amp;#34;20210101&amp;#34;,periods=10,freq=&amp;#34;MS&amp;#34;)#MS每月第一个日历日 df1 = pd.DataFrame(data,index=idx,columns=[&amp;#34;Revenue&amp;#34;]) df1[&amp;#34;State&amp;#34;] = States df1 result: data2 = [10.0, 10.0, 9, 9, 8, 8, 7, 7, 6, 6] idx2 = pd.</description>
    </item>
    
    <item>
      <title>学习Pandas_第十课</title>
      <link>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E5%8D%81%E8%AF%BE/</link>
      <pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E5%8D%81%E8%AF%BE/</guid>
      <description>import pandas as pd import numpy as np import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False 从DataFrame 到 Excel 从Excel 到 DataFrame 从DataFrame到 JSON 从JSON到DataFrame #创建一个DataFrame d = [1,2,3,4,5,6,7,8,9] df = pd.DataFrame(d,columns=[&amp;#34;Number&amp;#34;]) df result: #导出到excel df.to_excel(&amp;#34;./Lesson10.xlsx&amp;#34;,sheet_name=&amp;#34;testing&amp;#34;,index=False) print(&amp;#34;Done&amp;#34;) result:
Done 从 Excel 到 DataFram
df = pd.read_excel(r&amp;#34;./Lesson10.xlsx&amp;#34;,sheet_name=0) df.head() result: df.dtypes result:
umber int64 dtype: object df.tail() 从 DataFrame 到 JSON
df.to_json(&amp;#34;./Lesson10.json&amp;#34;) print(&amp;#34;Done&amp;#34;) result:
Done 从 JSON 到 DataFram</description>
    </item>
    
    <item>
      <title>学习Pandas_第五课</title>
      <link>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E4%BA%94%E8%AF%BE/</link>
      <pubDate>Thu, 23 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E4%BA%94%E8%AF%BE/</guid>
      <description>import pandas as pd import numpy as np import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = [&amp;#34;SimHei&amp;#34;] plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False #小数据集 d = {&amp;#34;one&amp;#34;:[1,1],&amp;#34;two&amp;#34;:[2,2]} i = [&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;] df = pd.DataFrame(d,index=i) df result: df.index result:
Index([&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;], dtype=&amp;#39;object&amp;#39;) #把列名(columns)放置到索引位置 srack叠积 stack = df.stack() stack result: #现在索引包含了原来的列名 stack.index result: unstack = df.unstack()#如果是unstack则是解除叠积(这是对一个已经stack了的而言的) #对于没有stack的而言，unstack则是花结构加过来，而且交换行index的位置 unstack result: unstack.index 用 T (转置)，我们可以把列和索引交换位置。
df transpose = df.T transpose transpose.index result:
Index([&amp;#39;one&amp;#39;, &amp;#39;two&amp;#39;], dtype=&amp;#39;object&amp;#39;) </description>
    </item>
    
    <item>
      <title>学习Pandas_第六课</title>
      <link>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E5%85%AD%E8%AF%BE/</link>
      <pubDate>Thu, 23 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E5%85%AD%E8%AF%BE/</guid>
      <description>import pandas as pd import numpy as np import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = [&amp;#34;SimHei&amp;#34;] plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False #小数据集 d = {&amp;#34;one&amp;#34;:[1,1,1,1,1], &amp;#34;two&amp;#34;:[2,2,2,2,2], &amp;#34;letter&amp;#34;:[&amp;#34;a&amp;#34;,&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;c&amp;#34;]} df = pd.DataFrame(d) df result: #创建一个groupby对象 one = df.groupby(&amp;#34;letter&amp;#34;)#根据letter分组 即根据letter的结果分组，相同的放一起 one.sum() result: #创建一个groupby对象 one = df.groupby(&amp;#34;letter&amp;#34;)#根据letter分组 即根据letter的结果分组，相同的放一起 one.sum() #多个分组依据记得[]封起来 letterone = df.groupby([&amp;#34;letter&amp;#34;,&amp;#34;one&amp;#34;]).sum() letterone letterone.index result: 你可能不想把用来分组的列名字作为索引，像下面的做法很容易实现。
#参数as_index=False会取消把groupby的对象作为index letterone = df.groupby([&amp;#34;letter&amp;#34;,&amp;#34;one&amp;#34;],as_index=False).sum() letterone letterone.index result: </description>
    </item>
    
    <item>
      <title>my_decisionTree_code</title>
      <link>https://example.com/p/my_decisiontree_code/</link>
      <pubDate>Wed, 22 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/my_decisiontree_code/</guid>
      <description>这是WZU老师搭配的决策树的code，自己略作修改
1．分类决策树模型是表示基于特征对实例进行分类的树形结构。决策树可以转换成一个if-then规则的集合，也可以看作是定义在特征空间划分上的类的条件概率分布。
2．决策树学习旨在构建一个与训练数据拟合很好，并且复杂度小的决策树。因为从可能的决策树中直接选取最优决策树是NP完全问题。现实中采用启发式方法学习次优的决策树。
决策树学习算法包括3部分：特征选择、树的生成和树的剪枝。常用的算法有ID3、 C4.5和CART。
3．特征选择的目的在于选取对训练数据能够分类的特征。特征选择的关键是其准则。常用的准则自己去MD中看
4．决策树的生成。通常使用信息增益最大、信息增益比最大或基尼指数最小作为特征选择的准则。决策树的生成往往通过计算信息增益或其他指标，从根结点开始，递归地产生决策树。这相当于用信息增益或其他准则不断地选取局部最优的特征，或将训练集分割为能够基本正确分类的子集。
5．决策树的剪枝。由于生成的决策树存在过拟合问题，需要对它进行剪枝，以简化学到的决策树。决策树的剪枝，往往从已生成的树上剪掉一些叶结点或叶结点以上的子树，并将其父结点或根结点作为新的叶结点，从而简化生成的决策树。
#导库 import numpy as np import pandas as pd import math from sklearn import tree import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = [&amp;#34;SimHei&amp;#34;] plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False #原始数据 def create_data(): datasets = [[&amp;#39;青年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;一般&amp;#39;, &amp;#39;否&amp;#39;], [&amp;#39;青年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;否&amp;#39;], [&amp;#39;青年&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;青年&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;一般&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;青年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;一般&amp;#39;, &amp;#39;否&amp;#39;], [&amp;#39;中年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;一般&amp;#39;, &amp;#39;否&amp;#39;], [&amp;#39;中年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;否&amp;#39;], [&amp;#39;中年&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;中年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;非常好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;中年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;非常好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;老年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;非常好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;老年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;老年&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;老年&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;非常好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;老年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;一般&amp;#39;, &amp;#39;否&amp;#39;], ] labels = [u&amp;#39;年龄&amp;#39;, u&amp;#39;有工作&amp;#39;, u&amp;#39;有自己的房子&amp;#39;, u&amp;#39;信贷情况&amp;#39;, u&amp;#39;类别&amp;#39;] # 返回数据集和每个维度的名称 return datasets, labels datasets,label = create_data() train_data = pd.</description>
    </item>
    
    <item>
      <title>学习Pandas_第四课</title>
      <link>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E5%9B%9B%E8%AF%BE/</link>
      <pubDate>Wed, 22 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E5%9B%9B%E8%AF%BE/</guid>
      <description>import pandas as pd import numpy as np #一个小数据集 d = [0,1,2,3,4,5,6,7,8,9] #创建一个dataframe df = pd.DataFrame(d) df result: #修改列名 df.columns = [&amp;#34;Rev&amp;#34;] df #增加一列 服从广播机制 df[&amp;#34;NewCol&amp;#34;] = 5 df result: #修改一下增加这一列的值 df[&amp;#34;NewCol&amp;#34;] = df[&amp;#34;NewCol&amp;#34;] + 1 df result: #可以删除这一列 del df[&amp;#34;NewCol&amp;#34;] df result: # 让我们增加几列。 译者注: 当使用 dataframe 没有的列时，dataframe 自动增加这个新列 df[&amp;#34;test&amp;#34;] = 3 df[&amp;#34;col&amp;#34;] = df[&amp;#34;Rev&amp;#34;] df result: # 如果有需要，可以改变索引(index)的名字 注意数量 i = [&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;c&amp;#39;,&amp;#39;d&amp;#39;,&amp;#39;e&amp;#39;,&amp;#39;f&amp;#39;,&amp;#39;g&amp;#39;,&amp;#39;h&amp;#39;,&amp;#39;i&amp;#39;,&amp;#39;j&amp;#39;] df.index = i df result: # 通过使用 *loc，我们可以选择 dataframe 中的部分数据 loc要传入值，不能是数字，而iloc可以 df.</description>
    </item>
    
    <item>
      <title>学习Pandas_第一课</title>
      <link>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E4%B8%80%E8%AF%BE/</link>
      <pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E4%B8%80%E8%AF%BE/</guid>
      <description>数据异常常见的情况：
数据缺失 missing data 数据不一致 inconsistent 在正常范围之外 out of place #导入相关库 import pandas as pd import matplotlib.pyplot as plt import sys #导入这个是为了确认py的版本 import matplotlib #这样导入matplotlib只是为了显示一下其版本号 # 初始化matplotlib，用inline方式显示图形 %matplotlib inline print(&amp;#34;Python 版本&amp;#34; + sys.version) print(&amp;#34;pd版本&amp;#34; + pd.__version__) print(&amp;#34;plt版本&amp;#34; + matplotlib.__version__) result: 创建数据 #初始化数据集: 婴儿名字和出生率 names = [&amp;#39;Bob&amp;#39;,&amp;#39;Jessica&amp;#39;,&amp;#39;Mary&amp;#39;,&amp;#39;John&amp;#39;,&amp;#39;Mel&amp;#39;] births = [968, 155, 77, 578, 973] #zip函数可以将多个列并起来为一个大的list 即拼接在一起如names中的第一个和births中的第一个放在一起，以此类推 zip? #这样可以查看zip函数的说明 #zip函数进行直到某列没有数据，停止 BabyDataSet = list(zip(names,births)) BabyDataSet result: df 是一个 DataFrame对象。 你可以把这个对象理解为包含了 BabyDataset 的 内容而格式非常象一个 sql 表格或者 Excel 的数据表。 让我们看看 df 中的内容。</description>
    </item>
    
    <item>
      <title>学习Pandas_第三课</title>
      <link>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E4%B8%89%E8%AF%BE/</link>
      <pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E4%B8%89%E8%AF%BE/</guid>
      <description>获取数据 - 我们的数据在一个 Excel 文件中，包含了每一个日期的客户数量。 我们 将学习如何读取 Excel 文件的内容并处理其中的数据。
准备数据 - 这组时间序列的数据并不规整而且有重复。 我们的挑战是整理这些数据 并且预测下一个年度的客户数。
分析数据 - 我们将使用图形来查看趋势情况和离群点。我们会使用一些内置的计算 工具来预测下一年度的客户数。
表现数据 - 结果将会被绘制成图形。
import numpy as np import pandas as pd import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) %matplotlib inline plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = [&amp;#34;SimHei&amp;#34;] plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False pd.date_range? #date_range()函数用来生成时间序列的 #参数freq是单位 #设置种子 np.random.seed(2021) #生成测试数据的函数 def create_dataset(Number = 1): output = [] for _ in range(Number): #创建一个按周期计算的日期的范围（每周一起始） ==》 W-MON rng = pd.date_range(start=&amp;#34;1/1/2021&amp;#34;,end=&amp;#34;12/31/2024&amp;#34;,freq=&amp;#34;W-MON&amp;#34;) #创建一些随机数 data = np.</description>
    </item>
    
    <item>
      <title>学习Pandas_第二课</title>
      <link>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E4%BA%8C%E8%AF%BE/</link>
      <pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%AD%A6%E4%B9%A0pandas_%E7%AC%AC%E4%BA%8C%E8%AF%BE/</guid>
      <description>#导入库 import numpy as np import pandas as pd import matplotlib.pyplot as plt %matplotlib inline import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = [&amp;#34;SimHei&amp;#34;] names = [&amp;#34;Bob&amp;#34;,&amp;#34;Jessica&amp;#34;,&amp;#34;Mary&amp;#34;,&amp;#34;John&amp;#34;,&amp;#34;Mel&amp;#34;] 使用上面的5个名字来创建一个有1,000个婴儿名字的随机列表，我们要做如下一些
操作:
生成一个 0 到 4 之间的随机数
我们会用到 seed，randint, len, range 和 zip 这几个函数。
#随机种子保证随机的一致性 np.random.seed? np.random.seed(2021)#随机种子 #用loop产生随机数（index），再去找值 random_names = [names[np.random.randint(0,len(names))]for _ in range(1000)] random_names[:10] result: #同理birth ## 1880年，不同婴儿名字对应的出生数量 np.random.seed(2021) births = [np.random.randint(0,1000) for _ in range(1000)] births[:10] result: #用 zip 函数把 names 和 births 这两个数据集合并在一起。 bady_data_set = list(zip(random_names,births)) bady_data_set[:10] result: 我们基本上完成了数据集的创建工作。 现在我们要用 pandas 库将这个数据集导出 到一个 csv 文件中。</description>
    </item>
    
    <item>
      <title>WZU_DecisionTree</title>
      <link>https://example.com/p/wzu_decisiontree/</link>
      <pubDate>Mon, 20 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_decisiontree/</guid>
      <description>这里是一个限制决策树层数为4的DecisionTreeClassifier例子。
#1.导入相关库 from itertools import product#用来相互交叉乘即笛卡尔积 import numpy as np import matplotlib.pyplot as plt from sklearn import datasets from sklearn.tree import DecisionTreeClassifier #2.导入数据 iris = datasets.load_iris()#仍然是使用鸢尾花 X = iris.data[:,[0,2]] X result: code:
y = iris.target#标签 y result: #使用算法训练模型 iris_decision_tree = DecisionTreeClassifier(max_depth=4) iris_decision_tree.fit(X,y) result:
DecisionTreeClassifier(max_depth=4) #可视化数据 x_min,x_max = X[:,0].min() - 1, X[:,0].max() + 1#z这个处理是为了调整坐标轴 y_min,y_max = X[:,1].min() - 1, X[:,1].max() + 1 #注意分类图中的x和y #创建坐标轴 xx,yy = np.meshgrid(np.arange(x_min,x_max,0.1),np.arange(y_min,y_max,0.1)) #预测 Z = iris_decision_tree.</description>
    </item>
    
    <item>
      <title>刘建平老师Pinard博客的SVM_RBF分类调参例子</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84svm_rbf%E5%88%86%E7%B1%BB%E8%B0%83%E5%8F%82%E4%BE%8B%E5%AD%90/</link>
      <pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84svm_rbf%E5%88%86%E7%B1%BB%E8%B0%83%E5%8F%82%E4%BE%8B%E5%AD%90/</guid>
      <description>import numpy as np import pandas as pd import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import matplotlib import matplotlib.pyplot as plt matplotlib.style.use(&amp;#34;ggplot&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False from sklearn import datasets,svm from sklearn.svm import SVC from sklearn.datasets import make_moons,make_circles,make_classification 生成一些随机数据来让我们后面去分类，为了数据难一点，我们加入了一些噪音。生成数据的同时把数据归一化
#make_circles生成月亮形数据 X,y = make_circles(noise=0.2,factor=0.5,random_state=22) #从sklearn.preprocessing导入StandardScaler归一化处理 from sklearn.preprocessing import StandardScaler X = StandardScaler().fit_transform(X) 我们先看看我的数据是什么样子的，这里做一次可视化如下：
from matplotlib.colors import ListedColormap # matplotlib.colors模块用于将颜色或数字参数转换为RGBA或RGB。 #此模块用于将数字映射到颜色或以一维颜色数组(也称为colormap)进行颜色规格转换。 cm = plt.cm.RdBu cm_bright = ListedColormap([&amp;#34;#FF0000&amp;#34;,&amp;#34;#0000FF&amp;#34;]) ax = plt.subplot() ax.set_title(&amp;#34;Input data&amp;#34;) ax.scatter(X[:,0],X[:,1],c=y,cmap=cm_bright) ax.set_xticks(()) ax.</description>
    </item>
    
    <item>
      <title>每节问题整理</title>
      <link>https://example.com/p/%E6%AF%8F%E8%8A%82%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/</link>
      <pubDate>Wed, 15 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E6%AF%8F%E8%8A%82%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/</guid>
      <description>-i 表示忽略大小写（windox下大小写不敏感，但是Linux下敏感）</description>
    </item>
    
    <item>
      <title>WZU_KNN代码学习记录</title>
      <link>https://example.com/p/wzu_knn%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Tue, 14 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_knn%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>机器学习练习6 KNN算法 代码修改并注释：黄海广，haiguang2000@wzu.edu.cn
1．$k$近邻法是基本且简单的分类与回归方法。$k$近邻法的基本做法是：对给定的训练实例点和输入实例点，首先确定输入实例点的$k$个最近邻训练实例点，然后利用这$k$个训练实例点的类的多数来预测输入实例点的类。
2．$k$近邻模型对应于基于训练数据集对特征空间的一个划分。$k$近邻法中，当训练集、距离度量、$k$值及分类决策规则确定后，其结果唯一确定。
3．$k$近邻法三要素：距离度量、$k$值的选择和分类决策规则。常用的距离度量是欧氏距离及更一般的pL距离。$k$值小时，$k$近邻模型更复杂；$k$值大时，$k$近邻模型更简单。$k$值的选择反映了对近似误差与估计误差之间的权衡，通常由交叉验证选择最优的$k$。
常用的分类决策规则是多数表决，对应于经验风险最小化。
4．$k$近邻法的实现需要考虑如何快速搜索k个最近邻点。kd树是一种便于对k维空间中的数据进行快速检索的数据结构。kd树是二叉树，表示对$k$维空间的一个划分，其每个结点对应于$k$维空间划分中的一个超矩形区域。利用kd树可以省去对大部分数据点的搜索， 从而减少搜索的计算量。
距离度量 在机器学习算法中，我们经常需要计算样本之间的相似度，通常的做法是计算样本之间的距离。
设$x$和$y$为两个向量，求它们之间的距离。
这里用Numpy实现，设和为ndarray &amp;lt;numpy.ndarray&amp;gt;，它们的shape都是(N,)
$d$为所求的距离，是个浮点数（float）。
import numpy as np #注意：运行代码时候需要导入NumPy库 欧氏距离(Euclidean distance) 欧几里得度量(euclidean metric)(也称欧氏距离)是一个通常采用的距离定义，指在$m$维空间中两个点之间的真实距离，或者向量的自然长度(即该点到原点的距离)。在二维和三维空间中的欧氏距离就是两点之间的实际距离。
距离公式：
$$ d\left( x,y \right) = \sqrt{\sum_{i}^{}(x_{i} - y_{i})^{2}} $$ 代码实现：
def euclidean(x, y): return np.sqrt(np.sum((x - y)**2)) 曼哈顿距离(Manhattan distance) 想象你在城市道路里，要从一个十字路口开车到另外一个十字路口，驾驶距离是两点间的直线距离吗？显然不是，除非你能穿越大楼。实际驾驶距离就是这个“曼哈顿距离”。而这也是曼哈顿距离名称的来源，曼哈顿距离也称为城市街区距离(City Block distance)。
距离公式：
$$ d(x,y) = \sum_{i}^{}|x_{i} - y_{i}| $$ 代码实现：
def manhattan(x, y): return np.sum(np.abs(x - y)) 切比雪夫距离(Chebyshev distance) 在数学中，切比雪夫距离(Chebyshev distance)或是L∞度量，是向量空间中的一种度量，二个点之间的距离定义是其各坐标数值差绝对值的最大值。以数学的观点来看，切比雪夫距离是由一致范数(uniform norm)(或称为上确界范数)所衍生的度量，也是超凸度量(injective metric space)的一种。</description>
    </item>
    
    <item>
      <title>刘建平老师Pinard博客的KNN算法例子</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84knn%E7%AE%97%E6%B3%95%E4%BE%8B%E5%AD%90/</link>
      <pubDate>Tue, 14 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84knn%E7%AE%97%E6%B3%95%E4%BE%8B%E5%AD%90/</guid>
      <description>这是刘建平Pinard老师博客上KNN的例子，略做了修改,https://www.cnblogs.com/nolonely/p/6980160.html
%matplotlib inline import numpy as np import pandas as pd import matplotlib.pyplot as plt # from sklearn.datasets.samples_generator import make_classification from sklearn.datasets._samples_generator import make_classification 这里再讲下sklearn.datasets._sample_generator(旧写法sklearn.datasets.sample_generator) 是用来生成数据集的：可以用来分类任务，可以用来回归任务，可以用来聚类任务，用于流形学习的，用于因子分解任务的,用于分类任务和聚类任务的：这些函数产生样本特征向量矩阵以及对应的类别标签集合
make_blobs：多类单标签数据集，为每个类分配一个或多个正太分布的点集
make_classification：多类单标签数据集，为每个类分配一个或多个正太分布的点集，提供了为数据添加噪声的方式，包括维度相关性，无效特征以及冗余特征等
make_gaussian-quantiles：将一个单高斯分布的点集划分为两个数量均等的点集，作为两类
make_hastie-10-2：产生一个相似的二元分类数据集，有10个维度
make_circle和make_moom产生二维二元分类数据集来测试某些算法的性能，可以为数据集添加噪声，可以为二元分类器产生一些球形判决界面的数据,X为样本特征，Y为样本类别输出， 共1000个样本，每个样本2个特征，输出有3个类别，没有冗余特征，每个类别一个簇
code:
#n_samples 样本数 n_features特征数 n_classes样本y即类别数 n_clusters_per_class 每个类别的簇数 (质心) 暂时没搞懂这个簇数有什么影响 X, Y = make_classification(n_samples=1000, n_features=2, n_redundant=0, n_clusters_per_class=1, n_classes=3) X[:10] result: code:
Y[:10] result:
array([1, 0, 1, 2, 1, 1, 2, 1, 2, 0]) code:
plt.scatter(X[:, 0], X[:, 1], marker=&amp;#39;o&amp;#39;, c=Y) #参数c就是color，赋值为可迭代参数对象，长度与x，y相同，根据值的不同使得（x,y）参数对表现为不同的颜色。 # 简单地说，按x,y值其中某一个值来区分颜色就好，比如上边想按照y值来区分，所以直接c=y就可以了， #这里就是根据类取划分颜色 plt.</description>
    </item>
    
    <item>
      <title>my_KNN_code</title>
      <link>https://example.com/p/my_knn_code/</link>
      <pubDate>Sun, 12 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/my_knn_code/</guid>
      <description>这里是用sklearn的KDtree来实现WZU对应的纯手写的那一部分，因为纯手写太麻烦了，不过里面提到的排序的思路值得一学！！ 顺便说一下，WZU的KNN的那个KD绘图，我还没看
import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn import neighbors #sklearn中的knn是有kd树和限定半径近邻，我们这里用的是kd树 from matplotlib.colors import ListedColormap#方便可视化时，使得相同的类颜色一致 在这次数据中没有意义了 import random from time import process_time#获取当前的时间 import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = [&amp;#34;SimHei&amp;#34;] plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False 在次之前先让我们看看md中数据来熟悉sklearn中KDtree的使用
from sklearn import neighbors data_md = [(2,3), (5,7), (9,6), (4,5), (6,4), (7,2) ] data_md_tree = neighbors.KDTree(data_md) #Get data and node arrays. data_md_tree.get_arrays() #Arrays for storing tree data, index, node data and node bounds.</description>
    </item>
    
    <item>
      <title>myNBcode</title>
      <link>https://example.com/p/mynbcode/</link>
      <pubDate>Sat, 11 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/mynbcode/</guid>
      <description>copy过来的，略作修改
1．朴素贝叶斯法是典型的生成学习方法。生成方法由训练数据学习联合概率分布 $P(X,Y)$，然后求得后验概率分布$P(Y|X)$。具体来说，利用训练数据学习$P(X|Y)$和$P(Y)$的估计，得到联合概率分布：
$$P(X,Y)＝P(Y)P(X|Y)$$
概率估计方法可以是极大似然估计或贝叶斯估计。
2．朴素贝叶斯法的基本假设是条件独立性，
$$\begin{aligned} P(X&amp;amp;=x | Y=c_{k} )=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} | Y=c_{k}\right) \ &amp;amp;=\prod_{j=1}^{n} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right) \end{aligned}$$
这是一个较强的假设。由于这一假设，模型包含的条件概率的数量大为减少，朴素贝叶斯法的学习与预测大为简化。因而朴素贝叶斯法高效，且易于实现。其缺点是分类的性能不一定很高。
3．朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测。
$$P(Y | X)=\frac{P(X, Y)}{P(X)}=\frac{P(Y) P(X | Y)}{\sum_{Y} P(Y) P(X | Y)}$$
将输入$x$分到后验概率最大的类$y$。
$$y=\arg \max {c{k}} P\left(Y=c_{k}\right) \prod_{j=1}^{n} P\left(X_{j}=x^{(j)} | Y=c_{k}\right)$$
后验概率最大等价于0-1损失函数时的期望风险最小化。（可能会用到拉普拉斯平滑）
模型：
高斯模型 多项式模型 伯努利模型 自定义一组数据用来看看 import numpy as np import pandas as pd import math from collections import Counter #这里用的是sklearn上自带的数据集Iris 鸢尾花 #https://www.cnblogs.com/nolonely/p/6980160.html #http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html from sklearn.datasets import load_iris #从model_selection模块中导入train_test_split划分数据用 from sklearn.</description>
    </item>
    
    <item>
      <title>Linux学习字典</title>
      <link>https://example.com/p/linux%E5%AD%A6%E4%B9%A0%E5%AD%97%E5%85%B8/</link>
      <pubDate>Fri, 10 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/linux%E5%AD%A6%E4%B9%A0%E5%AD%97%E5%85%B8/</guid>
      <description>这是系统性学习一遍Linxu的笔记 看的教程：https://www.bilibili.com/video/BV1CQ4y127LQ?spm_id_from=333.999.0.0
ls 1 列的第一个字符可能是 d/l/- -表示这个文件是一个二进制文件 d表示是一个目录文件 l表示一个软连接文件；第二个字符到第九个字符代表权限
2 列 表示文件的数量 （如目录的多个文件也会显示出来）
3 列/4列 分别是文件的所有者/所有组 配合权限使用
5 列是文件的大小 单位为btype（字节） ls -alh可以转换为M/kb的形式
6 列 文件上一次被修改的时间 （当年的会具体到h）
7 文件名 （软连接则指向真实路径）
以.点开头的是隐藏文件，ls -a 可以看出
ls -al /cd /pwd/ls -alh Linux文件系统 bin ： 放的都是命令文件
sbin： 放的是命令文件 权限等级高于bin
boot : 存放的是启动系统所需的东西
dev ： 存放Linux的设备文件
etc ： 存放配置/应用 文件
home： 存放用户的身份目录 root比较特殊单独成一个
run：系统启动和程序启动时运行产生的文件
usr: 存放应用程序的文件
tmp：存放临时文件 /dev/sda2 理解为window的D盘访问
cp / mv cp cp -r 可以拷贝目录中的所有文件（目录） mv 用法和cp一样 touch / mkdir / rm touch 1112310630.</description>
    </item>
    
    <item>
      <title>mylogicRegresscode</title>
      <link>https://example.com/p/mylogicregresscode/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/mylogicregresscode/</guid>
      <description>这次来练习下逻辑回归,感觉过程和线性回归很类似，只是加了个sigmoid函数,dataset分别是ex2data1.txt / ex2data2.txt
dataset1 在训练的初始阶段，我们将要构建一个逻辑回归模型来预测，某个学生是否被大学录取。设想你是大学相关部分的管理者，想通过申请学生两次测试的评分，来决定他们是否被录取。现在你拥有之前申请学生的可以用于训练逻辑回归的训练样本集。对于每一个训练样本，你有他们两次测试的评分和最后是被录取的结果。为了完成这个预测任务，我们准备构建一个可以基于两次测试评分来评估录取可能性的分类模型。上面的话是copy过来的
分析数据 import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns sns.set_style(&amp;#39;white&amp;#39;) import warnings warnings.filterwarnings(&amp;#39;ignore&amp;#39;) #为了美观，当然是不影响结果的前提下 plt.rcParams[&amp;#39;font.sans-serif&amp;#39;]=[&amp;#39;SimHei&amp;#39;] #正常显示中文 plt.rcParams[&amp;#39;axes.unicode_minus&amp;#39;]=False #正常显示非负号 dataset1 = pd.read_csv(&amp;#39;./ex2data1.txt&amp;#39;,header=None,names=[&amp;#39;Exam1&amp;#39;,&amp;#39;Exam2&amp;#39;,&amp;#39;Admitted&amp;#39;]) dataset1.head() result: code:
dataset1.describe() result: code:
dataset1.shape result:
(100, 3) code:
dataset1.isnull().sum() result:
Exam1 0 Exam2 0 Admitted 0 dtype: int64 #可视化下数据 f,axes = plt.subplots(figsize=(9,9)) dataset1_corr = dataset1.corr() print(dataset1_corr) sns.heatmap(dataset1_corr,annot=True) plt.xticks(range(len(dataset1_corr.columns)),dataset1_corr.columns) plt.yticks(range(len(dataset1_corr.columns)),dataset1_corr.columns) plt.show() result: f,axes = plt.</description>
    </item>
    
    <item>
      <title>Pandas秘籍_第五章</title>
      <link>https://example.com/p/pandas%E7%A7%98%E7%B1%8D_%E7%AC%AC%E4%BA%94%E7%AB%A0/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pandas%E7%A7%98%E7%B1%8D_%E7%AC%AC%E4%BA%94%E7%AB%A0/</guid>
      <description> 放这里用来随时随地看
在处理自行车数据时，我需要温度和降水数据，来弄清楚人们下雨时是否喜欢骑自 行车。 所以我访问了加拿大历史天气数据的网站，并想出如何自动获得它们。 这里我们将获取 201 年 3 月的数据，并清理它们。 以下是可用于在蒙特利尔获取数据的网址模板。
import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt matplotlib.style.use(&amp;#34;ggplot&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) df = pd.read_csv(&amp;#34;./comptagevelo2012.csv&amp;#34;,index_col=&amp;#34;Date&amp;#34;,sep=&amp;#34;,&amp;#34;, encoding=&amp;#34;latin1&amp;#34;,parse_dates=[&amp;#34;Date&amp;#34;],dayfirst=True) df result: </description>
    </item>
    
    <item>
      <title>WZU_决策树算法代码学习记录</title>
      <link>https://example.com/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>机器学习练习7 决策树 代码修改并注释：黄海广，haiguang2000@wzu.edu.cn
1．分类决策树模型是表示基于特征对实例进行分类的树形结构。决策树可以转换成一个if-then规则的集合，也可以看作是定义在特征空间划分上的类的条件概率分布。
2．决策树学习旨在构建一个与训练数据拟合很好，并且复杂度小的决策树。因为从可能的决策树中直接选取最优决策树是NP完全问题。现实中采用启发式方法学习次优的决策树。
决策树学习算法包括3部分：特征选择、树的生成和树的剪枝。常用的算法有ID3、 C4.5和CART。
3．特征选择的目的在于选取对训练数据能够分类的特征。特征选择的关键是其准则。常用的准则如下：
（1）样本集合$D$对特征$A$的信息增益（ID3）
$$g(D, A)=H(D)-H(D|A)$$
$$H(D)=-\sum_{k=1}^{K} \frac{\left|C_{k}\right|}{|D|} \log {2} \frac{\left|C{k}\right|}{|D|}$$
$$H(D | A)=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} H\left(D_{i}\right)$$
其中，$H(D)$是数据集$D$的熵，$H(D_i)$是数据集$D_i$的熵，$H(D|A)$是数据集$D$对特征$A$的条件熵。	$D_i$是$D$中特征$A$取第$i$个值的样本子集，$C_k$是$D$中属于第$k$类的样本子集。$n$是特征$A$取 值的个数，$K$是类的个数。
（2）样本集合$D$对特征$A$的信息增益比（C4.5）
$$g_{R}(D, A)=\frac{g(D, A)}{H(D)}$$
其中，$g(D,A)$是信息增益，$H(D)$是数据集$D$的熵。
（3）样本集合$D$的基尼指数（CART）
$$\operatorname{Gini}(D)=1-\sum_{k=1}^{K}\left(\frac{\left|C_{k}\right|}{|D|}\right)^{2}$$
特征$A$条件下集合$D$的基尼指数：
$$\operatorname{Gini}(D, A)=\frac{\left|D_{1}\right|}{|D|} \operatorname{Gini}\left(D_{1}\right)+\frac{\left|D_{2}\right|}{|D|} \operatorname{Gini}\left(D_{2}\right)$$
4．决策树的生成。通常使用信息增益最大、信息增益比最大或基尼指数最小作为特征选择的准则。决策树的生成往往通过计算信息增益或其他指标，从根结点开始，递归地产生决策树。这相当于用信息增益或其他准则不断地选取局部最优的特征，或将训练集分割为能够基本正确分类的子集。
5．决策树的剪枝。由于生成的决策树存在过拟合问题，需要对它进行剪枝，以简化学到的决策树。决策树的剪枝，往往从已生成的树上剪掉一些叶结点或叶结点以上的子树，并将其父结点或根结点作为新的叶结点，从而简化生成的决策树。
import numpy as np import pandas as pd import math from math import log 创建数据 def create_data(): datasets = [[&amp;#39;青年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;一般&amp;#39;, &amp;#39;否&amp;#39;], [&amp;#39;青年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;否&amp;#39;], [&amp;#39;青年&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;青年&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;一般&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;青年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;一般&amp;#39;, &amp;#39;否&amp;#39;], [&amp;#39;中年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;一般&amp;#39;, &amp;#39;否&amp;#39;], [&amp;#39;中年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;否&amp;#39;], [&amp;#39;中年&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;中年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;非常好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;中年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;非常好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;老年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;非常好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;老年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;老年&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;老年&amp;#39;, &amp;#39;是&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;非常好&amp;#39;, &amp;#39;是&amp;#39;], [&amp;#39;老年&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;否&amp;#39;, &amp;#39;一般&amp;#39;, &amp;#39;否&amp;#39;], ] labels = [u&amp;#39;年龄&amp;#39;, u&amp;#39;有工作&amp;#39;, u&amp;#39;有自己的房子&amp;#39;, u&amp;#39;信贷情况&amp;#39;, u&amp;#39;类别&amp;#39;] # 返回数据集和每个维度的名称 return datasets, labels datasets, labels = create_data() train_data = pd.</description>
    </item>
    
    <item>
      <title>WZU_逻辑回归代码学习记录</title>
      <link>https://example.com/p/wzu_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>机器学习练习 3 - 逻辑回归
在这一次练习中，我们将要实现逻辑回归并且应用到一个分类任务。我们还将通过将正则化加入训练算法，来提高算法的鲁棒性，并用更复杂的情形来测试它。
代码修改并注释：黄海广，haiguang2000@wzu.edu.cn
逻辑回归 在训练的初始阶段，我们将要构建一个逻辑回归模型来预测，某个学生是否被大学录取。设想你是大学相关部分的管理者，想通过申请学生两次测试的评分，来决定他们是否被录取。现在你拥有之前申请学生的可以用于训练逻辑回归的训练样本集。对于每一个训练样本，你有他们两次测试的评分和最后是被录取的结果。为了完成这个预测任务，我们准备构建一个可以基于两次测试评分来评估录取可能性的分类模型。
让我们从检查数据开始。
import numpy as np import pandas as pd import matplotlib.pyplot as plt path = &amp;#39;ex2data1.txt&amp;#39; data = pd.read_csv(path, header=None, names=[&amp;#39;Exam 1&amp;#39;, &amp;#39;Exam 2&amp;#39;, &amp;#39;Admitted&amp;#39;]) data.head() result: code:
data.shape result:
(100, 3) 让我们创建两个分数的散点图，并使用颜色编码来可视化，如果样本是正的（被接纳）或负的（未被接纳）。
positive = data[data[&amp;#39;Admitted&amp;#39;].isin([1])] negative = data[data[&amp;#39;Admitted&amp;#39;].isin([0])] fig, ax = plt.subplots(figsize=(12, 8)) ax.scatter(positive[&amp;#39;Exam 1&amp;#39;], positive[&amp;#39;Exam 2&amp;#39;], s=50, c=&amp;#39;b&amp;#39;, marker=&amp;#39;o&amp;#39;, label=&amp;#39;Admitted&amp;#39;) ax.scatter(negative[&amp;#39;Exam 1&amp;#39;], negative[&amp;#39;Exam 2&amp;#39;], s=50, c=&amp;#39;r&amp;#39;, marker=&amp;#39;x&amp;#39;, label=&amp;#39;Not Admitted&amp;#39;) ax.legend() ax.</description>
    </item>
    
    <item>
      <title>Pandas秘籍_第三章</title>
      <link>https://example.com/p/pandas%E7%A7%98%E7%B1%8D_%E7%AC%AC%E4%B8%89%E7%AB%A0/</link>
      <pubDate>Mon, 06 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pandas%E7%A7%98%E7%B1%8D_%E7%AC%AC%E4%B8%89%E7%AB%A0/</guid>
      <description>放这里用来随时随地看
import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt matplotlib.style.use(&amp;#34;ggplot&amp;#34;)#这要放在plt后 import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False plt.rcParams[&amp;#34;figure.figsize&amp;#34;] = (15,5) %matplotlib inline complaints = pd.read_csv(&amp;#34;./311_Service_Requests_from_2010_to_Present.csv&amp;#34;) 我想知道哪个区有最多的噪音投诉。 首先，我们来看看数据，看看它是什么样子：
complaints[:5] result: 为了得到噪音投诉，我们需要找到 Complaint Type 列为 Noise - Street/Sidewalk 的行。
#其实就是列用了个判断去取值 noise_complaints = complaints[complaints[&amp;#34;Complaint Type&amp;#34;] == &amp;#34;Noise - Street/Sidewalk&amp;#34;] noise_complaints[:3] result: 您还可以将多个条件与 &amp;amp; 运算符组合，如下所示:
is_noise = complaints[&amp;#34;Complaint Type&amp;#34;] == &amp;#34;Noise - Street/Sidewalk&amp;#34; is_noise[:6] result: code:</description>
    </item>
    
    <item>
      <title>Pandas秘籍_第二章</title>
      <link>https://example.com/p/pandas%E7%A7%98%E7%B1%8D_%E7%AC%AC%E4%BA%8C%E7%AB%A0/</link>
      <pubDate>Sun, 05 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pandas%E7%A7%98%E7%B1%8D_%E7%AC%AC%E4%BA%8C%E7%AB%A0/</guid>
      <description>放这里用来随时随地看
import pandas as pd import matplotlib import matplotlib.pyplot as plt matplotlib.style.use(&amp;#34;ggplot&amp;#34;) matplotlib.line_width = 5000#行宽 matplotlib.max_columns = 60 plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False plt.rcParams[&amp;#34;figure.figsize&amp;#34;] = (15,5) complaints = pd.read_csv()#读取数据csv complaints#查看数据有什么 选择列和行 为了选择一列，使用列名称作为索引，像这样：
complaints[&amp;#34;Complaint Type&amp;#34;] 要获得 DataFrame 的前 5 行，我们可以使用切片： df [:5]
complaints[:5] 我们可以组合它们来获得一列的前五行
complaints[&amp;#34;Compaint Type&amp;#34;][:5] #等同于 complaints[:5][&amp;#34;Complaint Type&amp;#34;] 选择多列 如果我们只关心投诉类型和区，但不关心其余的信息怎么办？ Pandas 使它很容易 选择列的一个子集：只需将所需列的列表用作索引。
#记得用一个[]装起来 complaints[[&amp;#34;Complaint Type&amp;#34;,&amp;#34;Borough&amp;#34;]] 这会向我们展示总结，我们可以获取前 10 列：
complaints[[&amp;#34;Complaint Type&amp;#34;,&amp;#34;Borough&amp;#34;]][:10] value_counts() 方法计算类别 什么是最常见的投诉类型？
这是个易于回答的问题，我们可以调用 .value_counts() 方法：
这个方法可以计算类别</description>
    </item>
    
    <item>
      <title>Pandas秘籍_第四章</title>
      <link>https://example.com/p/pandas%E7%A7%98%E7%B1%8D_%E7%AC%AC%E5%9B%9B%E7%AB%A0/</link>
      <pubDate>Sat, 04 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pandas%E7%A7%98%E7%B1%8D_%E7%AC%AC%E5%9B%9B%E7%AB%A0/</guid>
      <description>放这里用来随时随地看
import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt matplotlib.style.use(&amp;#34;ggplot&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False plt.rcParams[&amp;#34;figure.figsize&amp;#34;] = (15,5) import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) 好的！ 我们将在这里回顾我们的自行车道数据集。 我住在蒙特利尔，我很好奇我 们是一个通勤城市，还是以骑自行车为乐趣的城市 - 人们在周末还是工作日骑自行车？
df = pd.read_csv(&amp;#34;./comptagevelo2012.csv&amp;#34;,index_col=&amp;#34;Date&amp;#34;,sep=&amp;#34;,&amp;#34;, encoding=&amp;#34;latin1&amp;#34;,parse_dates=[&amp;#34;Date&amp;#34;],dayfirst=True) df result: code:
df[&amp;#34;Berri1&amp;#34;].plot() result: 接下来，我们只是看看 Berri 自行车道。 Berri 是蒙特利尔的一条街道，是一个相当 重要的自行车道。 现在我习惯走这条路去图书馆，但我在旧蒙特利尔工作时，我习 惯于走这条路去上班。 所以我们要创建一个只有 Berri 自行车道的 DataFrame 。
b_df = df[[&amp;#34;Berri1&amp;#34;]]#[[&amp;#34;xxx&amp;#34;]]这样可以使得赋予赋值的b_df是DataFrame对象 b_df[:5] result: code:
b_df_2 = df[&amp;#34;Berri1&amp;#34;] b_df_2[:5] ressult: 接下来，我们需要添加一列 weekday 。 首先，我们可以从索引得到星期。 我们还 没有谈到索引，但索引在上面的 DataFrame 中是左边的东西，在 Date 下面。 它 基本上是一年中的所有日子。</description>
    </item>
    
    <item>
      <title>Pandas秘籍_第一章</title>
      <link>https://example.com/p/pandas%E7%A7%98%E7%B1%8D_%E7%AC%AC%E4%B8%80%E7%AB%A0/</link>
      <pubDate>Fri, 03 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pandas%E7%A7%98%E7%B1%8D_%E7%AC%AC%E4%B8%80%E7%AB%A0/</guid>
      <description>放这里用来随时随地看
读取文件 import pandas as pd import numpy as np import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False 您可以使用 read_csv 函数从CSV文件读取数据。 默认情况下，它假定字段以逗 号分隔。
这个数据集是一个列表，蒙特利尔的 7 个不同的自行车道上每天有多少人。
df = pd.read_csv(&amp;#34;./comptagevelo2012.csv&amp;#34;,index_col=&amp;#34;Date&amp;#34;) df.tail() result: 你可以看到这完全损坏了。 read_csv 拥有一堆选项能够让我们修复它，在这里我 们：
将列分隔符改成 ; sep=&amp;quot;,&amp;quot; 将编码改为 latin1 （默认为 utf-8 ） encoding=&amp;ldquo;latin1&amp;rdquo; 解析 Date 列中的日期 parse_dates=[&amp;ldquo;Date&amp;rdquo;] 告诉它我们的日期将日放在前面，而不是月 dayfirst = True 将索引设置为 Date index_col = &amp;ldquo;Date&amp;rdquo; df = pd.read_csv(&amp;#34;./comptagevelo2012.csv&amp;#34;,index_col=&amp;#34;Date&amp;#34;,sep=&amp;#34;,&amp;#34;, encoding=&amp;#34;latin1&amp;#34;,parse_dates=[&amp;#34;Date&amp;#34;],dayfirst=True) df.head() result: 选择一列 当你读取 CSV 时，你会得到一种称为 DataFrame 的对象，它由行和列组成。 您 从数据框架中获取列的方式与从字典中获取元素的方式相同。</description>
    </item>
    
    <item>
      <title>myRegressioncode1</title>
      <link>https://example.com/p/myregressioncode1/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/myregressioncode1/</guid>
      <description>这是针对吴恩达老师课程的线性回归的课后练习 dataset:regress_data1.csv/regress_data2.csv
采用手写算法，初期不调用sklearn库
收集数据 数据由外部提供
分析数据 import pandas as pd import numpy as np import matplotlib.pyplot as plt dataset1 = pd.read_csv(&amp;#34;./regress_data1.csv&amp;#34;) print(dataset1.head()) print(dataset1.describe()) result: 可以看出只有一个特征属于单变量的线性回归
#可视化数据 plt.rcParams[&amp;#39;font.sans-serif&amp;#39;]=[&amp;#39;SimHei&amp;#39;]#显示中文 plt.rcParams[&amp;#39;axes.unicode_minus&amp;#39;]=False#显示负号 dataset1.plot(kind=&amp;#39;scatter&amp;#39;,x=&amp;#39;人口&amp;#39;,y=&amp;#39;收益&amp;#39;,figsize=(12,8)) plt.xlabel(&amp;#39;人口&amp;#39;,fontsize=18) plt.ylabel(&amp;#39;收益&amp;#39;,fontsize=18)#可以添加rotationx=0使得收益转为来 plt.show() result: 处理数据 #插入一列恒为1的列 dataset1.insert(0,&amp;#39;Ones&amp;#39;,1)#在第零列插入列名为Ones，值为1 的一列 dataset1 result: #分开特征和目标 X = dataset1.iloc[:,:2] Y = dataset1.iloc[:,2] print(X.head()) print(Y.head()) print(Y.shape) result: code:
X.shape result:
(97, 2) 训练算法 #编写cost函数，方便起见写成np数组，并初始化w和alpha X = np.matrix(X.values) Y = np.matrix(Y.values).T w = np.matrix(np.array([0,0]))#因为从dataset1中可以看出只有两个特征，所以初始化w为（1，2）的0矩阵就好了 print(X.shape,Y.shape,w.shape)#注意矩阵的数据的行列 result:
(97, 2) (97, 1) (1, 2) 参数$w$为特征函数的代价函数 $$J\left( w \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{{{\left( {{h}}\left( {{x}^{(i)}} \right)-{{y}^{(i)}} \right)}^{2}}}$$ 其中：$${{h}}\left( x \right)={{w}^{T}}X={{w }{0}}{{x}{0}}+{{w }{1}}{{x}{1}}+{{w }{2}}{{x}{2}}+&amp;hellip;+{{w }{n}}{{x}{n}}$$ code:</description>
    </item>
    
    <item>
      <title>myRegressioncode2</title>
      <link>https://example.com/p/myregressioncode2/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/myregressioncode2/</guid>
      <description>这次练习采用sklearn来实现预测,dataset：ToyotaCorolla,这里不详细探究调参，后期返回来再摸索参数对训练的影响,date 2021/10/1
收集数据 分析数据 import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt sns.set_style(&amp;#39;white&amp;#39;) dataset = pd.read_csv(&amp;#39;ToyotaCorolla.csv&amp;#39;) dataset.head()#最好加上（）输出的结构结构比较好看 result: dataset.describe() result: code:
len(dataset)#dataset.count()也行 result:
1436 code:
dataset.isnull().sum()#数据样本看来不用做null的处理了，没有null值~~~太好了 result: code:
#采用和seaborn可视化数据,用一下热图吧 #首先，先看看相关性 dataset_corr = dataset.corr() print(dataset_corr.shape) #corr是pandas的函数之一，计算列与列之间的相关系数，返回相关系数矩阵，相关系数的取值范围为[-1, 1],当接近1时，表示两者具有强烈的正相关性，比如‘s’和‘x’；当接近-1时，表示有强烈的的负相关性，比如‘s’和‘c’，而若值接近0，则表示相关性很低. f,axes = plt.subplots(figsize=(10,10)) sns.heatmap(dataset_corr,annot=True,fmt=&amp;#39;.3f&amp;#39;) length = dataset_corr.columns plt.yticks(range(len(length)),dataset_corr.columns) plt.xticks(range(len(length)),dataset_corr.columns) plt.show() result: code:
dataset_corr = dataset.corr() length = dataset_corr.columns print(length) result: 由上面的热图可以看出price和Age、KM呈负相关系数较大，和HP、Weight呈正相关的系数较大;注意热图中没有显示FuelType的数据，因为它是文本数据
画个线性的图看看 f,axes = plt.subplots(2,2,figsize=(14,8)) #负相关的两个 sns.</description>
    </item>
    
    <item>
      <title>WZU_线性回归代码学习记录</title>
      <link>https://example.com/p/wzu_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>机器学习练习 - 线性回归 代码修改并注释：黄海广，haiguang2000@wzu.edu.cn
单变量线性回归 import numpy as np import pandas as pd import matplotlib.pyplot as plt import matplotlib.pyplot as plt plt.rcParams[&amp;#39;font.sans-serif&amp;#39;]=[&amp;#39;SimHei&amp;#39;] #用来正常显示中文标签 plt.rcParams[&amp;#39;axes.unicode_minus&amp;#39;]=False #用来正常显示负号 path = &amp;#39;data/regress_data1.csv&amp;#39; data = pd.read_csv(path) data.head() result: code:
data.describe() result: 看下数据长什么样子
code:
data.plot(kind=&amp;#39;scatter&amp;#39;, x=&amp;#39;人口&amp;#39;, y=&amp;#39;收益&amp;#39;, figsize=(12,8)) plt.xlabel(&amp;#39;人口&amp;#39;, fontsize=18) plt.ylabel(&amp;#39;收益&amp;#39;, rotation=0, fontsize=18) plt.show() result: 现在让我们使用梯度下降来实现线性回归，以最小化代价函数。
首先，我们将创建一个以参数$w$为特征函数的代价函数 $$J\left( w \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{{{\left( {{h}}\left( {{x}^{(i)}} \right)-{{y}^{(i)}} \right)}^{2}}}$$ 其中：$${{h}}\left( x \right)={{w}^{T}}X={{w }{0}}{{x}{0}}+{{w }{1}}{{x}{1}}+{{w }{2}}{{x}{2}}+&amp;hellip;+{{w }{n}}{{x}{n}}$$ code:
def computeCost(X, y, w): inner = np.</description>
    </item>
    
    <item>
      <title>用scikit-learn和pandas学习Ridge回归</title>
      <link>https://example.com/p/%E7%94%A8scikit-learn%E5%92%8Cpandas%E5%AD%A6%E4%B9%A0ridge%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8scikit-learn%E5%92%8Cpandas%E5%AD%A6%E4%B9%A0ridge%E5%9B%9E%E5%BD%92/</guid>
      <description>数据读取与训练集测试集划分 import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) matplotlib.style.use(&amp;#34;ggplot&amp;#34;) from sklearn.linear_model import LinearRegression from sklearn import datasets data = pd.read_csv(&amp;#34;./CCPP/Folds5x2_pp.csv&amp;#34;) data.head() result: code:
from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=22) print(X_train.shape) print(X_test.shape) print(y_train.shape) print(y_test.shape) result:
(7176, 4) (2392, 4) (7176, 1) (2392, 1) 用sklearn运行Ridge回归 要运行Ridge回归，我们必须要指定超参数α。你也许会问：“我也不知道超参数是多少啊？” 我也不知道，那么我们随机指定一个(比如1)，后面我们会讲到用交叉验证从多个输入超参数α中快速选择最优超参数的办法。
from sklearn.linear_model import Ridge ridge = Ridge(alpha=1) ridge.fit(X_train,y_train) result:
Ridge(alpha=1) code:
print(ridge.intercept_) print(ridge.coef_) result:</description>
    </item>
    
    <item>
      <title>用scikit-learn和pandas学习线性回归</title>
      <link>https://example.com/p/%E7%94%A8scikit-learn%E5%92%8Cpandas%E5%AD%A6%E4%B9%A0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8scikit-learn%E5%92%8Cpandas%E5%AD%A6%E4%B9%A0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description>pandas来读取数据 import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt matplotlib.style.use(&amp;#34;ggplot&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False from sklearn import datasets,linear_model import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) data = pd.read_csv(&amp;#34;./CCPP/Folds5x2_pp.csv&amp;#34;) data.head() result: 准备运行算法的数据 data.shape result:
(9568, 5) 结果是(9568, 5)。说明我们有9568个样本，每个样本有5列。
现在我们开始准备样本特征X，我们用AT， V，AP和RH这4个列作为样本特征。
code:
X = data[[&amp;#34;AT&amp;#34;,&amp;#34;V&amp;#34;,&amp;#34;AP&amp;#34;,&amp;#34;RH&amp;#34;]] X.head() result: code:
y = data[[&amp;#34;PE&amp;#34;]] y.head result: 划分训练集和测试集 from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1) print(X_train.shape) print(X_test.shape) print(y_train.shape) print(y_test.shape) #可以看到75%的样本数据被作为训练集，25%的样本被作为测试集。 result: 运行scikit-learn的线性模型 scikit-learn的线性回归算法使用的是最小二乘法来实现的。</description>
    </item>
    
    <item>
      <title>ch20_高级</title>
      <link>https://example.com/p/ch20_%E9%AB%98%E7%BA%A7/</link>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch20_%E9%AB%98%E7%BA%A7/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
解析器的设计 过去很多Biopython解析器都是根据面向事件设计出来的，包括Scanner和Consumer。
Scanners是将输入的数据源进行逐行分析，只要识别出数据中的信息就会发送一个事件。 例如，如果数据中包含物种名信息，Scanner只要读到某行包含名称信息时就会产生一个 organism_name 事件。
Consumers是用来接收Scanners所发出事件的对象。 接着上面的例子，当Consumer收到了 organism_name 事件，在当前应用程序中无论以何种方式都会运行。
这是一个非常灵活的构架，如果你想要将一个文件解析成多种其他格式的，这将会很有优势。 例如， Bio.GenBank 模块可以运用这种方式构建 SeqRecord 或者其他独特的文件格式记录对象。
最近，很多添加了 Bio.SeqIO 和 Bio.AlignIO 的解析器使用了一种更为简单的方法， 但是只能产生单一形式的文件格式（分别是 SeqRecord and MultipleSeqAlignment ）。 在某些情况，Bio.SeqIO 解析器实际上包含了另一种Biopython解析器 - 例如， Bio.SwissProt 解析器产生了特定的SwissProt格式对象，又转换成了 SeqRecord 格式对象。
替换矩阵 SubsMat 这个模块提供了一个类和一些固定的方法来产生替换矩阵，类似于BLOSUM或者PAM矩阵，但是是基于用户提供的数据。 此外，你还可以从已建立的替换矩阵集合MatrixInfo.py中选择一个矩阵。 SeqMat 类来自于一个字典（dictionary）:
class SeqMat(dict) 这个字典的格式是 {(i1,j1):n1, (i1,j2):n2,&amp;hellip;,(ik,jk):nk} ， i和j是字母集，而n是一个值。
属性 self.alphabet: Bio.Alphabet中定义的一个类 self.ab_list: 排列好的字母列表。主要是内部需求。 方法 __init__(self,data=None,alphabet=None, mat_name=&amp;#39;&amp;#39;, build_later=0): data: 可以是一个字典，也可以是另一个SeqMat实例。 alphabet: 一个Bio.Alphabet的实例。如果没有提供，将从数据构建一个alphabet。 mat_name: 矩阵名，例如 BLOSUM62 或者 PAM250 build_later: 默认值为false。如果为true，用户应该只提供alphabet和空字典。如果想要之后再构建矩阵，这样会跳过alphabet大小和矩阵大小的检查。 entropy(self,obs_freq_mat) obs_freq_mat: 一个观测频率矩阵。基于“obs_freq_mat”的频率返回矩阵的熵值。矩阵实例须为LO或者SUBS。 sum(self) 计算矩阵的字母表中每个字母值的总和，返回值是字典的形式 {i1: s1, i2: s2,&amp;hellip;,in:sn}, 其中:</description>
    </item>
    
    <item>
      <title>ch19_biopython测试框架</title>
      <link>https://example.com/p/ch19_biopython%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6/</link>
      <pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch19_biopython%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
Biopython具有一个基于Python标准单元测试框架 unittesthttp://docs.python.org/library/unittest.html 的回归测试框架（文件 run_tests.py）。而为模块提供全面测试， 是确保Biopython代码在使用期内尽可能无bug的一个最重要的方面。 也经常是最被轻视的方面之一。本章旨在使运行Biopython测试和编 写测试代码尽可能容易。理想情况下，进入Biopython的每个模块都 应该有一个测试（还应该有对应文档！）。强烈鼓励我们所有开发 者，以及任何从源码安装Biopython的人运行单元测试。
运行测试 在你下载Biopython源码或者从我们的源码仓库签出时，你会发现一 个子目录调用 Tests。 这包括关键脚本 run_tests.py、 名为 test_XXX.py 的很多独立脚本、一个叫 output 的子目录和 很多其他包含测试套件输入文件的子目录。
作为构建和安装Biopython的一部分，你通常会在命令行上从Biopython 源码顶层目录运行整个测试套件如下：
python setup.py test 这事实上等价于转到 Tests 子目录，并运行：
python run_tests.py #你通常会想要只运行测试的一部分，这可以如下来操作： python run_tests.py test_SeqIO.py test_AlignIO.py #当给出测试列表时， .py 扩展名是可选的，所以你可以只需打字： python run_tests.py test_SeqIO test_AlignIO #要运行 docstring 测试（见 19.3 节）的话， 你可以用 python run_tests.py doctest 缺省情况下， run_tests.py 运行所有测试，包括docstring测试。
如果一单个测试失败了，你还可以尝试直接运行它，它会给出更多信息。
重要的是，要注意单个单元测试有两类作用：
简单打印和比较脚本。 这些单元测试本质上是简短的 Python 示例 程序，它们会打印出各种输出文本。对于一个名为 test_XXX.py 的测试文件，在 output 子目录（包含期望的输出）下会有一个 叫做 test_XXX 的匹配文本文件。测试框架所做的全部就是运行 脚本并检查输出的一致性。 基于 unittest 的标准测试。 这些会 import unittest ，然 后定义 unittest.</description>
    </item>
    
    <item>
      <title>ch18_coobook</title>
      <link>https://example.com/p/ch18_coobook/</link>
      <pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch18_coobook/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
操作序列文件 过滤文件中的序列 通常你会拥有一个包含许多序列的大文件（例如，FASTA基因文件，或者FASTQ或SFF读长文件），和一个包含你所感兴趣的序列的ID列表，而你希望创建一个由这一ID列表里的序列构成的文件。
让我们假设这个ID列表在一个简单的文本文件中，作为每一行的第一个词。这可能是一个表格文件，其第一列是序列ID。尝试下面的代码：
from Bio import SeqIO input_file = &amp;#34;big_file.sff&amp;#34; id_file = &amp;#34;short_list.txt&amp;#34; output_file = &amp;#34;short_list.sff&amp;#34; wanted = set(line.rstrip(&amp;#34;\n&amp;#34;).split(None,1)[0] for line in open(id_file)) print &amp;#34;Found %i unique identifiers in %s&amp;#34; % (len(wanted), id_file) records = (r for r in SeqIO.parse(input_file, &amp;#34;sff&amp;#34;) if r.id in wanted) count = SeqIO.write(records, output_file, &amp;#34;sff&amp;#34;) print &amp;#34;Saved %i records from %s to %s&amp;#34; % (count, input_file, output_file) if count &amp;lt; len(wanted): print &amp;#34;Warning %i IDs not found in %s&amp;#34; % (len(wanted)-count, input_file) 注意，我们使用Python的 set 类型而不是 list，这会使得检测成员关系更快。</description>
    </item>
    
    <item>
      <title>《PYTHON生物信息学数据管理》</title>
      <link>https://example.com/p/python%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/</link>
      <pubDate>Mon, 16 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/python%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>ch16_监督学习方法</title>
      <link>https://example.com/p/ch16_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</link>
      <pubDate>Mon, 16 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch16_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
注意本章介绍的所有监督学习方法都需要先安装Numerical Python （numpy）。
Logistic回归模型 背景和目的 Logistic回归是一种监督学习方法，通过若干预测变量 x__i 的加权和来尝试将样本划分为 K 个不同类别。Logistic回归模型可用来计算预测变量的权重 β_i_ 。在Biopython中，logistic回归模型目前只实现了二类别（ K = 2 ）分类，而预测变量的数量没有限制。
作为一个例子，我们试着预测细菌中的操纵子结构。一个操纵子是在一条DNA链上许多相邻基因组成的一个集合，可以被共同转录为一条mRNA分子。这条mRNA分子经翻译后产生多个不同的蛋白质。我们将以枯草芽孢杆菌的操纵子数据进行说明，它的一个操纵子平均包含2.4个基因。
作为理解细菌的基因调节的第一步，我们需要知道其操纵子的结构。枯草芽孢杆菌大约10%的基因操纵子结构已经通过实验获知。剩下的90%的基因操纵子结构可以通过一种监督学习方法来预测。
在这种监督学习方法中，我们需要选择某些与操纵子结构有关的容易度量的预测变量 x__i 。例如可以选择基因间碱基对距离来来作为其中一个预测变量。同一个操纵子中的相邻基因往往距离相对较近，而位于不同操纵子的相邻基因间通常具有更大的空间来容纳启动子和终止子序列。另一个预测变量可以基于基因表达量度。根据操纵子的定义，属于同一个操纵子的基因有相同的基因表达谱，而不同操纵子的两个基因的表达谱也不相同。在实际操作中，由于存在测量误差，对相同操纵子的基因表达轮廓的测量不会完全一致。为了测量基因表达轮廓的相似性，我们假设测量误差服从正态分布，然后计算对应的对数似然分值。
现在我们有了两个预测变量，可以据此预测在同一条DNA链上两个相邻基因是否属于相同的操纵子： - _x_1 ：两基因间的碱基对数； - _x_2 ：两基因表达谱的相似度。
在logistic回归模型中，我们使用这两个预测变量的加权和来计算一个联合得分 S：
S=β0+β1x1+β2x2.S=β0+β1x1+β2x2.
根据下面两组示例基因，logistic回归模型对参数 β0 ， β1, β2 给出合适的值： - OP: 相邻基因，相同DNA链，属于相同操纵子； - NOP: 相邻基因，相同DNA链，属于不同操纵子。
在logistic回归模型中，属于某个类别的概率依赖于通过logistic函数得出的分数。对于这两类OP和NOP，相应概率可如下表述：
使用一组已知是否属于相同操纵子（OP类别）或不同操纵子（NOP类别）的基因对，通过最大化相应概率函数的对数似然值，我们可以计算权重 β0, β1, β2 。
训练logistic回归模型 已知类别(OP or NOP)的相邻基因对.如果两个基因相重叠，其基因间距离为负值
基因对	基因间距离 (x1)	基因表达得分 (x2)	类别 cotJA — cotJB	-53	-200.78	OP yesK — yesL	117	-267.</description>
    </item>
    
    <item>
      <title>ch15_聚类分析</title>
      <link>https://example.com/p/ch15_%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/</link>
      <pubDate>Sun, 15 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch15_%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
聚类分析是根据元素相似度，进行分组的过程。在生物信息学中，聚类分析广泛 用于基因表达数据分析，用来对具有相似表达谱的基因归类；从而鉴定功能相关的基 因，或预测未知基因的功能。
Biopython中的 Bio.Cluster 模块提供了常用的聚类算法。虽然Bio.Cluster被设计用于 基因表达数据，它也可用于其他类型数据的聚类。 Bio.Cluster 和其使用的C聚类库的说明见De Hoon et al. [14].
Bio.Cluster 包含了以下四种聚类算法：
系统聚类（成对重心法，最短距离，最大距离和平均连锁法); k-means, k-medians, 和 k-medoids 聚类; 自组织映射（Self-Organizing Maps）; 主成分分析 数据表示法
用于聚类的输入为一个 n x m 的Python 数值矩阵 data。在基因表达数据聚类中， 每一行表示不同的基因，每一列表示不同的实验条件。 Bio.Cluster 既可以 针对每行（基因），也可以针对每列（实验条件）进行聚类。
缺失值
在芯片实验中，经常会有些缺失值，可以用一个额外的 n × m Numerical Python 整型矩阵 mask 表示。 例如 mask[i,j] ,表示 data[i,j] 是个缺失值， 并且在分析中被忽略。
随机数据生成器
k-means/medians/medoids 聚类和 Self-Organizing Maps (SOMs) 需要调用随机数生成器。在 Bio.Cluster 中，正态分布随机数 生成器的算法是基于L’Ecuyer [25] ，二项分布的随机数 生成器算法是基于Kachitvichyanukul and Schmeiser [23] 开发的BTPE算法。随机数生成器在调用时会首先进行初始化。由于随机数生成器使用了 两个乘同余发生器（multiplicative linear congruential generators），所以初始化时需要两个整型的 种子。这两个种子可以调用系统提供的 rand （C标准库）函数生成。在 Bio.</description>
    </item>
    
    <item>
      <title>ch14_使用Bio.motifs进行模体序列分析</title>
      <link>https://example.com/p/ch14_%E4%BD%BF%E7%94%A8bio.motifs%E8%BF%9B%E8%A1%8C%E6%A8%A1%E4%BD%93%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/</link>
      <pubDate>Sat, 14 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch14_%E4%BD%BF%E7%94%A8bio.motifs%E8%BF%9B%E8%A1%8C%E6%A8%A1%E4%BD%93%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
这章主要的介绍Biopython中的 Bio.motifs 包。这个包是为了方便那些需要进行模体序列分析的人们而特意提供的，所以我想你们在使用时肯定对模体序列分析的一些相关要点都很熟悉。假如在使用中遇到不清楚的地方，请您查阅 相关章节以获得有关的信息。
这章的大部分内容是介绍Biopython 1.61 之前版本中新加入的 Bio.motifs 包，该包替代了Biopython 1.50版本中的 Bio.Motif 包，而 Bio.Motif 包是基于较早版本的Biopython 中的两个模块 Bio.AlignAce 和 Bio.MEME 。Bio.motifs 包较好地综合了上述的几个模块的功能，做为一个统一模块工具。
说到其他库，看到这里，你或许会对 TAMO 感兴趣，这是另一个分析模体序列的Python库。它能提供更多关于 de-novo 模体的查找方式，不过它并没有纳入到Biopython中，而且在商业用途上还有一些限制
模体对象 由于我们感兴趣的是模体分析，所以我们需要先看看 Motif 对象。对此我们需要先导入Bio.motifs包：
&amp;gt;&amp;gt;&amp;gt; from Bio import motifs 然后我们可以开始创建我们第一个模体对象。我们可以从模体的实例列表中创建一个 Motif 对象，也可以通过读取模体数据库中或模体查找软件产生的文件来获得一个 Motif 对象
&amp;gt;&amp;gt;&amp;gt; from Bio import motifs 从实例中创建一个模体 假设我们有一些DNA模体的实例
&amp;gt;&amp;gt;&amp;gt; from Bio.Seq import Seq &amp;gt;&amp;gt;&amp;gt; instances = [Seq(&amp;#34;TACAA&amp;#34;), ... Seq(&amp;#34;TACGC&amp;#34;), ... Seq(&amp;#34;TACAC&amp;#34;), ... Seq(&amp;#34;TACCC&amp;#34;), ... Seq(&amp;#34;AACCC&amp;#34;), ... Seq(&amp;#34;AATGC&amp;#34;), ... Seq(&amp;#34;AATGC&amp;#34;), .</description>
    </item>
    
    <item>
      <title>ch13_Bio.Phylo系统发育分析</title>
      <link>https://example.com/p/ch13_bio.phylo%E7%B3%BB%E7%BB%9F%E5%8F%91%E8%82%B2%E5%88%86%E6%9E%90/</link>
      <pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch13_bio.phylo%E7%B3%BB%E7%BB%9F%E5%8F%91%E8%82%B2%E5%88%86%E6%9E%90/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
Biopython1.54开始引入了Bio.Phylo模块，与SeqIO和AlignIO类似，它的目的是提供 一个通用的独立于源数据格式的方法来使用系统进化树，同时提供一致的API来进行 I/O操作。
Bio.Phylo在一篇开放获取的期刊文章中有介绍 [9, Talevich et al., 2012], 这可能对您也有所帮助。
树中有什么？ 为了熟悉这个模块，让我们首先从一个已经创建好的树开始，从几个不同的角度来审视 它。接着我们将给树的分支上颜色，并使用一个特殊的phyloXML特性，最终保存树
译者注：本翻译中， 分支 对应原文中的 branch ，原文中一般代表 某一个节点的前导连线；而 进化枝 对应原文中的 clade ，代表某个节点所代表的整个 进化分支，包括本身和它所有的后代；若clade代表biopython中的对象则保留原文
在终端中使用你喜欢的编辑器创建一个简单的Newick文件：
% cat &amp;gt; simple.dnd &amp;lt;&amp;lt;EOF &amp;gt; (((A,B),(C,D)),(E,F,G)); &amp;gt; EOF 这棵树没有分支长度，只有一个拓扑结构和标记的端点。（如果你有一个真正的树文件， 你也可以使用它来替代进行示例操作。）
选择启动你的Python解释器：
% ipython -pylab 对于交互式操作，使用参数 -pylab 启动IPython解释器能启用 matplotlib 整合 功能，这样图像就能自动弹出来。我们将在这个示例中使用该功能。
现在，在Python终端中，读取树文件，给定文件名和格式名。
&amp;gt;&amp;gt;&amp;gt; from Bio import Phylo &amp;gt;&amp;gt;&amp;gt; tree = Phylo.read(&amp;#34;simple.dnd&amp;#34;, &amp;#34;newick&amp;#34;) 以字符串打印该树对象我们将得到整个对象的层次结构概况。
&amp;gt;&amp;gt;&amp;gt; print tree Tree(weight=1.0, rooted=False, name=&amp;#34;&amp;#34;) Clade(branch_length=1.0) Clade(branch_length=1.0) Clade(branch_length=1.</description>
    </item>
    
    <item>
      <title>ch12_Bio.PopGen_群体遗传学</title>
      <link>https://example.com/p/ch12_bio.popgen_%E7%BE%A4%E4%BD%93%E9%81%97%E4%BC%A0%E5%AD%A6/</link>
      <pubDate>Thu, 12 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch12_bio.popgen_%E7%BE%A4%E4%BD%93%E9%81%97%E4%BC%A0%E5%AD%A6/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
Bio.PopGen是一个群体遗传学相关的模块，在Biopython 1.44及以后的版本中可用。
该模块的中期目标是支持各种类型的数据格式、应用程序和数据库。目前，该模块正在紧张的开发中，并会快速实现对新特征的支持。这可能会带来一些不稳定的API，尤其是当你使用的是开发版。不过，我们正式公开发行的API应该更加稳定。
GenePop GenePop（ http://genepop.curtin.edu.au/）是一款主流的群体遗传学软件包，支持Hardy-Weinberg检验、连锁不平衡、群体分化、基础统计计算、 FstFst 和迁移率估计等等。GenePop并不支持基于序列的统计计算，因为它并不能处理序列数据。GenePop文件格式广泛用于多种其它的群体遗传学应用软件，因此成为群体遗传学领域重要格式。
Bio.PopGen提供GenePop文件格式解析器和生成器，同时也提供操作记录内容的小工具。此处有个关于怎样读取GenePop文件的示例（你可以在Biopython的Test/PopGen文件夹下找到GenePop示例文件）：
from Bio.PopGen import GenePop handle = open(&amp;#34;example.gen&amp;#34;) rec = GenePop.read(handle) handle.close() 它将读取名为example.gen的文件并解析。如果你输出rec，那么该记录将会以GenePop格式再次输出。
在rec中最重要的信息是基因座名称和群体信息（当然不止这些，请使用help(GenePop.Record)获得API帮助文档）。基因座名称可以在rec.loci_list中找到，群体信息可以在rec.populations中找到。群体信息是一个列表，每个群体（population）作为其中一个元素。每个元素本身又是包含个体（individual）的列表，每个个体包含个体名和等位基因列表（每个marker两个元素），下面是一个rec.populations的示例：
[ [ (&amp;#39;Ind1&amp;#39;, [(1, 2), (3, 3), (200, 201)], (&amp;#39;Ind2&amp;#39;, [(2, None), (3, 3), (None, None)], ], [ (&amp;#39;Other1&amp;#39;, [(1, 1), (4, 3), (200, 200)], ] ] 在上面的例子中，我们有两个群体，第一个群体包含两个个体，第二个群体只包含一个个体。第一个群体的第一个个体叫做Ind1，紧接着是3个基因座各自的等位基因信息。请注意，对于任何的基因座，信息可以缺失（如上述个体Ind2）。
有几个可用的工具函数可以处理GenePop记录，如下例：
from Bio.PopGen import GenePop #Imagine that you have loaded rec, as per the code snippet above.</description>
    </item>
    
    <item>
      <title>Ch10_Swiss-Prot_ExPASy</title>
      <link>https://example.com/p/ch10_swiss-prot_expasy/</link>
      <pubDate>Wed, 11 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch10_swiss-prot_expasy/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
Swiss-Prot ( http://www.expasy.org/sprot )是一个 蛋白质序列数据库。 Biopython能够解析纯文本的Swiss-Prot文件, 这种格式也被Swiss-Prot、TrEMBL和PIRPSD的UniProt数据库使用。然而我们并 不支持UniProKB的XML格式文件。
解析Swiss-Prot和ExPASy 你可以将 Swiss-Prot记录存到 Bio.SwissProt.Record 对象, 这实际上存储了Swiss-Prot记录 中所包含的的全部信息。在这部分我们将介绍怎样从一个Swiss-Prot文件中提 取 Bio.SwissProt.Record 对象。
获取Swiss-Prot文件记录的方式 为了解析Swiss-Prot记录，我们首先需要得到一个Swiss-Prot记录文件。根据该Swiss-Prot 记录的储存位置和储存方式，获取该记录文件的方式也有所不同：
#本地打开Swiss-Prot文件： &amp;gt;&amp;gt;&amp;gt; handle = open(&amp;#34;myswissprotfile.dat&amp;#34;) #打开使用gzip压缩的Swiss-Prot文件： &amp;gt;&amp;gt;&amp;gt; import gzip &amp;gt;&amp;gt;&amp;gt; handle = gzip.open(&amp;#34;myswissprotfile.dat.gz&amp;#34;) #在线打开Swiss-Prot文件： &amp;gt;&amp;gt;&amp;gt; import urllib &amp;gt;&amp;gt;&amp;gt; handle = urllib.urlopen(&amp;#34;http://www.somelocation.org/data/someswissprotfile.dat&amp;#34;) #从ExPASy数据库在线打开Swiss-Prot文件 &amp;gt;&amp;gt;&amp;gt; from Bio import ExPASy &amp;gt;&amp;gt;&amp;gt; handle = ExPASy.get_sprot_raw(myaccessionnumber) 读取Swiss-Prot文件 通过 Bio.SeqIO 来获取格式未知的 SeqRecord 对象。此外，我们也可以 用 Bio.SwissProt 来获取更加匹配基本文件格式的 Bio.SwissProt.Record 对象。
我们使用 read() 函数来从文件中读取一个Swiss-Prot记录：</description>
    </item>
    
    <item>
      <title>ch11_PDB模块</title>
      <link>https://example.com/p/ch11_pdb%E6%A8%A1%E5%9D%97/</link>
      <pubDate>Wed, 11 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch11_pdb%E6%A8%A1%E5%9D%97/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
Bio.PDB是Biopython中处理生物大分子晶体结构的模块。除了别的类之外，Bio.PDB包含PDBParser类，此类能够产生一个Structure对象，以一种较方便的方式获取文件中的原子数据。只是在处理PDB文件头所包含的信息时，该类有一定的局限性。
晶体结果文件的读与写 读取PDB文件 首先，我们创建一个 PDBParser 对象：
&amp;gt;&amp;gt;&amp;gt; from Bio.PDB.PDBParser import PDBParser &amp;gt;&amp;gt;&amp;gt; p = PDBParser(PERMISSIVE=1) PERMISSIV 标签表示一些与PDB文件相关的问题会被忽略（注意某些原子和/或残基会丢失）。如果没有这个标签，则会在解析器运行期间有问题被检测到的时候生成一个 PDBConstructionException 标签。
接着通过 PDBParser 解析PDB文件，就产生了Structure对象（在此例子中，PDB文件为’pdb1fat.ent’，’1fat’是用户定义的结构名称）:
&amp;gt;&amp;gt;&amp;gt; structure_id = &amp;#34;1fat&amp;#34; &amp;gt;&amp;gt;&amp;gt; filename = &amp;#34;pdb1fat.ent&amp;#34; &amp;gt;&amp;gt;&amp;gt; s = p.get_structure(structure_id, filename) 你可以从PDBParser对象中用 get_header 和 get_trailer 方法来提取PDB文件中的文件头和文件尾（简单的字符串列表）。然而许多PDB文件头包含不完整或错误的信息。许多错误在等价的mmCIF格式文件中得到修正。 因此，如果你对文件头信息感兴趣，可以用下面即将讲到的 MMCIF2Dict 来提取信息，而不用处理PDB文件文件头。
现在澄清了，让我们回到解析PDB文件头这件事上。结构对象有个属性叫 header ，这是一个将头记录映射到其相应值的Python字典。
例子：
&amp;gt;&amp;gt;&amp;gt; resolution = structure.header[&amp;#39;resolution&amp;#39;] &amp;gt;&amp;gt;&amp;gt; keywords = structure.header[&amp;#39;keywords&amp;#39;] 在这个字典中可用的关键字有 name 、 head 、 deposition_date 、 release_date 、 structure_method 、 resolution 、 structure_reference （映射到一个参考文献列表）、 journal_reference 、 author 、和 compound （映射到一个字典，其中包含结晶化合物的各种信息）。</description>
    </item>
    
    <item>
      <title>ch9_访问NCBI_Entrez数据库</title>
      <link>https://example.com/p/ch9_%E8%AE%BF%E9%97%AEncbi_entrez%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Tue, 10 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch9_%E8%AE%BF%E9%97%AEncbi_entrez%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
这一章只挑取自己感觉有需要的去记录
简介 Entrez (http://www.ncbi.nlm.nih.gov/Entrez) 是一个给客户提供NCBI各个数据库（如PubMed, GeneBank, GEO等等）访问的检索系统。 用户可以通过浏览器手动输入查询条目访问Entrez，也可以使用Biopython的 Bio.Entrez 模块以编程方式访问来访问Entrez。 如果使用第二种方法，用户用一个Python脚本就可以实现在PubMed里面搜索或者从GenBank下载数据。
Bio.Entrez 模块利用了Entrez Programming Utilities（也称作EUtils），包含八个工具，详情请见NCBI的网站： http://www.ncbi.nlm.nih.gov/entrez/utils/. 每个工具都能在Python的 Bio.Entrez 模块中找到对应函数，后面会详细讲到。这个模块可以保证用来查询的URL 的正确性，并且向NCBI要求的一样，每三秒钟查询的次数不超过一。
EUtils返回的输出结果通常是XML格式，我们有以下不同的方法来解析这种类型的输入文件：
使用 Bio.Entrez解析器将XML输出的解析成Python对象; 使用Python标准库中的DOM (Document Object Model)解析器; 使用Python标准库中的SAX (Simple API for XML)解析器; 把XML输出当做原始的文本文件，通过字符串查找和处理来进行解析； 对于DOM和SAX解析器，可以查看Python的文档. Bio.Entrez 中使用到的解析器将会在下面讨论.
NCBI使用DTD (Document Type Definition)文件来描述XML文件中所包含信息的结构. 大多数NCBI使用的DTD文件 格式都包含在了Biopython发行包里。当NCBI Entrez读入一个XML格式的文件的时候，Bio.Entrez 将会使用DTD文件。
有时候，你可能会发现与某种特殊的XML相关的DTD文件在Biopython发行包里面不存在。当NCBI升级它的 DTD文件的时候，这种情况可能发生。如果发生这种情况，Entrez.read 将会显示丢失的DTD文件名字和URL的 警示信息。解析器会通过互联网获取缺失的DTD文件，让XML的分析继续正常进行。如果本地存在对应的DTD文件的 话，处理起来会更快。因此，为了更快的处理，我们可以通过警示信息里面的URL来下载对应的DTD文件，将文件放在DTD 文件默认存放的文件夹 &amp;hellip;site-packages/Bio/Entrez/DTDs 。如果你没有权限进入这个文件夹，你也可以把 DTD文件放到 ~/.biopython/Bio/Entrez/DTDs 这个目录，~ 表示的是你的Home目录。因为这个目录会先于 &amp;hellip;site-packages/Bio/Entrez/DTDs 被解析器读取，所以当 &amp;hellip;site-packages/Bio/Entrez/DTDs 下面的DTD文件过时的时候，你也可以将最新版本的DTD文件放到Home目录的那个文件夹下面。当然也有其他方案，如果你 是通过源码来安装的Biopython，你可以将DTD文件放到源码的 Bio/Entrez/DTDs 文件夹下，然后重新安装Biopython。 这样会将新的DTD文件和之前的一样地安装到正确的位置。
Entrez Programming Utilities也可以生成其他格式的输出文件，比如Fasta、序列数据库里面的GenBank文件格式 或者文献数据库里面的MedLine格式 详细的访问规范 对任何连续超过100次的访问请求，请在周末时间或者避开美国的使用高峰时间。这个取决于你是否遵从。 使用这个网址 http://eutils.</description>
    </item>
    
    <item>
      <title>ch8_BLAST和其他序列搜素工具</title>
      <link>https://example.com/p/ch8_blast%E5%92%8C%E5%85%B6%E4%BB%96%E5%BA%8F%E5%88%97%E6%90%9C%E7%B4%A0%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Mon, 09 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch8_blast%E5%92%8C%E5%85%B6%E4%BB%96%E5%BA%8F%E5%88%97%E6%90%9C%E7%B4%A0%E5%B7%A5%E5%85%B7/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
生物序列的鉴定是生物信息工作的主要部分。有几个工具像BLAST（可能是最流行 的），FASTA ，HMMER还有许多其它的都有这个功能，每个工具都有独特的算法和 途径。一般来说，这些工具都是用你的序列在数据库中搜索可能的匹配。随着序列 数量的增加（匹配数也会随之增加），将会有成百上千的可能匹配，解析这些结果 无疑变得越来越困难。理所当然，人工解析搜索结果变得不可能。而且你可能会同 时用几种不同的搜索工具，每种工具都有独特的统计方法、规则和输出格式。可以 想象，同时用多种工具搜索多条序列是多么恐怖的事。 我们对此非常了解，所以我们在Biopython构建了 Bio.SearchIO 亚模块。Bio.SearchIO 模块使从搜索结果中提取信息变得简单，并且可以处理不同工具 的不同标准和规则。SearchIO 和BioPerl中模块名称一致。 在本章中，我们将学习 Bio.SearchIO 的主要功能，了解它可以做什么。我 们将使用两个主要的搜索工具：BLAST和FASTA。它们只是用来阐明思路，你可以轻 易地把工作流程应用到 Bio.SearchIO 支持的其他工具中
SearchIO对象模型 尽管多数搜索工具的输出风格极为不同，但是它们蕴含的理念很相似：
输出文件可能包含一条或更多的搜索查询的结果。 在每次查询中，你会在给定的数据库中得到一个或更多的hit（命中）。 在每个hit中，你会得到一个或更多包含query（查询)序列和数据库序列实际比对的区域。 一些工具如BLAT和Exonerate可能会把这些区域分成几个比对片段（或在BLAT中 称为区块，在Exonerate中称为可能外显子）。这并不是很常见，像BLAST和 HMMER就不这么做。 一些名词介绍 知道这些共性之后，我们决定把它们作为创造 Bio.SearchIO 对象模型的基础。对 象模型是Python对象组成的嵌套分级系统，每个对象都代表一个上面列出的概念。这些对 象是：
QueryResult，代表单个搜索查询。 Hit，代表单个的数据库hit。Hit 对象包含在 QueryResult 中， 每个 QueryResult 中有0个或多个 Hit 对象。 HSP (high-scoring pair（高分片段）)，代表query和hit序列中有 意义比对的区域。HSP 对象包含在 Hit 对象中，而且每个 Hit 有一个 或更多的 HSP 对象。 HSPFragment，代表query和hit序列中单个的邻近比对。 HSPFragment 对象包含在 HSP 对象中。多数的搜索工具如BLAST和HMMER把 HSP 和 HSPFragment 合并，因为一个 HSP 只含有一个 HSPFragment。但是 像BLAT和Exonerate会产生含有多个 HSPFragment 的 HSP 。似乎有些困 惑？不要紧，稍后我们将详细介绍这两个对象。 这四个对象是当你用 Bio.</description>
    </item>
    
    <item>
      <title>ch7_blast</title>
      <link>https://example.com/p/ch7_blast/</link>
      <pubDate>Sat, 07 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch7_blast/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
这章是来解决使用Blast的一些麻烦地方——处理大量的BLAST比对结果数据 通常是困难的，还有怎么自动运行BLAST序列比对。 使用BLAST通常可以分成2个步。这两步都可以用上Biopython。第一步，提交你的查询 序列,运行BLAST，并得到输出数据。第二步，用Python解析BLAST的输出，并作进一步分析。 我们将在一个Python脚本里调用NCBI在线BLAST服务来开始这章的内容。
通过Internet运行BLAST 我们使用 Bio.Blast.NCBIWWW 模块的函数 qblast() 来调用在线版本的BLAST。 这个函数有3个必需的参数:
第一个参数是用来搜索的blast程序，这是小写的字符串。对这个参数的选项和描述可以在 http://www.ncbi.nlm.nih.gov/BLAST/blast_program.shtml. 查到。目前 qblast 只支持 blastn, blastp, blastx, tblast 和 tblastx. 第二个参数指定了将要搜索的数据库。同样地，这个参数的选项也可以在 http://www.ncbi.nlm.nih.gov/BLAST/blast_databases.shtml. 查到 第三个参数是一个包含你要查询序列的字符串。这个字符串可以是序列的本身 （fasta格式的），或者是一个类似GI的id。 qblast 函数还可以接受许多其他选项和参数。这些参数基本上类似于你在BLAST网站页面 能够设置的参数。在这里我们只强调其中的一些： qblast 函数可以返回多种格式的BLAST结果。你可以通过可选参数 format_type 指定格式关键字为：&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;Text&amp;rdquo;, &amp;ldquo;ASN.1&amp;rdquo;, 或 &amp;ldquo;XML&amp;rdquo; 。默认 格式是 &amp;ldquo;XML&amp;rdquo; ，这是解析器期望的格式， 参数 expect 指定期望值，即阀值 e-value 请注意，NCBI BLAST 网站上的默认参数和QBLAST的默认参数不完全相同。如果你得到了 不同的结果，你就需要检查下参数设置 （比如，e-value阈值和gap值）. 简单的例子 举个例子，如果你有条核酸序列，想使用BLAST对核酸数据库（nt）进行搜索，已知这条查询序列的GI号， 你可以这样做：
&amp;gt;&amp;gt;&amp;gt; from Bio.Blast import NCBIWWW &amp;gt;&amp;gt;&amp;gt; result_handle = NCBIWWW.qblast(&amp;#34;blastn&amp;#34;, &amp;#34;nt&amp;#34;, &amp;#34;8332116&amp;#34;) 或者，我们想要查询的序列在FASTA文件中，那么我们只需打开这个文件并把这条记录读入到字符串，然后用这个字符串作为查询参数:</description>
    </item>
    
    <item>
      <title>Ch6_Multiple_Sequence_Alignment_objects</title>
      <link>https://example.com/p/ch6_multiple_sequence_alignment_objects/</link>
      <pubDate>Fri, 06 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch6_multiple_sequence_alignment_objects/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
MSA的基本原理 多序列比对（Multiple Sequence Alignment, MSA）是指对多个序列进行对位排列。 这通常需要保证序列间的等同位点处在同一列上，并通过引进小横线（-）以保证最终的序列具有相同的长度。这种序列比对可以视作是由字符组成的矩阵。在Biopython中，多序列比对中每一个序列是以 SeqRecord 对象来表示的。 这里我们介绍一种新的对象 – MultipleSeqAlignment 来表示这样一类数据，我们还将介绍 Bio.AlignIO 模块来读写不同格式的多序列比对数据（ Bio.AlignIO 在设计上与之前介绍的 Bio.SeqIO 模块是类似的）。Biopython中， Bio.SeqIO 和 Bio.AlignIO 都能读写各种格式的多序列比对数据。在实际处理中，使用哪一个模块取决于用户需要对数据进行何种操作。
读取多序列比对数据 在Biopython中，有两种方法读取多序列比对数据：
io.AlignIO.read() 只能读取一个多序列比对，在大多数情况下，你所遇到的文件仅仅包括一个多序列比对。这时，你应该使用 Bio.AlignIO.read() ，这将返回一个 MultipleSeqAlignment 对象 Bio.AlignIO.parse() 可以依次读取多个序列比对数据，将会返回一个 MultipleSeqAlignment 的 迭代器（iterator） 。迭代器往往在循环中使用。在实际数据分析过程中会时常处理包含有多个多序列比对的文件 这两个函数的参数： 第一个参数为包含有多序列比对数据的 句柄（handle） 。在实际操作中，这往往是一个打开的文件/文件名 第二个参数为多序列比对文件格式（小写）（http://biopython.org/wiki/AlignIO 这里可以看支持哪几种格式） Bio.AlignIO 模块还接受一个可选参数 seq_count，它可以处理不确定的多序列比对格式，或者包含有多个序列的排列 单一的序列比对 F05371_seed.sth文件是一个FAM数据库中Phage_Coat_Gp8的种子排列（PF05371） 你会注意到，以上输出截短了中间一部分序列的内容。你也可以很容易地通过控制多序列比对中每一条序列（作为 SeqRecord 对象）来输出你所喜欢的格式。例如 你是否已经注意到以上原始数据文件中包含有蛋白数据库（PDB）交叉引用以及相关二级结构的信息？可以尝试以下代码：record.dbxrefs 多个序列比对 如果你想用 Bio.AlignIO 来读取这个文件，你可以使用： 与 Bio.SeqIO.parse 一样， Bio.SeqIO.parse() 将返回一个迭代器（iterator）。如果你希望把所有的序列比对都读取到内存中，以下代码将把它们储存在一个列表对象里 含糊的序列比对 将多个序列比对以FASTA格式储存并不方便。然而，在某些情况下，如果你一定要这么做， Bio.AlignIO 依然能够处理上述情形（但是所有的序列比对必须都含有相同的序列）。一个很常见的例子是，我们经常会使用EMBOSS工具箱中的 needle 和 water 来产生许多两两间的序列比对 —— 然而在这种情况下，你可以指定数据格式为“emboss”，Bio.</description>
    </item>
    
    <item>
      <title>Ch5_Sequence_Input_Output</title>
      <link>https://example.com/p/ch5_sequence_input_output/</link>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch5_sequence_input_output/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
The workhorse function Bio.SeqIO.parse() is used to read in sequence data as SeqRecord objects. This function expects two arguments:
The first argument is a handle to read the data from, or a filename. A The second argument is a lower case string specifying sequence format The Bio.SeqIO.parse() function returns an iterator which gives SeqRecord objects. Iterators are typically used in a for loop as shown below. Sometimes you&amp;rsquo;ll find yourself dealing with files which contain only a single record.</description>
    </item>
    
    <item>
      <title>ch3_seq_object</title>
      <link>https://example.com/p/ch3_seq_object/</link>
      <pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch3_seq_object/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
Sequences are essentially strings of letters like AGTACACTGGT, which seems very natural since this is the most common way that sequences are seen in biological file formats. The most important difference between Seq objects and standard Python strings is they have different methods. Although the Seq object supports many of the same methods as a plain string, its translate()method differs by doing biological translation, and there are also additional biologically relevant methods like reverse_complement().</description>
    </item>
    
    <item>
      <title>Ch4_Sequence_annotation_object_序列注释信息</title>
      <link>https://example.com/p/ch4_sequence_annotation_object_%E5%BA%8F%E5%88%97%E6%B3%A8%E9%87%8A%E4%BF%A1%E6%81%AF/</link>
      <pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch4_sequence_annotation_object_%E5%BA%8F%E5%88%97%E6%B3%A8%E9%87%8A%E4%BF%A1%E6%81%AF/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
help查看帮助 SeqRecord对象的属性 创建SeqRecord对象 直接用Seq 可以直接赋予其相关信息 annotations的字典 letter_annotations的字典 读取fasta(NCBI)创建SeqRecord objects 读取GenBank files （GenBamk）创建SeqRecord对象 这里以NC_005816.gb为例 同样用SeqIO读取 SeqFeatrue objects 属性： Postions / locations The key idea about each SeqFeature object is to describe a region on a parent sequence, for which we use a location object, typically describing a range between two positions. Two try to clarify the terminology we&amp;rsquo;re using
locations的分类 具体的可以百度看下
FeatureLocation object CompoundLocation object positions的分类 具体的可以百度看下</description>
    </item>
    
    <item>
      <title>ch1&#43;ch2&#43;安装&#43;引用&#43;快速上手</title>
      <link>https://example.com/p/ch1-ch2-%E5%AE%89%E8%A3%85-%E5%BC%95%E7%94%A8-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</link>
      <pubDate>Tue, 03 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ch1-ch2-%E5%AE%89%E8%A3%85-%E5%BC%95%E7%94%A8-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</guid>
      <description>biopython官方地址：https://biopython.org/
github地址：https://github.com/biopython/biopython/blob/master/
中文版教程：https://biopython-cn.readthedocs.io/zh_CN/latest/cn/chr06.html
biopython包的说明（具体到每个模块了）：https://www.osgeo.cn/biopython/Bio.HMM.DynamicProgramming.html
安装biopython的库 安装命令：
pip install biopython 从biopython 1.77开始支持py3
这样可以查看biopython版本 FAQ PAGES https://docs.python.org/3/faq/index.html question email http://biopython.org/wiki/Mailing_lists 引用说明 Peter J. A. Cock, Tiago Antao, Jexb;rey T. Chang, Brad A. Chapman, Cymon J. Cox, Andrew Dalke, Iddo
Friedberg, Thomas Hamelryck, Frank Kauxb;, Bartek Wilczynski, Michiel J. L. de Hoon: \Biopython:
freely available Python tools for computational molecular biology and bioinformatics&amp;quot;. Bioinformatics
25 (11), 1422{1423 (2009). https://doi.org/10.1093/bioinformatics/btp163 快速上手 Seq对象 创建Seq对象 属性：SeqRecord Seq对象都会被赋予 SeqRecord的属性，这个属性会含有seq的信息（如 identifier, name and description）</description>
    </item>
    
    <item>
      <title>pandas读取文件的read_csv()方法的parse_dates参数</title>
      <link>https://example.com/p/pandas%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6%E7%9A%84read_csv%E6%96%B9%E6%B3%95%E7%9A%84parse_dates%E5%8F%82%E6%95%B0/</link>
      <pubDate>Sun, 18 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/pandas%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6%E7%9A%84read_csv%E6%96%B9%E6%B3%95%E7%9A%84parse_dates%E5%8F%82%E6%95%B0/</guid>
      <description>parse_dates参数： 将csv的时间字符串转换成日期格式 第一种 第二种 第三种 第四种 </description>
    </item>
    
    <item>
      <title>安装虚拟机</title>
      <link>https://example.com/p/%E5%AE%89%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BA/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%AE%89%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BA/</guid>
      <description> 再点击完成
点击开启虚拟机 Try and install
等待即可
重启计算
安装tools
点击虚拟机
安装tool
双击将tar.gz取出来
将其复制到home下
tar -xzvf 解压
进入文件夹
sudo ./vmware-install.pl
接下来N多的enter，N多的YES，自己慢慢按吧
重启虚拟机
若还没有全屏显示，则将虚拟机的【查看】-&amp;gt;【自动调整大小】-&amp;gt;【自适应客户机】,都选上。即可实现全屏。
安装vmware tools实现全屏后，即也实现了在主机（WIN7）和虚拟机VMware （ubuntu）间
直接拖拽文件 联网 </description>
    </item>
    
    <item>
      <title>《机器学习个人笔记完整版》</title>
      <link>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%E5%AE%8C%E6%95%B4%E7%89%88/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%E5%AE%8C%E6%95%B4%E7%89%88/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>py_basic_Q91-100</title>
      <link>https://example.com/p/py_basic_q91-100/</link>
      <pubDate>Mon, 14 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_basic_q91-100/</guid>
      <description>这是为了加强Python基础，在Github上找来的练习，地址：https://github.com/darkprinx/break-the-ice-with-python
Question 91 Question Please write a program which accepts a string from console and print it in reverse order.
**Example:
If the following string is given as input to the program:***
rise to vote sir
Then, the output of the program should be:
ris etov ot esir
Hints Use list[::-1] to iterate a list in a reverse order.
Solutions:
a = input() #逆序输出直接设定步长就好了 #运用切片的步长即可 -1 print(a[::-1]) rise to vote sir ris etov ot esir Question 92 Question Please write a program which accepts a string from console and print the characters that have even indexes.</description>
    </item>
    
    <item>
      <title>py_basic_Q81-90</title>
      <link>https://example.com/p/py_basic_q81-90/</link>
      <pubDate>Sun, 13 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_basic_q81-90/</guid>
      <description>这是为了加强Python基础，在Github上找来的练习，地址：https://github.com/darkprinx/break-the-ice-with-python
Question 81 Question By using list comprehension, please write a program to print the list after removing numbers which are divisible by 5 and 7 in [12,24,35,70,88,120,155].
Hints Use list comprehension to delete a bunch of element from a list.
Solutions:
[ i for i in [12,24,35,70,88,120,155] if i%(5*7)!=0] [12, 24, 88, 120, 155] Question 82 Question By using list comprehension, please write a program to print the list after removing the 0th, 2nd, 4th,6th numbers in [12,24,35,70,88,120,155].</description>
    </item>
    
    <item>
      <title>1_Getting_Started_Menu_Version-1</title>
      <link>https://example.com/p/1_getting_started_menu_version-1/</link>
      <pubDate>Sat, 12 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/1_getting_started_menu_version-1/</guid>
      <description>Part 1:Manipulation, Selection, and Chains Fetch:获取结构文件 顶部菜单栏menu选择 这里获取1zik
File... Fetch by ID... 会弹出下图右边的那个窗口，选择对应的数据库database,输入对应的结构ID即可 Action: 改变结构展现的形式 Cihmrea默认读取结构后，展现为ribbon带状，tan棕黄色 可以通过 顶部action 选择展现其他形式 (&amp;hellip; 代表空格，即需要点击鼠标才会出现后面的选项)
Actions... Atoms/Bonds... show 选择原子模式看看，从右图的结果可以看出，同PyMOL一样，结构的展现形式都是叠加上去的，即上一个展示形式仍然存在 注意下，不同的原子（主要是杂原子（非C原子））展现的颜色也不一样，即byelement
O原子：红色 N原子：蓝色 更多的，如下图片所示 图片原来源[^2] ,经过处理 恢复ribbon带状的展现形式
Actions... Ribbon... hide Actions... Ribbon... show 鼠标的基本操作和属性 默认的鼠标设置下 左键旋转 滑轮 XY方向上放大缩小 右键 放大缩小 （需要长按） 我觉得滑轮和右键没啥区别
调整 如果需要其他鼠标设置可以去顶部menu菜单栏自行调整
Favorites... Preferences [category] Mouse 还是比较喜欢默认的，所以其他模式的没研究过
鼠标接触蛋白的作用 显示残基的信息 格式为：
res-name res-num.chain atom-name 方便展示，我重新加上了atom/bond的形式，下面的图上半部分是这个蛋白的pdb文件，下面是对应AA在Chimera鼠标轻触显示的信息（以11号的GLU谷氨酸，E，为例子）
轻触的是键时,结果的格式是： 氨基酸名字 位置.链 原子-原子(互相连接的两个原子) 距离 如图中结果说明，这个蛋白A链11号上的位置是谷氨酸，这个氨基酸Ca与Cb成键的距离为1.520A 轻触的是的单个原子时，结果的格式是： 氨基酸名字 位置.链 所选原子名称 鼠标多选AA Ctrl + 单击 这能选中单个AA Shift + Ctrl + 单击 可以连续追加选中多个AA 补充 （keyboard - up） 但是实际上，这样选的可能还不是完整的整个AA，可能是其AA上的某个原子元素，可以通过键盘的方向键（上），选中整个AA（即这样可以通过单个原子或者元素，选到整个氨基酸） 等同于menu的 Select.</description>
    </item>
    
    <item>
      <title>py_basic_Q71-80</title>
      <link>https://example.com/p/py_basic_q71-80/</link>
      <pubDate>Sat, 12 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_basic_q71-80/</guid>
      <description>这是为了加强Python基础，在Github上找来的练习，地址：https://github.com/darkprinx/break-the-ice-with-python
Question 71 Question Please write a program to output a random number, which is divisible by 5 and 7, between 10 and 150 inclusive using random module and list comprehension.
Hints Use random.choice() to a random element from a list.
Solutions:
import random result = [ i for i in range(10,151) if i%(5*7)==0] random.choice(result) 105 Question 72 Question Please write a program to generate a list with 5 random numbers between 100 and 200 inclusive.</description>
    </item>
    
    <item>
      <title>py_basic_Q61-70</title>
      <link>https://example.com/p/py_basic_q61-70/</link>
      <pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_basic_q61-70/</guid>
      <description>这是为了加强Python基础，在Github上找来的练习，地址：https://github.com/darkprinx/break-the-ice-with-python
Question 61 Question The Fibonacci Sequence is computed based on the following formula:
$f(n)=0$ if n=0
$f(n)=1$ if n=1
$f(n)=f(n-1)+f(n-2)$ if n&amp;gt;1
Please write a program to compute the value of f(n) with a given n input by console.
**_Example:
If the following n is given as input to the program:_**
7
Then, the output of the program should be:
13
In case of input data being supplied to the question, it should be assumed to be a console input.</description>
    </item>
    
    <item>
      <title>py_basic_Q51-60</title>
      <link>https://example.com/p/py_basic_q51-60/</link>
      <pubDate>Thu, 10 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_basic_q51-60/</guid>
      <description>这是为了加强Python基础，在Github上找来的练习，地址：https://github.com/darkprinx/break-the-ice-with-python
Question 51 Question Write a function to compute 5/0 and use try/except to catch the exceptions.
Hints Use try/except to catch exceptions.
Solutions:
#首先要知道错误的类型 def Q51(): return 5/0 Q51() # ZeroDivisionError 可以看到是这个wrong类型 --------------------------------------------------------------------------- ZeroDivisionError Traceback (most recent call last) &amp;lt;ipython-input-2-1c67e02e3140&amp;gt; in &amp;lt;module&amp;gt; 2 def Q51(): 3 return 5/0 ----&amp;gt; 4 Q51() &amp;lt;ipython-input-2-1c67e02e3140&amp;gt; in Q51() 1 #首先要知道错误的类型 2 def Q51(): ----&amp;gt; 3 return 5/0 4 Q51() ZeroDivisionError: division by zero #try/except捕获异常 def Q51(): return 5/0 try: Q51() #except 后面可以指定错误类型 / 也可以不指定，则捕获全部类型 except ZeroDivisionError as ZD: print(&amp;#34;不能除于零！&amp;#34;) except: print(&amp;#34;唔知道！&amp;#34;) 不能除于零！ Question 52 Question Define a custom exception class which takes a string message as attribute.</description>
    </item>
    
    <item>
      <title>py_basic_Q41-50</title>
      <link>https://example.com/p/py_basic_q41-50/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_basic_q41-50/</guid>
      <description>这是为了加强Python基础，在Github上找来的练习，地址：https://github.com/darkprinx/break-the-ice-with-python
Question 41 Question: Write a program which can map() to make a list whose elements are square of elements in [1,2,3,4,5,6,7,8,9,10].
Hints: Use map() to generate a list.Use lambda to define anonymous functions.
Solutions:
#温习下map的使用，传入方法和可迭代对象 liss = [1,2,3,4,5,6,7,8,9,10] print(list(map(lambda i:i**2,liss))) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] Question 42 Question: Write a program which can map() and filter() to make a list whose elements are square of even number in [1,2,3,4,5,6,7,8,9,10].</description>
    </item>
    
    <item>
      <title>py_basic_Q31-40</title>
      <link>https://example.com/p/py_basic_q31-40/</link>
      <pubDate>Tue, 08 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_basic_q31-40/</guid>
      <description>这是为了加强Python基础，在Github上找来的练习，地址：https://github.com/darkprinx/break-the-ice-with-python
Question 31 Question: Define a function which can print a dictionary where the keys are numbers between 1 and 20 (both included) and the values are square of keys.
Hints: Use dict[key]=value pattern to put entry into a dictionary.Use ** operator to get power of a number.Use range() for loops.
Solutions:
def Q31(): #用字典生成式 dict = {i:i**2 for i in range(1,21)} return dict Q31() {1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81, 10: 100, 11: 121, 12: 144, 13: 169, 14: 196, 15: 225, 16: 256, 17: 289, 18: 324, 19: 361, 20: 400} Question 32 Question: Define a function which can generate a dictionary where the keys are numbers between 1 and 20 (both included) and the values are square of keys.</description>
    </item>
    
    <item>
      <title>py_basic_Q21-30</title>
      <link>https://example.com/p/py_basic_q21-30/</link>
      <pubDate>Mon, 07 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_basic_q21-30/</guid>
      <description>这是为了加强Python基础，在Github上找来的练习，地址：https://github.com/darkprinx/break-the-ice-with-python
Question 21 Question: A robot moves in a plane starting from the original point (0,0). The robot can move toward UP, DOWN, LEFT and RIGHT with a given steps. The trace of robot movement is shown as the following:
UP 5 DOWN 3 LEFT 3 RIGHT 2 The numbers after the direction are steps. Please write a program to compute the distance from current position after a sequence of movement and original point.</description>
    </item>
    
    <item>
      <title>py_basic_Q1-10</title>
      <link>https://example.com/p/py_basic_q1-10/</link>
      <pubDate>Sun, 06 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_basic_q1-10/</guid>
      <description>这是为了加强Python基础，在Github上找来的练习，地址：https://github.com/darkprinx/break-the-ice-with-python
Question 1 Question: **_Write a program which will find all such numbers which are divisible by 7 but are not a multiple of 5,
between 2000 and 3200 (both included).The numbers obtained should be printed in a comma-separated sequence on a single line._**
Hints: Consider use range(#begin, #end) method.
Solutions:
Using for loops #注意range是左闭右开，range(a,b)产生[a,b)区间的int for i in range(2000,3201): if i%7 == 0 and i%5 != 0: print(i,end=&amp;#34;,&amp;#34;)#end=&amp;#34;,&amp;#34;每个对象的结尾以，分开 print(&amp;#34;\b&amp;#34;)#光标倒退指定长度的字符，最会一个的，去掉 2002,2009,2016,2023,2037,2044,2051,2058,2072,2079,2086,2093,2107,2114,2121,2128,2142,2149,2156,2163,2177,2184,2191,2198,2212,2219,2226,2233,2247,2254,2261,2268,2282,2289,2296,2303,2317,2324,2331,2338,2352,2359,2366,2373,2387,2394,2401,2408,2422,2429,2436,2443,2457,2464,2471,2478,2492,2499,2506,2513,2527,2534,2541,2548,2562,2569,2576,2583,2597,2604,2611,2618,2632,2639,2646,2653,2667,2674,2681,2688,2702,2709,2716,2723,2737,2744,2751,2758,2772,2779,2786,2793,2807,2814,2821,2828,2842,2849,2856,2863,2877,2884,2891,2898,2912,2919,2926,2933,2947,2954,2961,2968,2982,2989,2996,3003,3017,3024,3031,3038,3052,3059,3066,3073,3087,3094,3101,3108,3122,3129,3136,3143,3157,3164,3171,3178,3192,3199, Using generators and list comprehension #进阶一点的写法，用生成器和列表理解式,理解式中是以空格分开的 [ print(i,end=&amp;#34;,&amp;#34;) for i in range(2000,3201) if i%7 == 0 and i%5 !</description>
    </item>
    
    <item>
      <title>py_basic_Q11-20</title>
      <link>https://example.com/p/py_basic_q11-20/</link>
      <pubDate>Sun, 06 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/py_basic_q11-20/</guid>
      <description>这是为了加强Python基础，在Github上找来的练习，地址：https://github.com/darkprinx/break-the-ice-with-python
Question 11 Question Write a program which accepts a sequence of comma separated 4 digit binary numbers as its input and then check whether they are divisible by 5 or not. The numbers that are divisible by 5 are to be printed in a comma separated sequence.
Example:
0100,0011,1010,1001
Then the output should be:
1010
Notes: Assume the data is input by console.
Hints: In case of input data being supplied to the question, it should be assumed to be a console input.</description>
    </item>
    
    <item>
      <title>《利用Python进行数据分析》</title>
      <link>https://example.com/p/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</link>
      <pubDate>Tue, 25 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>test</title>
      <link>https://example.com/p/test/</link>
      <pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/test/</guid>
      <description>这是正文内容！！ 随便放上一张照片看看 image 这是一个标题测试 这是另一个标题测试 这是标题测试 这是另一个图片测试 image </description>
    </item>
    
    <item>
      <title>《看漫画学PYTHON》</title>
      <link>https://example.com/p/%E7%9C%8B%E6%BC%AB%E7%94%BB%E5%AD%A6python/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%9C%8B%E6%BC%AB%E7%94%BB%E5%AD%A6python/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>python基础整理</title>
      <link>https://example.com/p/python%E5%9F%BA%E7%A1%80%E6%95%B4%E7%90%86/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/python%E5%9F%BA%E7%A1%80%E6%95%B4%E7%90%86/</guid>
      <description>这是看完pythond的书后，再过一遍基础知识的post，原文地址：https://github.com/fengdu78/Data-Science-Notes/tree/master/1.python-basic 本章是python语言的基础部分，也是后续内容的基础。
Python数据类型 1.1 字符串 在Python中用引号引起来的字符集称之为字符串，比如：&amp;lsquo;hello&amp;rsquo;、&amp;ldquo;my Python&amp;rdquo;、&amp;ldquo;2+3&amp;quot;等都是字符串
Python中字符串中使用的引号可以是单引号、双引号跟三引号
print (&amp;#39;hello world!&amp;#39;) hello world! c = &amp;#39;It is a &amp;#34;dog&amp;#34;!&amp;#39; print (c) It is a &amp;#34;dog&amp;#34;! c1= &amp;#34;It&amp;#39;s a dog!&amp;#34; print (c1) It&amp;#39;s a dog! c2 = &amp;#34;&amp;#34;&amp;#34;hello world !&amp;#34;&amp;#34;&amp;#34; print (c2) hello world ! 转义字符&amp;rsquo;&#39; 转义字符\可以转义很多字符，比如\n表示换行，\t表示制表符，字符\本身也要转义，所以\表示的字符就是\
print (&amp;#39;It\&amp;#39;s a dog!&amp;#39;) print (&amp;#34;hello world!\nhello Python!&amp;#34;) print (&amp;#39;\\\t\\&amp;#39;) It&amp;#39;s a dog! hello world! hello Python! \	\ 原样输出引号内字符串可以使用在引号前加r
print (r&amp;#39;\\\t\\&amp;#39;) \\\t\\ 子字符串及运算 s = &amp;#39;Python&amp;#39; print( &amp;#39;Py&amp;#39; in s) print( &amp;#39;py&amp;#39; in s) True False 取子字符串有两种方法，使用[]索引或者切片运算法[:]，这两个方法使用面非常广</description>
    </item>
    
    <item>
      <title>python基础_1</title>
      <link>https://example.com/p/python%E5%9F%BA%E7%A1%80_1/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/python%E5%9F%BA%E7%A1%80_1/</guid>
      <description>这是看完pythond的书后，再过一遍基础知识的post，原文地址：https://github.com/fengdu78/Data-Science-Notes/tree/master/1.python-basic
print name = input(&amp;#34;What is your name?&amp;#34;) print(&amp;#34;Hello &amp;#34;+name ) # 或者print(&amp;#34;Hello&amp;#34;,name ),print中逗号分隔直接将字符串用空格分隔，若用+号连接，并且想留空格，则在前一字符串留空格即可 What is your name?Mike Hello Mike 输入输出 username=input(&amp;#34;username:&amp;#34;) password=input(&amp;#34;password:&amp;#34;) print(username,password) username:111 password:666 111 666 格式输入输出 # 第一种方法 name=input(&amp;#34;Name:&amp;#34;) age=input(&amp;#34;age:&amp;#34;) job=input(&amp;#34;job:&amp;#34;) info=&amp;#39;&amp;#39;&amp;#39;---------info of ---------&amp;#39;&amp;#39;&amp;#39; + &amp;#39;&amp;#39;&amp;#39; Name:&amp;#39;&amp;#39;&amp;#39;+name+&amp;#39;&amp;#39;&amp;#39; Age:&amp;#39;&amp;#39;&amp;#39;+age+&amp;#39;&amp;#39;&amp;#39; Job:&amp;#39;&amp;#39;&amp;#39;+job print(info) Name:Mike age:28 job:worker ---------info of --------- Name:Mike Age:28 Job:worker # 第二种方法 name=input(&amp;#34;Name:&amp;#34;) age=int(input(&amp;#34;age:&amp;#34;)) #如果不用int()就会报错(虽然输入为数字，但是print(type(age))为str型)，因为python如果不强制类型转化，就会默认字符型 job=input(&amp;#34;job:&amp;#34;) info=&amp;#39;&amp;#39;&amp;#39;---------info of --------- Name:%s Age:%d Job:%s&amp;#39;&amp;#39;&amp;#39;%(name,age,job) print(info) Name:Mike age:28 job:worker ---------info of --------- Name:Mike Age:28 Job:worker # 第三种方法 name=input(&amp;#34;Name:&amp;#34;) age=int(input(&amp;#34;age:&amp;#34;)) #如果不用int()就会报错(虽然输入为数字，但是print(type(age))为str型)，因为python如果不强制类型转化，就会默认字符型 job=input(&amp;#34;job:&amp;#34;) info=&amp;#39;&amp;#39;&amp;#39;---------info of --------- Name:{_name} Age:{_age} Job:{_job}&amp;#39;&amp;#39;&amp;#39;.</description>
    </item>
    
    <item>
      <title>python基础_2</title>
      <link>https://example.com/p/python%E5%9F%BA%E7%A1%80_2/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/python%E5%9F%BA%E7%A1%80_2/</guid>
      <description>这是看完pythond的书后，再过一遍基础知识的post，原文地址：https://github.com/fengdu78/Data-Science-Notes/tree/master/1.python-basic
编码变换 # utf-8与gbk互相转化需要通过Unicode作为中介 s=&amp;#34;我爱北京天安门&amp;#34; # 默认编码为Unicode print(s.encode(&amp;#34;gbk&amp;#34;)) # Unicode可直接转化为gbk b&amp;#39;\xce\xd2\xb0\xae\xb1\xb1\xbe\xa9\xcc\xec\xb0\xb2\xc3\xc5&amp;#39; print(s.encode(&amp;#34;utf-8&amp;#34;)) # Unicode可直接转化为utf-8 b&amp;#39;\xe6\x88\x91\xe7\x88\xb1\xe5\x8c\x97\xe4\xba\xac\xe5\xa4\xa9\xe5\xae\x89\xe9\x97\xa8&amp;#39; print(s.encode(&amp;#34;utf-8&amp;#34;).decode(&amp;#34;utf-8&amp;#34;).encode(&amp;#34;gb2312&amp;#34;)) # 此时s.encode(&amp;#34;utf-8&amp;#34;)即转为utf-8了，然后转为gb2312，则需要先告诉Unicode你原先的编码是什么，即s.encode(&amp;#34;utf-8&amp;#34;).decode(&amp;#34;utf-8&amp;#34;),再对其进行编码为gb2312，即最终为s.encode(&amp;#34;utf-8&amp;#34;).decode(&amp;#34;utf-8&amp;#34;).encode(&amp;#34;gb2312&amp;#34;) b&amp;#39;\xce\xd2\xb0\xae\xb1\xb1\xbe\xa9\xcc\xec\xb0\xb2\xc3\xc5&amp;#39; 文件 f=open(&amp;#39;ly.txt&amp;#39;,&amp;#39;r&amp;#39;,encoding=&amp;#39;utf-8&amp;#39;) # 文件句柄 &amp;#39;w&amp;#39;为创建文件，之前的数据就没了 data=f.read() print(data) f.close() ��������������������我爱中华 f=open(&amp;#39;test&amp;#39;,&amp;#39;a&amp;#39;,encoding=&amp;#39;utf-8&amp;#39;) # 文件句柄 &amp;#39;a&amp;#39;为追加文件 append f.write(&amp;#34;\n阿斯达所，\n天安门上太阳升&amp;#34;) f.close() f = open(&amp;#39;ly.txt&amp;#39;, &amp;#39;r&amp;#39;, encoding=&amp;#39;utf-8&amp;#39;) # 文件句柄 for i in range(5): print(f.readline().strip()) # strip()去掉空格和回车 for line in f.readlines(): print(line.strip()) # 到第十行不打印 for index, line in enumerate(f.readlines()): if index == 9: print(&amp;#39;----我是分隔符-----&amp;#39;) continue print(line.strip()) # 到第十行不打印 count = 0 for line in f: if count == 9: print(&amp;#39;----我是分隔符-----&amp;#39;) count += 1 continue print(line.</description>
    </item>
    
    <item>
      <title>Python绘制3D图形：Axes3D数据读写</title>
      <link>https://example.com/p/python%E7%BB%98%E5%88%B63d%E5%9B%BE%E5%BD%A2axes3d%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/python%E7%BB%98%E5%88%B63d%E5%9B%BE%E5%BD%A2axes3d%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99/</guid>
      <description>第一个学的python的包就是matplotlib，特地整理了去年的学习笔记
D图形绘制需要（x,y,z)三组值，下面通过numpy和Axes3D函数会议3D图形。
其中Axes3D是mpl_toolkits.mplot3d中的一个绘图函数，mpl_toolkits.mplot3d
是Matplotlib里面专门用来画三维图的工具包
#导入 # from mpl_toolkits.mplot3d import * from mpl_toolkits.mplot3d import Axes3D import numpy as np import matplotlib.pyplot as plt #建立画布，生成数据 fig = plt.figure() ax = Axes3D(fig) x = np.arange(-8,8,0.25) y = np.arange(-8,8,0.25) #生成x、y轴数据 x,y = np.meshgrid(x,y) r = np.sqrt(x**2+y**2) #生成z值 z = np.sin(r)/r #绘图 ax.plot_surface(x,y,z,rstride=1,cstride=1) ax.contourf(x,y,z,zdir=&amp;#34;z&amp;#34;,offset=-2) plt.show() 折线图 code:
import matplotlib as mpl from mpl_toolkits.mplot3d import Axes3D import numpy as np import matplotlib.pyplot as plt mpl.rcParams[&amp;#34;legend.fontsize&amp;#34;] = 10 fig = plt.</description>
    </item>
    
  </channel>
</rss>
