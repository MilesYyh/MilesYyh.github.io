<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sklearn on å¶å®‡æµ©éšè®°åšå®¢</title>
    <link>https://example.com/tags/sklearn/</link>
    <description>Recent content in sklearn on å¶å®‡æµ©éšè®°åšå®¢</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 24 Dec 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://example.com/tags/sklearn/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>é˜¿é‡Œäº‘_ML_02_æ•°æ®æ¢ç´¢</title>
      <link>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_02_%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/</link>
      <pubDate>Sat, 24 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_02_%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/</guid>
      <description>è¿™ä¸ªpostæ˜¯è‡ªå·±å»è·Ÿç€é˜¿é‡Œäº‘å¤©æ± ä¸Šçš„æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªæ¡ˆä¾‹è·Ÿç€æ•²äº†ä¸€éä»£ç ï¼Œå¹¶ä¸”åŠ äº†è‡ªå·±çš„ç†è§£ï¼Œæ”¾åˆ°è¿™é‡Œæ¥éšæ—¶å›é¡¾
è¯»å–æ•°æ® import pandas as pd import numpy as np import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import seaborn as sns #scipy æ˜¯ä¸€ä¸ªç»Ÿè®¡å­¦ä¹ çš„åº“ from scipy import stats train_data = pd.read_csv(&amp;#34;./zhengqi_train.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) test_data = pd.read_csv(&amp;#34;./zhengqi_test.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) æŸ¥çœ‹è®­ç»ƒé›†ç‰¹å¾å˜é‡ä¿¡æ¯ train_data.head() result: code:
train_data.info result æ­¤è®­ç»ƒé›†æ•°æ®å…±æœ‰2888ä¸ªæ ·æœ¬ï¼Œæ•°æ®ä¸­æœ‰V0-V37å…±è®¡38ä¸ªç‰¹å¾å˜é‡ï¼Œå˜é‡ç±»å‹éƒ½ä¸ºæ•°å€¼ç±»å‹ï¼Œæ‰€æœ‰æ•°æ®ç‰¹å¾æ²¡æœ‰ç¼ºå¤±å€¼æ•°æ®ï¼› æ•°æ®å­—æ®µç”±äºé‡‡ç”¨äº†è„±æ•å¤„ç†ï¼Œåˆ é™¤äº†ç‰¹å¾æ•°æ®çš„å…·ä½“å«ä¹‰ï¼›targetå­—æ®µä¸ºæ ‡ç­¾å˜é‡
code:
test_data.info result: æµ‹è¯•é›†æ•°æ®å…±æœ‰1925ä¸ªæ ·æœ¬ï¼Œæ•°æ®ä¸­æœ‰V0-V37å…±è®¡38ä¸ªç‰¹å¾å˜é‡ï¼Œå˜é‡ç±»å‹éƒ½ä¸ºæ•°å€¼ç±»å‹
æŸ¥çœ‹æ•°æ®ç»Ÿè®¡ä¿¡æ¯ train_data.describe() result: code:
test_data.describe() result: ä¸Šé¢æ•°æ®æ˜¾ç¤ºäº†æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œä¾‹å¦‚æ ·æœ¬æ•°ï¼Œæ•°æ®çš„å‡å€¼meanï¼Œæ ‡å‡†å·®stdï¼Œæœ€å°å€¼ï¼Œæœ€å¤§å€¼ç­‰
æŸ¥çœ‹æ•°æ®å­—æ®µä¿¡æ¯ code:
train_data.head() result: ä¸Šé¢æ˜¾ç¤ºè®­ç»ƒé›†å‰5æ¡æ•°æ®çš„åŸºæœ¬ä¿¡æ¯ï¼Œå¯ä»¥çœ‹åˆ°æ•°æ®éƒ½æ˜¯æµ®ç‚¹å‹æ•°æ®ï¼Œæ•°æ®éƒ½æ˜¯æ•°å€¼å‹è¿ç»­å‹ç‰¹å¾
code:
test_data.head() result: ç”»ç®±å½¢å›¾æ¢ç´¢æ•°æ® code:
#æŒ‡å®šç»˜å›¾å¯¹è±¡çš„å®½å’Œé«˜ fig = plt.figure(figsize=(4,8)) # orientï¼š&amp;#34;v&amp;#34;|&amp;#34;h&amp;#34; ç”¨äºæ§åˆ¶å›¾åƒä½¿æ°´å¹³è¿˜æ˜¯ç«–ç›´æ˜¾ç¤º sns.</description>
    </item>
    
    <item>
      <title>é˜¿é‡Œäº‘_ML_03_ç‰¹å¾å·¥ç¨‹</title>
      <link>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_03_%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</link>
      <pubDate>Sat, 24 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_03_%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</guid>
      <description>è¿™ä¸ªpostæ˜¯è‡ªå·±å»è·Ÿç€é˜¿é‡Œäº‘å¤©æ± ä¸Šçš„æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªæ¡ˆä¾‹è·Ÿç€æ•²äº†ä¸€éä»£ç ï¼Œå¹¶ä¸”åŠ äº†è‡ªå·±çš„ç†è§£ï¼Œæ”¾åˆ°è¿™é‡Œæ¥éšæ—¶å›é¡¾
import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) #ä»scipyä¸­å¯¼å…¥statsç»Ÿè®¡å‡½æ•° from scipy import stats plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False train_data = pd.read_csv(&amp;#34;./zhengqi_train.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) test_data = pd.read_csv(&amp;#34;./zhengqi_test.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) train_data.describe() result: å¼‚å¸¸å€¼åˆ†æ plt.figure(figsize=(18,10)) #xä¼ å…¥çš„æ¯ä¸€åˆ—çš„ç‰¹å¾å€¼ï¼ˆæ•°å€¼ï¼‰ï¼Œlabelsä¼ å…¥çš„æ˜¯æ¯ä¸ªç‰¹å¾å€¼çš„åå­—å³åˆ—å å°±æ˜¯å›¾ä¸­çš„xè½´çš„åå­— plt.boxplot(x=train_data.values,labels=train_data.columns) plt.hlines([7.5,-7.5],0,40,colors=&amp;#34;r&amp;#34;) plt.show() result: åˆ é™¤å¼‚å¸¸å€¼ train_data = train_data[train_data[&amp;#34;V9&amp;#34;]&amp;gt;-7.5] train_data.describe() result: code:
train_data.head() result: æœ€å¤§æœ€å°å€¼å½’ä¸€åŒ– code:
from sklearn import preprocessing feature_columns = [col for col in train_data.columns if col not in [&amp;#34;target&amp;#34;]] #æ³¨æ„MinScalerä¼ å…¥çš„æ˜¯æ¯ä¸€åˆ—çš„æ•°æ® min_max_scaler = preprocessing.</description>
    </item>
    
    <item>
      <title>é˜¿é‡Œäº‘_ML_04_æ¨¡å‹è®­ç»ƒ</title>
      <link>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_04_%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/</link>
      <pubDate>Sat, 24 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_04_%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/</guid>
      <description>è¿™ä¸ªpostæ˜¯è‡ªå·±å»è·Ÿç€é˜¿é‡Œäº‘å¤©æ± ä¸Šçš„æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªæ¡ˆä¾‹è·Ÿç€æ•²äº†ä¸€éä»£ç ï¼Œå¹¶ä¸”åŠ äº†è‡ªå·±çš„ç†è§£ï¼Œæ”¾åˆ°è¿™é‡Œæ¥éšæ—¶å›é¡¾
import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) from scipy import stats %matplotlib inline è¯»å–æ•°æ® train_data = pd.read_csv(&amp;#34;./zhengqi_train.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) test_data = pd.read_csv(&amp;#34;./zhengqi_test.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;,encoding=&amp;#34;utf-8&amp;#34;) train_data.describe() result: å¼‚å¸¸å€¼åˆ†æ å…¶å®å°±æ˜¯ç”»ç»™boxå›¾çœ‹ç¦»æ•£çš„ç‚¹
plt.figure(figsize=(18,10)) plt.boxplot(x=train_data.values,labels=train_data.columns) plt.hlines([-7.5,7.5],0,40,colors=&amp;#34;Blue&amp;#34;) plt.show() result: åˆ é™¤å¼‚å¸¸å€¼ train_data = train_data[train_data[&amp;#34;V9&amp;#34;]&amp;gt;-7.5] train_data.describe() result: code:
test_data.describe() result: æœ€å¤§å€¼æœ€å°å€¼å½’ä¸€åŒ–å¤„ç† from sklearn import preprocessing features_columns = [col for col in train_data.columns if col not in [&amp;#34;target&amp;#34;]] min_max_scaler = preprocessing.</description>
    </item>
    
    <item>
      <title>é˜¿é‡Œäº‘_ML_05_æ¨¡å‹éªŒè¯</title>
      <link>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_05_%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/</link>
      <pubDate>Sat, 24 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E9%98%BF%E9%87%8C%E4%BA%91_ml_05_%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/</guid>
      <description>è¿™ä¸ªpostæ˜¯è‡ªå·±å»è·Ÿç€é˜¿é‡Œäº‘å¤©æ± ä¸Šçš„æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªæ¡ˆä¾‹è·Ÿç€æ•²äº†ä¸€éä»£ç ï¼Œå¹¶ä¸”åŠ äº†è‡ªå·±çš„ç†è§£ï¼Œæ”¾åˆ°è¿™é‡Œæ¥éšæ—¶å›é¡¾
è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆçš„é—®é¢˜ è·å–å¹¶ç»˜åˆ¶æ•°æ®é›† import numpy as np import matplotlib.pyplot as plt import pandas as pd np.random.seed(22) x = np.random.uniform(-3.0,3.0,size=100) X = x.reshape(-1,1)#-1è¡¨ç¤ºç³»ç»Ÿè‡ªåŠ¨è®¡ç®—è¡Œ #np.random.normal()äº§ç”Ÿæ­£æ€åˆ†å¸ƒçš„æ•° y = 0.5 * x**2 + x + 2 + np.random.normal(0,1,size=100) plt.scatter(x,y) plt.show() result: ä½¿ç”¨çº¿æ€§å›å½’æ‹Ÿåˆæ•°æ® from sklearn.linear_model import LinearRegression lin_reg = LinearRegression() lin_reg.fit(X,y) lin_reg.score(X,y)#scoreè¿”å›çš„æ˜¯å‡†ç¡®ç‡ result:
0.4340452690750729 å‡†ç¡®ç‡ä¸º 0.434ï¼Œæ¯”è¾ƒä½ï¼Œç›´çº¿æ‹Ÿåˆæ•°æ®çš„ç¨‹åº¦è¾ƒä½
ä½¿ç”¨å‡æ–¹è¯¯å·®åˆ¤æ–­æ‹Ÿåˆç¨‹åº¦ from sklearn.metrics import mean_squared_error y_predict = lin_reg.predict(X) mean_squared_error(y_predict,y) result:
2.7365298290204287 ç»˜åˆ¶æ‹Ÿåˆæ•ˆæœ plt.scatter(x,y) plt.plot(np.sort(x),y_predict[np.argsort(x)],color=&amp;#34;red&amp;#34;) plt.show() result: ä½¿ç”¨å¤šé¡¹å¼å›å½’æ‹Ÿåˆ:
å°è£…Pipelineç®¡é“ #Pipelineå°è£…ç®—æ³•æµ from sklearn.</description>
    </item>
    
    <item>
      <title>sklearnä¸­çš„äº¤å‰éªŒè¯Cross-Validation</title>
      <link>https://example.com/p/sklearn%E4%B8%AD%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81cross-validation/</link>
      <pubDate>Fri, 16 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sklearn%E4%B8%AD%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81cross-validation/</guid>
      <description>sklearnæ˜¯åˆ©ç”¨pythonè¿›è¡Œæœºå™¨å­¦ä¹ ä¸­ä¸€ä¸ªéå¸¸å…¨é¢å’Œå¥½ç”¨çš„ç¬¬ä¸‰æ–¹åº“ï¼Œç”¨è¿‡çš„éƒ½è¯´å¥½ã€‚ä»Šå¤©ä¸»è¦è®°å½•ä¸€ä¸‹sklearnä¸­å…³äºäº¤å‰éªŒè¯çš„å„ç§ç”¨æ³•ï¼Œä¸»è¦æ˜¯å¯¹sklearnå®˜æ–¹æ–‡æ¡£ https://scikit-learn.org/stable/modules/cross_validation.html
import numpy as np from sklearn.model_selection import train_test_split from sklearn.datasets import load_iris from sklearn import svm iris = load_iris() iris.data.shape,iris.target.shape result:
((150, 4), (150,)) train_test_split å¯¹æ•°æ®é›†è¿›è¡Œå¿«é€Ÿæ‰“ä¹±ï¼ˆåˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼‰, è¿™é‡Œç›¸å½“äºå¯¹æ•°æ®é›†è¿›è¡Œäº†shuffleåæŒ‰ç…§ç»™å®šçš„test_sizeè¿›è¡Œæ•°æ®é›†åˆ’åˆ†
è¿™é‡Œæ˜¯æŒ‰ç…§6:4å¯¹è®­ç»ƒé›†æµ‹è¯•é›†è¿›è¡Œåˆ’åˆ† X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target,test_size=.4,random_state=22)
code:
X_train.shape,y_train.shape result:
((90, 4), (90,)) code:
iris.data[:5] result: code:
X_train[:5] result: code:
clf = svm.SVC(kernel=&amp;#34;linear&amp;#34;,C=1) clf.fit(X_train,y_train) result:
SVC(C=1, kernel=&amp;#39;linear&amp;#39;) clf.score(X_test,y_test) result:
0.9833333333333333 cross_val_score å¯¹æ•°æ®é›†è¿›è¡ŒæŒ‡å®šæ¬¡æ•°çš„äº¤å‰éªŒè¯å¹¶ä¸ºæ¯æ¬¡éªŒè¯æ•ˆæœè¯„æµ‹ å…¶ä¸­ï¼Œscore é»˜è®¤æ˜¯ä»¥ scoring=&amp;lsquo;f1_macroâ€™è¿›è¡Œè¯„æµ‹çš„ï¼Œä½™å¤–é’ˆå¯¹åˆ†ç±»æˆ–å›å½’è¿˜æœ‰ï¼š è¿™éœ€è¦fromã€€sklearn import metrics ,é€šè¿‡åœ¨cross_val_score æŒ‡å®šå‚æ•°æ¥è®¾å®šè¯„æµ‹æ ‡å‡†ï¼› å½“cv æŒ‡å®šä¸ºint ç±»å‹æ—¶ï¼Œé»˜è®¤ä½¿ç”¨KFold æˆ–StratifiedKFold è¿›è¡Œæ•°æ®é›†æ‰“ä¹±ï¼Œä¸‹é¢ä¼šå¯¹KFold å’ŒStratifiedKFold è¿›è¡Œä»‹ç»</description>
    </item>
    
    <item>
      <title>sklearn.preprocessing.StandardScaleræ•°æ®æ ‡å‡†åŒ–</title>
      <link>https://example.com/p/sklearn.preprocessing.standardscaler%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96/</link>
      <pubDate>Mon, 08 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sklearn.preprocessing.standardscaler%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96/</guid>
      <description>sklearn.preprocessing.StandardScaleræ•°æ®æ ‡å‡†åŒ– å¦‚æœæŸä¸ªç‰¹å¾çš„æ–¹å·®è¿œå¤§äºå…¶å®ƒç‰¹å¾çš„æ–¹å·®ï¼Œé‚£ä¹ˆå®ƒå°†ä¼šåœ¨ç®—æ³•å­¦ä¹ ä¸­å æ®ä¸»å¯¼ä½ç½®ï¼Œå¯¼è‡´æˆ‘ä»¬çš„å­¦ä¹ å™¨ä¸èƒ½åƒæˆ‘ä»¬æœŸæœ›çš„é‚£æ ·ï¼Œå»å­¦ä¹ å…¶ä»–çš„ç‰¹å¾ï¼Œè¿™å°†å¯¼è‡´æœ€åçš„æ¨¡å‹æ”¶æ•›é€Ÿåº¦æ…¢ç”šè‡³ä¸æ”¶æ•›ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å¯¹è¿™æ ·çš„ç‰¹å¾æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–/å½’ä¸€åŒ–
StandarScaler æ ‡å‡†åŒ–æ•°æ®é€šè¿‡å‡å»å‡å€¼ç„¶åé™¤ä»¥æ–¹å·®ï¼ˆæˆ–æ ‡å‡†å·®ï¼‰ï¼Œè¿™ç§æ•°æ®æ ‡å‡†åŒ–æ–¹æ³•ç»è¿‡å¤„ç†åæ•°æ®ç¬¦åˆæ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œå³å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1ï¼Œè½¬åŒ–å‡½æ•°ä¸ºï¼šx =(x - ğœ‡)/ğœ
import numpy as np from sklearn.preprocessing import StandardScaler &amp;#34;&amp;#34;&amp;#34; scale_ : ç¼©æ”¾æ¯”åˆ—ï¼ŒåŒæ—¶ä¹Ÿæ˜¯æ ‡å‡†å·® mean_ : æ¯ä¸ªç‰¹å¾çš„å¹³å‡å€¼ var_ : æ¯ä¸ªç‰¹å¾çš„æ–¹å·® n_samples_seen_ : æ ·æœ¬æ•°é‡ &amp;#34;&amp;#34;&amp;#34; x = np.array(range(1,10)).reshape(-1,1) ss = StandardScaler() ss.fit(X=x) print(x) print(ss.n_samples_seen_) print(ss.mean_) print(ss.var_) print(ss.scale_) print(&amp;#34;æ ‡å‡†åŒ–åçš„æ•°æ®ï¼š&amp;#34;) y = ss.fit_transform(x) print(y) result: </description>
    </item>
    
    <item>
      <title>Sklearn.metricsæœºå™¨å­¦ä¹ å„ç§è¯„ä»·æŒ‡æ ‡</title>
      <link>https://example.com/p/sklearn.metrics%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%90%84%E7%A7%8D%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</link>
      <pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sklearn.metrics%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%90%84%E7%A7%8D%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</guid>
      <description>è¿™æ˜¯Python sklearnæœºå™¨å­¦ä¹ å„ç§è¯„ä»·æŒ‡æ ‡â€”â€”sklearn.metricsç®€ä»‹åŠåº”ç”¨ç¤ºä¾‹ ï¼ˆæ–‡ä¸­å›¾ç‰‡æ¥æºäºçŸ¥ä¹ï¼Œä½†æ˜¯å› ä¸ºæ˜¯å¾ˆä¹…ä¹‹å‰çš„å›¾ç‰‡ï¼Œä»Šå¤©æ•´ç†èµ·æ¥æ‰¾ä¸åˆ°åŸä½œè€…çš„çŸ¥ä¹è´¦å·äº†ï¼‰
è¡¥å……ï¼Œæ‰¾åˆ°äº†ï¼Œä½†æ˜¯è®°é”™äº†ï¼Œä¸æ˜¯çŸ¥ä¹ã€‚ã€‚
https://scikit-learn.org/stable/modules/classes.html https://www.cnblogs.com/mindy-snail/p/12445973.html # æœ‰ä¸¤ç§æ–¹å¼å¯¼å…¥ï¼š #æ–¹å¼ä¸€ï¼š from sklearn.metrics import mean_squared_error from sklearn.metrics import r2_score # æ­¤æ—¶çš„è°ƒç”¨æ–¹å¼ç›´æ¥è°ƒç”¨å³å¯ mean_squared_error(y_test,y_pred) #æ–¹å¼äºŒï¼š from sklearn import metrics #æ­¤æ—¶çš„è°ƒç”¨æ–¹å¼ metrics.mean_squared_error(y_test,y_pred) æ¥çœ‹scikit-learn.metricsé‡Œå„ç§æŒ‡æ ‡ç®€ä»‹
å›å½’æŒ‡æ ‡ 1.explained_variance_score(y_true, y_pred, sample_weight=None, multioutput=â€˜uniform_averageâ€™)ï¼šå›å½’æ–¹å·®(ååº”è‡ªå˜é‡ä¸å› å˜é‡ä¹‹é—´çš„ç›¸å…³ç¨‹åº¦) 2.mean_absolute_error(y_true,y_pred,sample_weight=None,multioutput=â€˜uniform_averageâ€™)ï¼šå¹³å‡ç»å¯¹è¯¯å·® 3.mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=â€˜uniform_averageâ€™)ï¼šå‡æ–¹å·® 4.median_absolute_error(y_true, y_pred) ä¸­å€¼ç»å¯¹è¯¯å·® 5.r2_score(y_true, y_pred,sample_weight=None,multioutput=â€˜uniform_averageâ€™) ï¼šRå¹³æ–¹å€¼ åˆ†ç±»æŒ‡æ ‡ 1.accuracy_score(y_true,y_pred):ç²¾åº¦ 2.auc(x,y,reorder=False):ROCæ›²çº¿ä¸‹çš„é¢ç§¯;è¾ƒå¤§çš„AUCä»£è¡¨äº†è¾ƒå¥½çš„performance 3.average_precision_score(y_true, y_score, average=â€˜macroâ€™, sample_weight=None):æ ¹æ®é¢„æµ‹å¾—åˆ†è®¡ç®—å¹³å‡ç²¾åº¦(AP) 4.brief_score_loss(y_true, y_prob, sample_weight=None, pos_label=None):The smaller the Brier score, the better. 5.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None):é€šè¿‡è®¡ç®—æ··æ·†çŸ©é˜µæ¥è¯„ä¼°åˆ†ç±»çš„å‡†ç¡®æ€§ è¿”å›æ··æ·†çŸ©é˜µ 6.f1_score(y_true, y_pred, labels=None, pos_label=1, average=â€˜binaryâ€™, sample_weight=None):F1å€¼ 7.</description>
    </item>
    
    <item>
      <title>ç”¨scikit-learnè¿›è¡ŒLDAé™ç»´</title>
      <link>https://example.com/p/%E7%94%A8scikit-learn%E8%BF%9B%E8%A1%8Clda%E9%99%8D%E7%BB%B4/</link>
      <pubDate>Mon, 07 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8scikit-learn%E8%BF%9B%E8%A1%8Clda%E9%99%8D%E7%BB%B4/</guid>
      <description>æˆ‘ä»¬é¦–å…ˆç”Ÿæˆä¸‰ç±»ä¸‰ç»´ç‰¹å¾çš„æ•°æ®ï¼Œä»£ç å¦‚ä¸‹ï¼š
import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D from sklearn.datasets import make_classification X,y = make_classification(n_samples=1000,n_features=3,n_redundant=0, n_classes=3,n_informative=2,n_clusters_per_class=1,class_sep=0.5, random_state=22) fig = plt.figure(figsize=(15,8)) ax = Axes3D(fig,rect=[0,0,1,1],elev=30,azim=20) ax.scatter(X[:,0],X[:,1],X[:,2],marker=&amp;#34;o&amp;#34;,c=y) é¦–å…ˆæˆ‘ä»¬çœ‹çœ‹ä½¿ç”¨PCAé™ç»´åˆ°äºŒç»´çš„æƒ…å†µï¼Œæ³¨æ„PCAæ— æ³•ä½¿ç”¨ç±»åˆ«ä¿¡æ¯æ¥é™ç»´
from sklearn.decomposition import PCA pca = PCA(n_components=2) pca.fit(X) print(pca.explained_variance_ratio_) print(pca.explained_variance_) X_nex = pca.transform(X) plt.scatter(X_nex[:,0],X_nex[:,1],marker=&amp;#34;o&amp;#34;,c=y) plt.show() result: ç”±äºPCAæ²¡æœ‰åˆ©ç”¨ç±»åˆ«ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°é™ç»´åï¼Œæ ·æœ¬ç‰¹å¾å’Œç±»åˆ«çš„ä¿¡æ¯å…³è”å‡ ä¹å®Œå…¨ä¸¢å¤±ã€‚
ç°åœ¨æˆ‘ä»¬å†çœ‹çœ‹ä½¿ç”¨LDAçš„æ•ˆæœ
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis lda = LinearDiscriminantAnalysis(n_components=2) lda.fit(X,y) X_new = lda.transform(X) plt.scatter(X_new[:,0],X_new[:,1],marker=&amp;#34;o&amp;#34;,c=y) plt.show() result: å¯ä»¥çœ‹å‡ºé™ç»´åæ ·æœ¬ç‰¹å¾å’Œç±»åˆ«ä¿¡æ¯ä¹‹é—´çš„å…³ç³»å¾—ä»¥ä¿ç•™ã€‚
ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœæˆ‘ä»¬çš„æ•°æ®æ˜¯æœ‰ç±»åˆ«æ ‡ç­¾çš„ï¼Œé‚£ä¹ˆä¼˜å…ˆé€‰æ‹©LDAå»å°è¯•é™ç»´ï¼›å½“ç„¶ä¹Ÿå¯ä»¥ä½¿ç”¨PCAåšå¾ˆå°å¹…åº¦çš„é™ç»´å»æ¶ˆå»å™ªå£°ï¼Œç„¶åå†ä½¿ç”¨LDAé™ç»´ã€‚å¦‚æœæ²¡æœ‰ç±»åˆ«æ ‡ç­¾ï¼Œé‚£ä¹ˆè‚¯å®šPCAæ˜¯æœ€å…ˆè€ƒè™‘çš„ä¸€ä¸ªé€‰æ‹©äº†ã€‚</description>
    </item>
    
    <item>
      <title>ç”¨scikit-learnå­¦ä¹ ä¸»æˆåˆ†åˆ†æ(PCA)</title>
      <link>https://example.com/p/%E7%94%A8scikit-learn%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90pca/</link>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8scikit-learn%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90pca/</guid>
      <description>import numpy as np import pandas as pd import matplotlib import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) # matplotlib.style.use(&amp;#34;ggplot&amp;#34;) #è¿™ä¸ªç”¨æ¥ç»˜åˆ¶ä¸‰ç»´å›¾ from mpl_toolkits.mplot3d import Axes3D # from sklearn.datasets.samples_generator import make_blobs from sklearn.datasets import make_blobs # Xä¸ºæ ·æœ¬ç‰¹å¾ï¼ŒYä¸ºæ ·æœ¬ç°‡ç±»åˆ«ï¼Œ å…±1000ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬3ä¸ªç‰¹å¾ï¼Œå…±4ä¸ªç°‡ X,y = make_blobs(n_samples=10000,n_features=3,centers=[[3,3,3],[0,0,0],[1,1,1],[2,2,2]], cluster_std=[0.2,0.1,0.2,0.2],random_state=22) fig = plt.figure(figsize=(15,5))#ä¹‹æ‰€ä»¥è¦è¿™æ ·æ˜¯ä¸ºäº†ä¼ ç»™Axes3Dä¸€ä¸ªç”»å¸ƒ ax = Axes3D(fig,rect=[0,0,1,1],elev=30,azim=20) plt.scatter(X[:,0],X[:,1],X[:,2],marker=&amp;#34;o&amp;#34;) result: æˆ‘ä»¬å…ˆä¸é™ç»´ï¼Œåªå¯¹æ•°æ®è¿›è¡ŒæŠ•å½±ï¼Œçœ‹çœ‹æŠ•å½±åçš„ä¸‰ä¸ªç»´åº¦çš„æ–¹å·®åˆ†å¸ƒï¼Œä»£ç å¦‚ä¸‹ï¼š
from sklearn.decomposition import PCA pca = PCA(n_components=3) pca.fit(X) print(pca.explained_variance_) print(pca.explained_variance_ratio_) result:
[3.78352072 0.03342374 0.03210098] [0.98297637 0.00868364 0.00833998] æŠ•å½±åç¬¬ä¸€ä¸ªç‰¹å¾å äº†ç»å¤§å¤šæ•°çš„ä¸»æˆåˆ†æ¯”ä¾‹ã€‚
ç°åœ¨æˆ‘ä»¬æ¥è¿›è¡Œé™ç»´ï¼Œä»ä¸‰ç»´é™åˆ°2ç»´ï¼Œä»£ç å¦‚ä¸‹ï¼š
pca = PCA(n_components=2) pca.</description>
    </item>
    
    <item>
      <title>ç”¨scikit-learnç ”ç©¶å±€éƒ¨çº¿æ€§åµŒå…¥(LLE)</title>
      <link>https://example.com/p/%E7%94%A8scikit-learn%E7%A0%94%E7%A9%B6%E5%B1%80%E9%83%A8%E7%BA%BF%E6%80%A7%E5%B5%8C%E5%85%A5lle/</link>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8scikit-learn%E7%A0%94%E7%A9%B6%E5%B1%80%E9%83%A8%E7%BA%BF%E6%80%A7%E5%B5%8C%E5%85%A5lle/</guid>
      <description>LLEç”¨äºé™ç»´å¯è§†åŒ–å®è·µ
ä¸‹é¢æˆ‘ä»¬ç”¨ä¸€ä¸ªå…·ä½“çš„ä¾‹å­æ¥ä½¿ç”¨scikit-learnè¿›è¡ŒLLEé™ç»´å¹¶å¯è§†åŒ–ã€‚
import numpy as np import pandas as pd import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D #manifoldæ˜¯ç”¨æ¥å¯¼å…¥LLE from sklearn import manifold,datasets from sklearn.utils import check_random_state æˆ‘ä»¬æ¥ç€ç”Ÿæˆéšæœºæ•°æ®ï¼Œç”±äºLLEå¿…é¡»è¦åŸºäºæµå½¢ä¸èƒ½é—­åˆï¼Œå› æ­¤æˆ‘ä»¬ç”Ÿæˆäº†ä¸€ä¸ªç¼ºä¸€ä¸ªå£çš„ä¸‰ç»´çƒä½“ã€‚ç”Ÿæˆæ•°æ®å¹¶å¯è§†åŒ–çš„ä»£ç å¦‚ä¸‹ï¼š
n_samples = 500 #check_random_state çš„ä½œç”¨æ˜¯ Turn seed into a np.random.RandomState instance random_state = check_random_state(0) print(random_state) result:
RandomState(MT19937) #ä½œç”¨ä½“ç°åœ¨è¿™é‡Œäº† p = random_state.rand(n_samples)*(2*np.pi-0.55) t = random_state.rand(n_samples)*np.pi print(p,t) result: # è®©çƒä½“ä¸é—­åˆï¼Œç¬¦åˆæµå½¢å®šä¹‰ indices = ((t &amp;lt; (np.pi - (np.pi / 8))) &amp;amp; (t &amp;gt; ((np.pi / 8)))) colors = p[indices] x, y, z = np.</description>
    </item>
    
    <item>
      <title>sklearn.datasetsä¸­çš„å‡ ä¸ªå‡½æ•°make_moons,make_circles,make_classification</title>
      <link>https://example.com/p/sklearn.datasets%E4%B8%AD%E7%9A%84%E5%87%A0%E4%B8%AA%E5%87%BD%E6%95%B0make_moonsmake_circlesmake_classification/</link>
      <pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/sklearn.datasets%E4%B8%AD%E7%9A%84%E5%87%A0%E4%B8%AA%E5%87%BD%E6%95%B0make_moonsmake_circlesmake_classification/</guid>
      <description>make_moons() sklearn.datasets.make_moons(n_samples=100, shuffle=True, noise=None, random_state=None)
åˆ¶ä½œæœˆäº®å‹æ•°æ®
é‡è¦å‚æ•°ï¼šn_samplesï¼šè®¾ç½®æ ·æœ¬æ•°é‡ã€noise:è®¾ç½®å™ªå£°ã€random_stateï¼šè®¾ç½®éšæœºå‚æ•°ï¼ˆå˜¿å˜¿ï¼Œæ— æ‰€è°“ï¼Œéšä¾¿è®¾ï¼‰ï¼Œæˆ‘ä»¬ä¸»è¦è®²å‚æ•°noise
from sklearn.datasets import make_moons import matplotlib.pyplot as plt # plt.style.use(&amp;#34;seaborn-whitegrid&amp;#34;) a,b = make_moons(noise=0) plt.scatter(a[:,0],a[:,1],c=b) result: ![](picture/sklearn.datasetsä¸­çš„å‡ ä¸ªå‡½æ•°make_moons,%20make_circles(,make_classification.png)
#å°†noiseè®¾ç½®ä¸º0.1 a,b = make_moons(noise=0.1) plt.scatter(a[:,0],a[:,1],c=b) #å‘ç°è¿™ä¸ªnoiseè®¾ç½®çš„è¶Šå¤§ï¼Œé‚£ä¹ˆå™ªå£°å°±è¶Šå¤§ result: make_circles() sklearn.datasets.make_circles(n_samples=100, shuffle=True, noise=None, random_state=None, factor=0.8)
é‡è¦å‚æ•°ï¼šn_samplesï¼šè®¾ç½®æ ·æœ¬æ•°é‡ã€noise:è®¾ç½®å™ªå£°ã€factorï¼š0 &amp;lt; double &amp;lt; 1 é»˜è®¤å€¼0.8ï¼Œå†…å¤–åœ†ä¹‹é—´çš„æ¯”ä¾‹å› å­ã€random_stateï¼šè®¾ç½®éšæœºå‚æ•°ï¼ˆå˜¿å˜¿ï¼Œæ— æ‰€è°“ï¼Œéšä¾¿è®¾ï¼‰ï¼Œæˆ‘ä»¬ä¸»è¦è®²å‚æ•°noiseã€factor
from sklearn.datasets import make_circles #å°†moiseè®¾ç½®ä¸º0ï¼Œfactorè®¾ç½®ä¸º0.1 a,b = make_circles(noise=0,factor=0.1) plt.scatter(a[:,0],a[:,1],c=b) result: code:
#å°†noiseè®¾ç½®ä¸º0.1ï¼Œfactorè®¾ç½®ä¸º0.5 a,b = make_circles(noise=0.1,factor=0.5) plt.scatter(a[:,0],a[:,1],c=b) #å‘ç°è¿™ä¸ªnoiseè®¾ç½®çš„è¶Šå¤§ï¼Œé‚£ä¹ˆå™ªå£°å°±è¶Šå¤§ï¼Œfactorè®¾ç½®çš„è¶Šå¤§ï¼Œä¸¤ä¸ªç¯å°±è¶Šè¿‘ result: make_classfication sklearn.datasets.make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.</description>
    </item>
    
    <item>
      <title>cannot import name &#39;cross_validation&#39; </title>
      <link>https://example.com/p/cannot-import-name-cross_validation/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/cannot-import-name-cross_validation/</guid>
      <description>æƒ³ä» sklearn åŒ…ä¸­å¯¼å…¥æ¨¡å— cross_validationï¼Œè°ƒç”¨ cross_validation é‡Œé¢åˆ«çš„å‡½æ•°ï¼Œä¾‹å¦‚ äº¤å‰éªŒè¯æ•°æ® ä½¿ç”¨åˆ°çš„ cross_val_score å‡½æ•°ï¼Œä½†æ˜¯ from sklearn import cross_validation è¿è¡ŒæŠ¥é”™ code:
from sklearn import corss_validation result:
--------------------------------------------------------------------------- ImportError Traceback (most recent call last) ~\AppData\Local\Temp/ipykernel_6408/3988079335.py in &amp;lt;module&amp;gt; ----&amp;gt; 1 from sklearn import corss_validation ImportError: cannot import name &amp;#39;corss_validation&amp;#39; from &amp;#39;sklearn&amp;#39; (F:\anaconda3\lib\site-packages\sklearn\__init__.py) è¿™æ˜¯å› ä¸º sklearn 0.21.1 ç‰ˆæœ¬çš„å·²ç»ç§»é™¤ cross_validation æ¨¡å— ä» sklearn.model_selection æ¨¡å—ç›´æ¥å¯¼å…¥ cross_val_score å³
from sklearn.model_selection import cross_val_score </description>
    </item>
    
    <item>
      <title>ccannot import name â€˜cross_validationâ€™ from â€˜sklearnâ€™ </title>
      <link>https://example.com/p/ccannot-import-name-cross_validation-from-sklearn/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/ccannot-import-name-cross_validation-from-sklearn/</guid>
      <description>code:
from sklearn import cross_validation result:
--------------------------------------------------------------------------- ImportError Traceback (most recent call last) ~\AppData\Local\Temp/ipykernel_19376/266941855.py in &amp;lt;module&amp;gt; ----&amp;gt; 1 from sklearn import cross_validation ImportError: cannot import name &amp;#39;cross_validation&amp;#39; from &amp;#39;sklearn&amp;#39; (F:\anaconda3\lib\site-packages\sklearn\__init__.py) â€˜cross_validationâ€™ from â€˜sklearnâ€™â€ï¼Œåæ¥ç™¾åº¦æ‰çŸ¥é“sklearnåœ¨0.18ç‰ˆæœ¬ä¸­ï¼Œcross_validationè¢«åºŸå¼ƒäº†ï¼ŒåŸæ¥åœ¨ cross_validation é‡Œé¢çš„å‡½æ•°ç°åœ¨åœ¨ model_selection é‡Œé¢ï¼Œæ‰€ä»¥åªè¦å°†cross_validationæ›¿æ¢ä¸ºmodel_selectionå°±å¯ä»¥ä½¿ç”¨ï¼Œæ•°æ®ä¿¡æ¯éƒ½æ˜¯ä¸€æ ·çš„
from sklearn.model_selection import cross_validate </description>
    </item>
    
    <item>
      <title>No module named &#39;sklearn.datasets.samples_generator&#39;â€™ </title>
      <link>https://example.com/p/no-module-named-sklearn.datasets.samples_generator/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/no-module-named-sklearn.datasets.samples_generator/</guid>
      <description>code:
from sklearn.datasets.samples_generator import make_blobs result:
--------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) ~\AppData\Local\Temp/ipykernel_14680/1800722232.py in &amp;lt;module&amp;gt; ----&amp;gt; 1 from sklearn.datasets.samples_generator import make_blobs ModuleNotFoundError: No module named &amp;#39;sklearn.datasets.samples_generator&amp;#39; æ–°ç‰ˆçš„sklearnä¸­æ”¹ä¸ºäº†è¿™ç§ç”¨æ³•ï¼š
from sklearn.datasets import make_blobs </description>
    </item>
    
    <item>
      <title>No module named &#39;sklearn.grid_search&#39;</title>
      <link>https://example.com/p/no-module-named-sklearn.grid_search/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/no-module-named-sklearn.grid_search/</guid>
      <description>code:
from sklearn.grid_search import GridSearchCV result:
ModuleNotFoundError Traceback (most recent call last) ~\AppData\Local\Temp/ipykernel_7712/1716585072.py in &amp;lt;module&amp;gt; ----&amp;gt; 1 from sklearn.grid_search import GridSearchCV ModuleNotFoundError: No module named &amp;#39;sklearn.grid_search&amp;#39; æ£€æŸ¥Scikit-Learnçš„ç‰ˆæœ¬conda list scikit-learnå¦‚æœé«˜äºç­‰äº0.20è¯´æ˜æ˜¯grid_searchæ¨¡å—å·²è¢«å¼ƒç”¨ã€‚
æ”¹æˆè¿™æ ·äº†ï¼š
from sklearn.model_selection import GridSearchCV </description>
    </item>
    
    <item>
      <title>metrics.accuracy_score()è®¡ç®—åˆ†ç±»çš„å‡†ç¡®ç‡</title>
      <link>https://example.com/p/metrics.accuracy_score%E8%AE%A1%E7%AE%97%E5%88%86%E7%B1%BB%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87/</link>
      <pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/metrics.accuracy_score%E8%AE%A1%E7%AE%97%E5%88%86%E7%B1%BB%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87/</guid>
      <description>sklearnä¸­æä¾›äº†è®¡ç®—å‡†ç¡®ç‡çš„accurccy_scoreå‡½æ•° from sklearn import metrics metrics.accuracy_score? è¾“å…¥å‚æ•°ï¼š
y_trueï¼šçœŸæ˜¯æ ‡ç­¾ã€‚äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»æƒ…å†µä¸‹æ˜¯ä¸€åˆ—ï¼Œå¤šæ ‡ç­¾æƒ…å†µä¸‹æ˜¯æ ‡ç­¾çš„ç´¢å¼•ã€‚
y_predï¼šé¢„æµ‹æ ‡ç­¾ã€‚äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»æƒ…å†µä¸‹æ˜¯ä¸€åˆ—ï¼Œå¤šæ ‡ç­¾æƒ…å†µä¸‹æ˜¯æ ‡ç­¾çš„ç´¢å¼•ã€‚
normalize:bool, optional (default=True)ï¼Œå¦‚æœæ˜¯falseï¼Œæ­£ç¡®åˆ†ç±»çš„æ ·æœ¬çš„æ•°ç›®(int)ï¼›å¦‚æœä¸ºtrueï¼Œè¿”å›æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬çš„æ¯”ä¾‹ï¼Œå¿…é¡»ä¸¥æ ¼åŒ¹é…çœŸå®æ•°æ®é›†ä¸­çš„labelï¼Œæ‰ä¸º1ï¼Œå¦åˆ™ä¸º0ã€‚
sample_weightï¼šarray-like of shape (n_samples,), default=Noneã€‚Sample weights.
è¾“å‡ºï¼š
å¦‚æœnormalize == True,è¿”å›æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬çš„æ¯”ä¾‹ï¼Œå¦åˆ™è¿”å›æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬çš„æ•°ç›®(int)</description>
    </item>
    
    <item>
      <title>&#39;GridSearchCV&#39; object has no attribute &#39;grid_scores_&#39;</title>
      <link>https://example.com/p/gridsearchcv-object-has-no-attribute-grid_scores_/</link>
      <pubDate>Tue, 11 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/gridsearchcv-object-has-no-attribute-grid_scores_/</guid>
      <description>åŸå› åœ¨äºgrid_scores_åœ¨sklearn0.20ç‰ˆæœ¬ä¸­å·²è¢«åˆ é™¤ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯cv_results_</description>
    </item>
    
    <item>
      <title>åˆ˜å»ºå¹³è€å¸ˆPinardåšå®¢çš„XGBoostç±»åº“ä»£ç å­¦ä¹ è®°å½•</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84xgboost%E7%B1%BB%E5%BA%93%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84xgboost%E7%B1%BB%E5%BA%93%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>åŸç”ŸXGBoostéœ€è¦å…ˆæŠŠæ•°æ®é›†æŒ‰è¾“å…¥ç‰¹å¾éƒ¨åˆ†ï¼Œè¾“å‡ºéƒ¨åˆ†åˆ†å¼€ï¼Œç„¶åæ”¾åˆ°ä¸€ä¸ªDMatrixæ•°æ®ç»“æ„é‡Œé¢ï¼Œè¿™ä¸ªDMatrixæˆ‘ä»¬ä¸éœ€è¦å…³å¿ƒé‡Œé¢çš„ç»†èŠ‚ï¼Œä½¿ç”¨æˆ‘ä»¬çš„è®­ç»ƒé›†Xå’Œyåˆå§‹åŒ–å³å¯ã€‚
import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt matplotlib.style.use(&amp;#34;ggplot&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False plt.rcParams[&amp;#34;figure.figsize&amp;#34;] = (15,5) import xgboost as xgb from sklearn.model_selection import GridSearchCV from sklearn.model_selection import train_test_split # from sklearn.datasets.samples_generator import make_classification from sklearn.datasets import make_classification # Xä¸ºæ ·æœ¬ç‰¹å¾ï¼Œyä¸ºæ ·æœ¬ç±»åˆ«è¾“å‡ºï¼Œ å…±10000ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬20ä¸ªç‰¹å¾ï¼Œè¾“å‡ºæœ‰2ä¸ªç±»åˆ«ï¼Œæ²¡æœ‰å†—ä½™ç‰¹å¾ï¼Œæ¯ä¸ªç±»åˆ«ä¸€ä¸ªç°‡ X,y = make_classification(n_samples=10000,n_features=20,n_classes=2, n_clusters_per_class=1,n_redundant=0,flip_y=0.1) #flip_y éšæœºåˆ†é…çš„æ ·æœ¬çš„æ¯”ä¾‹ï¼Œå¢å¤§ä¼šåŠ å¤§å™ªå£°ï¼ŒåŠ å¤§åˆ†ç±»éš¾åº¦ X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=22) dtrain = xgb.DMatrix(X_train,y_train) dtest = xgb.DMatrix(X_test,y_test) ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬éšæœºåˆå§‹åŒ–äº†ä¸€ä¸ªäºŒåˆ†ç±»çš„æ•°æ®é›†ï¼Œç„¶ååˆ†æˆäº†è®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚ä½¿ç”¨è®­ç»ƒé›†å’ŒéªŒè¯é›†åˆ†åˆ«åˆå§‹åŒ–äº†ä¸€ä¸ªDMatrixï¼Œæœ‰äº†DMatrixï¼Œå°±å¯ä»¥åšè®­ç»ƒå’Œé¢„æµ‹äº†ã€‚ç®€å•çš„ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š
# param = {&amp;#39;max_depth&amp;#39;:5, &amp;#39;eta&amp;#39;:0.5, &amp;#39;verbosity&amp;#39;:1, &amp;#39;objective&amp;#39;:&amp;#39;binary:logistic&amp;#39;} param = {&amp;#34;max_depth&amp;#34;:5,&amp;#34;eta&amp;#34;:0.</description>
    </item>
    
    <item>
      <title>åˆ˜å»ºå¹³è€å¸ˆPinardåšå®¢çš„AdaBoostClassifierä»£ç å­¦ä¹ è®°å½•</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84adaboostclassifier%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84adaboostclassifier%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>import numpy as np import pandas as pd import matplotlib.pyplot as plt import matplotlib # matplotlib.style.use(&amp;#34;ggplot&amp;#34;) matplotlib.line_width = 5000 matplotlib.max_columns = 60 plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) from sklearn.ensemble import AdaBoostClassifier from sklearn.tree import DecisionTreeClassifier #ç”¨make_gaussian_quantilesç”Ÿæˆåˆ†ç»„å¤šç»´æ­£æ€åˆ†å¸ƒçš„æ•°æ® from sklearn.datasets import make_gaussian_quantiles æ¥ç€æˆ‘ä»¬ç”Ÿæˆä¸€äº›éšæœºæ•°æ®æ¥åšäºŒå…ƒåˆ†ç±»
#ç”Ÿæˆä¸€äº›éšæœºæ•°æ®æŒ‰ä½æ•°åˆ†ä¸ºä¸¤ç±»ï¼Œ500ä¸ªæ ·æœ¬ï¼Œ2ä¸ªæ ·æœ¬ç‰¹å¾ï¼Œåæ–¹å·®ç³»æ•°ä¸º2 X1, y1 = make_gaussian_quantiles(cov=2.0,n_samples=500,n_features=2, n_classes=2,random_state=23) #ç”Ÿæˆçš„ä¸¤ä¸ªæ ·æœ¬ç‰¹å¾å‡å€¼éƒ½ä¸º3 X2, y2 = make_gaussian_quantiles(cov=1.5,n_samples=400,n_features=2,n_classes=2, random_state=23,mean=(3,3)) X1[:5],y1[:5],X2[:5],y2[:5] result: #åˆå¹¶ä¸¤ç»„æ•°æ® #è®°å¾—ç”¨ä¸€ä¸ª()è£… X = np.concatenate((X1,X2)) y = np.concatenate((y1,y2)) X[:5],y[:5] result: æˆ‘ä»¬é€šè¿‡å¯è§†åŒ–çœ‹çœ‹æˆ‘ä»¬çš„åˆ†ç±»æ•°æ®ï¼Œå®ƒæœ‰ä¸¤ä¸ªç‰¹å¾ï¼Œä¸¤ä¸ªè¾“å‡ºç±»åˆ«ï¼Œç”¨é¢œè‰²åŒºåˆ«</description>
    </item>
    
    <item>
      <title>åˆ˜å»ºå¹³è€å¸ˆPinardåšå®¢çš„sklearnGBDTä»£ç å­¦ä¹ è®°å½•</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84sklearngbdt%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84sklearngbdt%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>import pandas as pd import numpy as np import matplotlib.pyplot as plt import matplotlib matplotlib.style.use(&amp;#34;ggplot&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False from sklearn.ensemble import GradientBoostingClassifier # from sklearn import cross_validation, metrics cross_validation æ¢æˆäº† cross_val_score from sklearn.model_selection import GridSearchCV,cross_val_score from sklearn import metrics æ¥ç€ï¼Œæˆ‘ä»¬æŠŠè§£å‹çš„æ•°æ®ç”¨ä¸‹é¢çš„ä»£ç è½½å…¥ï¼Œé¡ºä¾¿çœ‹çœ‹æ•°æ®çš„ç±»åˆ«åˆ†å¸ƒã€‚
train = pd.read_csv(&amp;#34;./train_modified.csv&amp;#34;) train result: code:
target = &amp;#34;Disbursed&amp;#34; IDcol = &amp;#34;ID&amp;#34; train[&amp;#34;Disbursed&amp;#34;].value_counts() # å¯ä»¥çœ‹åˆ°ç±»åˆ«è¾“å‡ºå¦‚ä¸‹ï¼Œä¹Ÿå°±æ˜¯ç±»åˆ«0çš„å å¤§å¤šæ•°ã€‚ result: ç°åœ¨æˆ‘ä»¬å¾—åˆ°æˆ‘ä»¬çš„è®­ç»ƒé›†ã€‚æœ€åä¸€åˆ—Disbursedæ˜¯åˆ†ç±»è¾“å‡ºã€‚å‰é¢çš„æ‰€æœ‰åˆ—ï¼ˆä¸è€ƒè™‘IDåˆ—ï¼‰éƒ½æ˜¯æ ·æœ¬ç‰¹å¾ code:
x_columns = [x for x in train.columns if x not in [target,IDcol]] X = train[x_columns] y = train[&amp;#34;Disbursed&amp;#34;] X.</description>
    </item>
    
    <item>
      <title>åˆ˜å»ºå¹³è€å¸ˆPinardåšå®¢çš„éšæœºæ£®æ—ä»£ç å­¦ä¹ è®°å½•</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description># å¯¼åŒ… import numpy as np import pandas as pd import matplotlib.pyplot as plt plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = [&amp;#34;SimHei&amp;#34;] plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) #ä»é›†æˆä¸­å¯¼å…¥RF from sklearn.ensemble import RandomForestClassifier #å¯¼å…¥ç½‘æ ¼è°ƒå‚ # from sklearn.grid_search import GridSearchCV æ—§ç‰ˆçš„sklearn from sklearn.model_selection import GridSearchCV # from sklearn import cross_validation,metrics æ—§ç‰ˆå†™æ³• from sklearn.model_selection import cross_validate from sklearn import metrics #æ•°æ® train = pd.read_csv(&amp;#34;./train_modified.csv&amp;#34;) train result: code:
target = &amp;#34;Disbursed&amp;#34;#Disbursedçš„å€¼å°±æ˜¯äºŒå…ƒåˆ†ç±»çš„è¾“å‡º IDcol = &amp;#34;ID&amp;#34; train[&amp;#34;Disbursed&amp;#34;].value_counts()#æŸ¥çœ‹ç±»åˆ«çš„æ•°é‡ result:
0 19680 1 320 Name: Disbursed, dtype: int64 å¯ä»¥çœ‹åˆ°ç±»åˆ«è¾“å‡ºå¦‚ä¸Šï¼Œä¹Ÿå°±æ˜¯ç±»åˆ«0çš„å å¤§å¤šæ•°ã€‚</description>
    </item>
    
    <item>
      <title>æ•°æ®é›†çš„åˆ›å»ºmake_classificationçš„å‚æ•°è¯¦æƒ…</title>
      <link>https://example.com/p/%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%9B%E5%BB%BAmake_classification%E7%9A%84%E5%8F%82%E6%95%B0%E8%AF%A6%E6%83%85/</link>
      <pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%9B%E5%BB%BAmake_classification%E7%9A%84%E5%8F%82%E6%95%B0%E8%AF%A6%E6%83%85/</guid>
      <description>è¿™é‡Œæ¥è®°å½•ä¸‹make_classificationçš„å‚æ•°è¯¦æƒ… import numpy as np import pandas as pd import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import matplotlib.pyplot as plt from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split X,y = make_classification(n_samples=1000,#1000ä¸ªæ ·æœ¬ n_features=2,#ä¸¤ä¸ªç‰¹å¾ï¼Œæ–¹ä¾¿ç”»å›¾ n_informative=2,#ä¿¡æ¯ç‰¹å¾(æœ‰ç”¨ç‰¹å¾) n_redundant=0,#å†—ä½™ç‰¹å¾ï¼Œå®ƒæ˜¯ä¿¡æ¯ç‰¹å¾çš„çº¿æ€§ç»„åˆ n_repeated=0,#é‡å¤ç‰¹å¾ n_classes=2,#åˆ†ç±»ç‰¹å¾ random_state=None, n_clusters_per_class=2,#æ¯ä¸ªç±»åˆ«ä¸¤ç°‡ shuffle=True, class_sep=1,#å°†æ¯ä¸ªç°‡åˆ†éš”å¼€æ¥ï¼Œè¾ƒå¤§çš„å€¼å°†ä½¿åˆ†ç±»ä»»åŠ¡æ›´åŠ å®¹æ˜“ shift = 10, scale = 3, flip_y = 0)#æ— å™ªå£° #è®­ç»ƒé›†ä¸æµ‹è¯•é›†åˆ†å‰²å‡½æ•° x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=22) data = np.concatenate((X,y.reshape(1000,1)),axis=1) x0 = [] x1 = [] y0 = [] y1 = [] for d in data: if d[2]==0: x0.</description>
    </item>
    
    <item>
      <title>æœºå™¨å­¦ä¹ ç®—æ³•çš„éšæœºæ•°æ®ç”Ÿæˆ</title>
      <link>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90/</link>
      <pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90/</guid>
      <description>numpyç”Ÿæˆ import numpy as np np.random.rand(2,2,2) result: np.random.randn(3,2) result: #åªéœ€è¦åœ¨randnä¸Šæ¯ä¸ªç”Ÿæˆçš„å€¼xä¸Šåšå˜æ¢Ïƒx+Î¼å³å¯ 2*np.random.randn(3,2) + 1 result: np.random.randint(3,6,[2,3,4]) result: np.random.random_integers(3,6,[2,3,4]) result: np.random.random_sample([2,2]) result: #å¦‚æœæ˜¯å…¶ä»–åŒºé—´[a,b),å¯ä»¥åŠ ä»¥è½¬æ¢(b - a) * random_sample([size]) + a (5-2)*np.random.random_sample([3]) + 2 result: å›å½’æ¨¡å‹éšæœºæ•°æ® è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨make_regressionç”Ÿæˆå›å½’æ¨¡å‹æ•°æ®ã€‚å‡ ä¸ªå…³é”®å‚æ•°æœ‰n_samplesï¼ˆç”Ÿæˆæ ·æœ¬æ•°ï¼‰ï¼Œ n_featuresï¼ˆæ ·æœ¬ç‰¹å¾æ•°ï¼‰ï¼Œnoiseï¼ˆæ ·æœ¬éšæœºå™ªéŸ³ï¼‰å’Œcoefï¼ˆæ˜¯å¦è¿”å›å›å½’ç³»æ•°ï¼‰ã€‚ä¾‹å­ä»£ç å¦‚ä¸‹ï¼š
import matplotlib.pyplot as plt from sklearn.datasets import make_regression #Xä¸ºæ ·æœ¬ç‰¹å¾ï¼Œyä¸ºæ ·æœ¬è¾“å‡ºï¼Œ coefä¸ºå›å½’ç³»æ•°ï¼Œå…±1000ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬1ä¸ªç‰¹å¾ X,y,coef = make_regression(n_samples=1000,n_features=1,noise=10,coef=True) plt.scatter(X,y,color=&amp;#34;black&amp;#34;) #çœ‹æ¥coefæ˜¯ä¸åŒ…å«bias print(coef) plt.plot(X,X*coef,color=&amp;#34;blue&amp;#34;,linewidth=3) plt.xticks(()) plt.yticks(()) plt.show() result: åˆ†ç±»æ¨¡å‹éšæœºæ•°æ® è¿™é‡Œæˆ‘ä»¬ç”¨make_classificationç”Ÿæˆä¸‰å…ƒåˆ†ç±»æ¨¡å‹æ•°æ®ã€‚å‡ ä¸ªå…³é”®å‚æ•°æœ‰n_samplesï¼ˆç”Ÿæˆæ ·æœ¬æ•°ï¼‰ï¼Œ n_featuresï¼ˆæ ·æœ¬ç‰¹å¾æ•°ï¼‰ï¼Œ n_redundantï¼ˆå†—ä½™ç‰¹å¾æ•°ï¼‰å’Œn_classesï¼ˆè¾“å‡ºçš„ç±»åˆ«æ•°ï¼‰ï¼Œä¾‹å­ä»£ç å¦‚ä¸‹
from sklearn.datasets import make_classification # X1ä¸ºæ ·æœ¬ç‰¹å¾ï¼ŒY1ä¸ºæ ·æœ¬ç±»åˆ«è¾“å‡ºï¼Œ å…±400ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬2ä¸ªç‰¹å¾ï¼Œè¾“å‡ºæœ‰3ä¸ªç±»åˆ«ï¼Œæ²¡æœ‰å†—ä½™ç‰¹å¾ï¼Œæ¯ä¸ªç±»åˆ«ä¸€ä¸ªç°‡ X1,Y1 = make_classification(n_samples=400,n_classes=3,n_clusters_per_class=1,n_features=2,n_redundant=0) plt.scatter(X1[:,0],X1[:,1],marker=&amp;#34;o&amp;#34;,c=Y1) plt.</description>
    </item>
    
    <item>
      <title>WZU_é›†æˆå­¦ä¹ ç®—æ³•ä»£ç å­¦ä¹ è®°å½•</title>
      <link>https://example.com/p/wzu_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Fri, 19 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>æœºå™¨å­¦ä¹ ç»ƒä¹ 8 é›†æˆå­¦ä¹  è¯¾ç¨‹å®Œæ•´ä»£ç ï¼šhttps://github.com/fengdu78/WZU-machine-learning-course
ä»£ç ä¿®æ”¹å¹¶æ³¨é‡Šï¼šé»„æµ·å¹¿ï¼Œhaiguang2000@wzu.edu.cn
import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import pandas as pd from sklearn.model_selection import train_test_split ç”Ÿæˆæ•°æ® ç”Ÿæˆ12000è¡Œçš„æ•°æ®ï¼Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†æŒ‰ç…§3:1åˆ’åˆ†
from sklearn.datasets import make_hastie_10_2 data, target = make_hastie_10_2() X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=123) X_train.shape, X_test.shape result:
((9000, 10), (3000, 10)) æ¨¡å‹å¯¹æ¯” å¯¹æ¯”å…­å¤§æ¨¡å‹ï¼Œéƒ½ä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œå› ä¸ºæ•°æ®æ˜¯
from sklearn.linear_model import LogisticRegression from sklearn.ensemble import RandomForestClassifier from sklearn.ensemble import AdaBoostClassifier from sklearn.ensemble import GradientBoostingClassifier from xgboost import XGBClassifier from lightgbm import LGBMClassifier from sklearn.model_selection import cross_val_score import time clf1 = LogisticRegression() clf2 = RandomForestClassifier() clf3 = AdaBoostClassifier() clf4 = GradientBoostingClassifier() clf5 = XGBClassifier() clf6 = LGBMClassifier() for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6], [ &amp;#39;Logistic Regression&amp;#39;, &amp;#39;Random Forest&amp;#39;, &amp;#39;AdaBoost&amp;#39;, &amp;#39;GBDT&amp;#39;, &amp;#39;XGBoost&amp;#39;, &amp;#39;LightGBM&amp;#39; ]): start = time.</description>
    </item>
    
    <item>
      <title>WZU_scikit_learn_ä»£ç å­¦ä¹ è®°å½•</title>
      <link>https://example.com/p/wzu_scikit_learn_%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_scikit_learn_%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>æœºå™¨å­¦ä¹ ç»ƒä¹  5 Scikit-learnçš„ä»‹ç»
æ•´ç†ç¼–è¯‘ï¼šé»„æµ·å¹¿ haiguang2000@wzu.edu.cn,å…‰åŸ
åœ¨æœ¬èŠ‚æ•™ç¨‹ä¸­å°†ä¼šç»˜åˆ¶å‡ ä¸ªå›¾å½¢ï¼Œäºæ˜¯æˆ‘ä»¬æ¿€æ´»matplotlib,ä½¿å¾—åœ¨notebookä¸­æ˜¾ç¤ºå†…è”å›¾ã€‚
%matplotlib inline import matplotlib.pyplot as plt ä¸ºä»€ä¹ˆè¦å‡ºè¿™ä¸ªæ•™ç¨‹ï¼Ÿ scikit-learn æä¾›æœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚ ä½†æ˜¯ï¼Œè¿™äº›ç®—æ³•ä¸èƒ½ç›´æ¥ç”¨äºåŸå§‹æ•°æ®ã€‚ åŸå§‹æ•°æ®éœ€è¦äº‹å…ˆè¿›è¡Œé¢„å¤„ç†ã€‚ å› æ­¤ï¼Œé™¤äº†æœºå™¨å­¦ä¹ ç®—æ³•ä¹‹å¤–ï¼Œscikit-learnè¿˜æä¾›äº†ä¸€å¥—é¢„å¤„ç†æ–¹æ³•ã€‚æ­¤å¤–ï¼Œscikit-learn æä¾›ç”¨äºæµæ°´çº¿åŒ–è¿™äº›ä¼°è®¡å™¨çš„è¿æ¥å™¨(å³è½¬æ¢å™¨ï¼Œå›å½’å™¨ï¼Œåˆ†ç±»å™¨ï¼Œèšç±»å™¨ç­‰)ã€‚
åœ¨æœ¬æ•™ç¨‹ä¸­,å°†ä»‹ç»scikit-learn å‡½æ•°é›†ï¼Œå…è®¸æµæ°´çº¿ä¼°è®¡å™¨ã€è¯„ä¼°è¿™äº›æµæ°´çº¿ã€ä½¿ç”¨è¶…å‚æ•°ä¼˜åŒ–è°ƒæ•´è¿™äº›æµæ°´çº¿ä»¥åŠåˆ›å»ºå¤æ‚çš„é¢„å¤„ç†æ­¥éª¤ã€‚
åŸºæœ¬ç”¨ä¾‹ï¼šè®­ç»ƒå’Œæµ‹è¯•åˆ†ç±»å™¨ å¯¹äºç¬¬ä¸€ä¸ªç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†åœ¨æ•°æ®é›†ä¸Šè®­ç»ƒå’Œæµ‹è¯•ä¸€ä¸ªåˆ†ç±»å™¨ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨æ­¤ç¤ºä¾‹æ¥å›å¿†scikit-learnçš„APIã€‚
æˆ‘ä»¬å°†ä½¿ç”¨digitsæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªæ‰‹å†™æ•°å­—çš„æ•°æ®é›†ã€‚
from sklearn.datasets import load_digits X, y = load_digits(return_X_y=True) X.shape result:
(1797, 64) Xä¸­çš„æ¯è¡ŒåŒ…å«64ä¸ªå›¾åƒåƒç´ çš„å¼ºåº¦ã€‚ å¯¹äºXä¸­çš„æ¯ä¸ªæ ·æœ¬ï¼Œæˆ‘ä»¬å¾—åˆ°è¡¨ç¤ºæ‰€å†™æ•°å­—å¯¹åº”çš„yã€‚
plt.imshow(X[0].reshape(8, 8), cmap=&amp;#39;gray&amp;#39;);# ä¸‹é¢å®Œæˆç°åº¦å›¾çš„ç»˜åˆ¶ # ç°åº¦æ˜¾ç¤ºå›¾åƒ plt.axis(&amp;#39;off&amp;#39;)# å…³é—­åæ ‡è½´ print(&amp;#39;The digit in the image is {}&amp;#39;.format(y[0]))# æ ¼å¼åŒ–æ‰“å° result:
åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬åº”è¯¥é€šè¿‡åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•æ¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚train_test_split æ˜¯ä¸€ä¸ªç”¨äºå°†æ•°æ®æ‹†åˆ†ä¸ºä¸¤ä¸ªç‹¬ç«‹æ•°æ®é›†çš„æ•ˆç”¨å‡½æ•°ã€‚stratifyå‚æ•°å¯å¼ºåˆ¶å°†è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†çš„ç±»åˆ†å¸ƒä¸æ•´ä¸ªæ•°æ®é›†çš„ç±»åˆ†å¸ƒç›¸åŒã€‚
code:
y result:
array([0, 1, 2, ..., 8, 9, 8]) code:
from sklearn.</description>
    </item>
    
    <item>
      <title>my_decisionTree_code</title>
      <link>https://example.com/p/my_decisiontree_code/</link>
      <pubDate>Wed, 22 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/my_decisiontree_code/</guid>
      <description>è¿™æ˜¯WZUè€å¸ˆæ­é…çš„å†³ç­–æ ‘çš„codeï¼Œè‡ªå·±ç•¥ä½œä¿®æ”¹
1ï¼åˆ†ç±»å†³ç­–æ ‘æ¨¡å‹æ˜¯è¡¨ç¤ºåŸºäºç‰¹å¾å¯¹å®ä¾‹è¿›è¡Œåˆ†ç±»çš„æ ‘å½¢ç»“æ„ã€‚å†³ç­–æ ‘å¯ä»¥è½¬æ¢æˆä¸€ä¸ªif-thenè§„åˆ™çš„é›†åˆï¼Œä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯å®šä¹‰åœ¨ç‰¹å¾ç©ºé—´åˆ’åˆ†ä¸Šçš„ç±»çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚
2ï¼å†³ç­–æ ‘å­¦ä¹ æ—¨åœ¨æ„å»ºä¸€ä¸ªä¸è®­ç»ƒæ•°æ®æ‹Ÿåˆå¾ˆå¥½ï¼Œå¹¶ä¸”å¤æ‚åº¦å°çš„å†³ç­–æ ‘ã€‚å› ä¸ºä»å¯èƒ½çš„å†³ç­–æ ‘ä¸­ç›´æ¥é€‰å–æœ€ä¼˜å†³ç­–æ ‘æ˜¯NPå®Œå…¨é—®é¢˜ã€‚ç°å®ä¸­é‡‡ç”¨å¯å‘å¼æ–¹æ³•å­¦ä¹ æ¬¡ä¼˜çš„å†³ç­–æ ‘ã€‚
å†³ç­–æ ‘å­¦ä¹ ç®—æ³•åŒ…æ‹¬3éƒ¨åˆ†ï¼šç‰¹å¾é€‰æ‹©ã€æ ‘çš„ç”Ÿæˆå’Œæ ‘çš„å‰ªæã€‚å¸¸ç”¨çš„ç®—æ³•æœ‰ID3ã€ C4.5å’ŒCARTã€‚
3ï¼ç‰¹å¾é€‰æ‹©çš„ç›®çš„åœ¨äºé€‰å–å¯¹è®­ç»ƒæ•°æ®èƒ½å¤Ÿåˆ†ç±»çš„ç‰¹å¾ã€‚ç‰¹å¾é€‰æ‹©çš„å…³é”®æ˜¯å…¶å‡†åˆ™ã€‚å¸¸ç”¨çš„å‡†åˆ™è‡ªå·±å»MDä¸­çœ‹
4ï¼å†³ç­–æ ‘çš„ç”Ÿæˆã€‚é€šå¸¸ä½¿ç”¨ä¿¡æ¯å¢ç›Šæœ€å¤§ã€ä¿¡æ¯å¢ç›Šæ¯”æœ€å¤§æˆ–åŸºå°¼æŒ‡æ•°æœ€å°ä½œä¸ºç‰¹å¾é€‰æ‹©çš„å‡†åˆ™ã€‚å†³ç­–æ ‘çš„ç”Ÿæˆå¾€å¾€é€šè¿‡è®¡ç®—ä¿¡æ¯å¢ç›Šæˆ–å…¶ä»–æŒ‡æ ‡ï¼Œä»æ ¹ç»“ç‚¹å¼€å§‹ï¼Œé€’å½’åœ°äº§ç”Ÿå†³ç­–æ ‘ã€‚è¿™ç›¸å½“äºç”¨ä¿¡æ¯å¢ç›Šæˆ–å…¶ä»–å‡†åˆ™ä¸æ–­åœ°é€‰å–å±€éƒ¨æœ€ä¼˜çš„ç‰¹å¾ï¼Œæˆ–å°†è®­ç»ƒé›†åˆ†å‰²ä¸ºèƒ½å¤ŸåŸºæœ¬æ­£ç¡®åˆ†ç±»çš„å­é›†ã€‚
5ï¼å†³ç­–æ ‘çš„å‰ªæã€‚ç”±äºç”Ÿæˆçš„å†³ç­–æ ‘å­˜åœ¨è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œéœ€è¦å¯¹å®ƒè¿›è¡Œå‰ªæï¼Œä»¥ç®€åŒ–å­¦åˆ°çš„å†³ç­–æ ‘ã€‚å†³ç­–æ ‘çš„å‰ªæï¼Œå¾€å¾€ä»å·²ç”Ÿæˆçš„æ ‘ä¸Šå‰ªæ‰ä¸€äº›å¶ç»“ç‚¹æˆ–å¶ç»“ç‚¹ä»¥ä¸Šçš„å­æ ‘ï¼Œå¹¶å°†å…¶çˆ¶ç»“ç‚¹æˆ–æ ¹ç»“ç‚¹ä½œä¸ºæ–°çš„å¶ç»“ç‚¹ï¼Œä»è€Œç®€åŒ–ç”Ÿæˆçš„å†³ç­–æ ‘ã€‚
#å¯¼åº“ import numpy as np import pandas as pd import math from sklearn import tree import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = [&amp;#34;SimHei&amp;#34;] plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False #åŸå§‹æ•°æ® def create_data(): datasets = [[&amp;#39;é’å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;ä¸€èˆ¬&amp;#39;, &amp;#39;å¦&amp;#39;], [&amp;#39;é’å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;å¦&amp;#39;], [&amp;#39;é’å¹´&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;é’å¹´&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;ä¸€èˆ¬&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;é’å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;ä¸€èˆ¬&amp;#39;, &amp;#39;å¦&amp;#39;], [&amp;#39;ä¸­å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;ä¸€èˆ¬&amp;#39;, &amp;#39;å¦&amp;#39;], [&amp;#39;ä¸­å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;å¦&amp;#39;], [&amp;#39;ä¸­å¹´&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;ä¸­å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;éå¸¸å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;ä¸­å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;éå¸¸å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;è€å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;éå¸¸å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;è€å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;è€å¹´&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;è€å¹´&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;éå¸¸å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;è€å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;ä¸€èˆ¬&amp;#39;, &amp;#39;å¦&amp;#39;], ] labels = [u&amp;#39;å¹´é¾„&amp;#39;, u&amp;#39;æœ‰å·¥ä½œ&amp;#39;, u&amp;#39;æœ‰è‡ªå·±çš„æˆ¿å­&amp;#39;, u&amp;#39;ä¿¡è´·æƒ…å†µ&amp;#39;, u&amp;#39;ç±»åˆ«&amp;#39;] # è¿”å›æ•°æ®é›†å’Œæ¯ä¸ªç»´åº¦çš„åç§° return datasets, labels datasets,label = create_data() train_data = pd.</description>
    </item>
    
    <item>
      <title>WZU_DecisionTree</title>
      <link>https://example.com/p/wzu_decisiontree/</link>
      <pubDate>Mon, 20 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_decisiontree/</guid>
      <description>è¿™é‡Œæ˜¯ä¸€ä¸ªé™åˆ¶å†³ç­–æ ‘å±‚æ•°ä¸º4çš„DecisionTreeClassifierä¾‹å­ã€‚
#1.å¯¼å…¥ç›¸å…³åº“ from itertools import product#ç”¨æ¥ç›¸äº’äº¤å‰ä¹˜å³ç¬›å¡å°”ç§¯ import numpy as np import matplotlib.pyplot as plt from sklearn import datasets from sklearn.tree import DecisionTreeClassifier #2.å¯¼å…¥æ•°æ® iris = datasets.load_iris()#ä»ç„¶æ˜¯ä½¿ç”¨é¸¢å°¾èŠ± X = iris.data[:,[0,2]] X result: code:
y = iris.target#æ ‡ç­¾ y result: #ä½¿ç”¨ç®—æ³•è®­ç»ƒæ¨¡å‹ iris_decision_tree = DecisionTreeClassifier(max_depth=4) iris_decision_tree.fit(X,y) result:
DecisionTreeClassifier(max_depth=4) #å¯è§†åŒ–æ•°æ® x_min,x_max = X[:,0].min() - 1, X[:,0].max() + 1#zè¿™ä¸ªå¤„ç†æ˜¯ä¸ºäº†è°ƒæ•´åæ ‡è½´ y_min,y_max = X[:,1].min() - 1, X[:,1].max() + 1 #æ³¨æ„åˆ†ç±»å›¾ä¸­çš„xå’Œy #åˆ›å»ºåæ ‡è½´ xx,yy = np.meshgrid(np.arange(x_min,x_max,0.1),np.arange(y_min,y_max,0.1)) #é¢„æµ‹ Z = iris_decision_tree.</description>
    </item>
    
    <item>
      <title>åˆ˜å»ºå¹³è€å¸ˆPinardåšå®¢çš„SVM_RBFåˆ†ç±»è°ƒå‚ä¾‹å­</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84svm_rbf%E5%88%86%E7%B1%BB%E8%B0%83%E5%8F%82%E4%BE%8B%E5%AD%90/</link>
      <pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84svm_rbf%E5%88%86%E7%B1%BB%E8%B0%83%E5%8F%82%E4%BE%8B%E5%AD%90/</guid>
      <description>import numpy as np import pandas as pd import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import matplotlib import matplotlib.pyplot as plt matplotlib.style.use(&amp;#34;ggplot&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False from sklearn import datasets,svm from sklearn.svm import SVC from sklearn.datasets import make_moons,make_circles,make_classification ç”Ÿæˆä¸€äº›éšæœºæ•°æ®æ¥è®©æˆ‘ä»¬åé¢å»åˆ†ç±»ï¼Œä¸ºäº†æ•°æ®éš¾ä¸€ç‚¹ï¼Œæˆ‘ä»¬åŠ å…¥äº†ä¸€äº›å™ªéŸ³ã€‚ç”Ÿæˆæ•°æ®çš„åŒæ—¶æŠŠæ•°æ®å½’ä¸€åŒ–
#make_circlesç”Ÿæˆæœˆäº®å½¢æ•°æ® X,y = make_circles(noise=0.2,factor=0.5,random_state=22) #ä»sklearn.preprocessingå¯¼å…¥StandardScalerå½’ä¸€åŒ–å¤„ç† from sklearn.preprocessing import StandardScaler X = StandardScaler().fit_transform(X) æˆ‘ä»¬å…ˆçœ‹çœ‹æˆ‘çš„æ•°æ®æ˜¯ä»€ä¹ˆæ ·å­çš„ï¼Œè¿™é‡Œåšä¸€æ¬¡å¯è§†åŒ–å¦‚ä¸‹ï¼š
from matplotlib.colors import ListedColormap # matplotlib.colorsæ¨¡å—ç”¨äºå°†é¢œè‰²æˆ–æ•°å­—å‚æ•°è½¬æ¢ä¸ºRGBAæˆ–RGBã€‚ #æ­¤æ¨¡å—ç”¨äºå°†æ•°å­—æ˜ å°„åˆ°é¢œè‰²æˆ–ä»¥ä¸€ç»´é¢œè‰²æ•°ç»„(ä¹Ÿç§°ä¸ºcolormap)è¿›è¡Œé¢œè‰²è§„æ ¼è½¬æ¢ã€‚ cm = plt.cm.RdBu cm_bright = ListedColormap([&amp;#34;#FF0000&amp;#34;,&amp;#34;#0000FF&amp;#34;]) ax = plt.subplot() ax.set_title(&amp;#34;Input data&amp;#34;) ax.scatter(X[:,0],X[:,1],c=y,cmap=cm_bright) ax.set_xticks(()) ax.</description>
    </item>
    
    <item>
      <title>WZU_KNNä»£ç å­¦ä¹ è®°å½•</title>
      <link>https://example.com/p/wzu_knn%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Tue, 14 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_knn%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>æœºå™¨å­¦ä¹ ç»ƒä¹ 6 KNNç®—æ³• ä»£ç ä¿®æ”¹å¹¶æ³¨é‡Šï¼šé»„æµ·å¹¿ï¼Œhaiguang2000@wzu.edu.cn
1ï¼$k$è¿‘é‚»æ³•æ˜¯åŸºæœ¬ä¸”ç®€å•çš„åˆ†ç±»ä¸å›å½’æ–¹æ³•ã€‚$k$è¿‘é‚»æ³•çš„åŸºæœ¬åšæ³•æ˜¯ï¼šå¯¹ç»™å®šçš„è®­ç»ƒå®ä¾‹ç‚¹å’Œè¾“å…¥å®ä¾‹ç‚¹ï¼Œé¦–å…ˆç¡®å®šè¾“å…¥å®ä¾‹ç‚¹çš„$k$ä¸ªæœ€è¿‘é‚»è®­ç»ƒå®ä¾‹ç‚¹ï¼Œç„¶ååˆ©ç”¨è¿™$k$ä¸ªè®­ç»ƒå®ä¾‹ç‚¹çš„ç±»çš„å¤šæ•°æ¥é¢„æµ‹è¾“å…¥å®ä¾‹ç‚¹çš„ç±»ã€‚
2ï¼$k$è¿‘é‚»æ¨¡å‹å¯¹åº”äºåŸºäºè®­ç»ƒæ•°æ®é›†å¯¹ç‰¹å¾ç©ºé—´çš„ä¸€ä¸ªåˆ’åˆ†ã€‚$k$è¿‘é‚»æ³•ä¸­ï¼Œå½“è®­ç»ƒé›†ã€è·ç¦»åº¦é‡ã€$k$å€¼åŠåˆ†ç±»å†³ç­–è§„åˆ™ç¡®å®šåï¼Œå…¶ç»“æœå”¯ä¸€ç¡®å®šã€‚
3ï¼$k$è¿‘é‚»æ³•ä¸‰è¦ç´ ï¼šè·ç¦»åº¦é‡ã€$k$å€¼çš„é€‰æ‹©å’Œåˆ†ç±»å†³ç­–è§„åˆ™ã€‚å¸¸ç”¨çš„è·ç¦»åº¦é‡æ˜¯æ¬§æ°è·ç¦»åŠæ›´ä¸€èˆ¬çš„pLè·ç¦»ã€‚$k$å€¼å°æ—¶ï¼Œ$k$è¿‘é‚»æ¨¡å‹æ›´å¤æ‚ï¼›$k$å€¼å¤§æ—¶ï¼Œ$k$è¿‘é‚»æ¨¡å‹æ›´ç®€å•ã€‚$k$å€¼çš„é€‰æ‹©åæ˜ äº†å¯¹è¿‘ä¼¼è¯¯å·®ä¸ä¼°è®¡è¯¯å·®ä¹‹é—´çš„æƒè¡¡ï¼Œé€šå¸¸ç”±äº¤å‰éªŒè¯é€‰æ‹©æœ€ä¼˜çš„$k$ã€‚
å¸¸ç”¨çš„åˆ†ç±»å†³ç­–è§„åˆ™æ˜¯å¤šæ•°è¡¨å†³ï¼Œå¯¹åº”äºç»éªŒé£é™©æœ€å°åŒ–ã€‚
4ï¼$k$è¿‘é‚»æ³•çš„å®ç°éœ€è¦è€ƒè™‘å¦‚ä½•å¿«é€Ÿæœç´¢kä¸ªæœ€è¿‘é‚»ç‚¹ã€‚kdæ ‘æ˜¯ä¸€ç§ä¾¿äºå¯¹kç»´ç©ºé—´ä¸­çš„æ•°æ®è¿›è¡Œå¿«é€Ÿæ£€ç´¢çš„æ•°æ®ç»“æ„ã€‚kdæ ‘æ˜¯äºŒå‰æ ‘ï¼Œè¡¨ç¤ºå¯¹$k$ç»´ç©ºé—´çš„ä¸€ä¸ªåˆ’åˆ†ï¼Œå…¶æ¯ä¸ªç»“ç‚¹å¯¹åº”äº$k$ç»´ç©ºé—´åˆ’åˆ†ä¸­çš„ä¸€ä¸ªè¶…çŸ©å½¢åŒºåŸŸã€‚åˆ©ç”¨kdæ ‘å¯ä»¥çœå»å¯¹å¤§éƒ¨åˆ†æ•°æ®ç‚¹çš„æœç´¢ï¼Œ ä»è€Œå‡å°‘æœç´¢çš„è®¡ç®—é‡ã€‚
è·ç¦»åº¦é‡ åœ¨æœºå™¨å­¦ä¹ ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦è®¡ç®—æ ·æœ¬ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œé€šå¸¸çš„åšæ³•æ˜¯è®¡ç®—æ ·æœ¬ä¹‹é—´çš„è·ç¦»ã€‚
è®¾$x$å’Œ$y$ä¸ºä¸¤ä¸ªå‘é‡ï¼Œæ±‚å®ƒä»¬ä¹‹é—´çš„è·ç¦»ã€‚
è¿™é‡Œç”¨Numpyå®ç°ï¼Œè®¾å’Œä¸ºndarray &amp;lt;numpy.ndarray&amp;gt;ï¼Œå®ƒä»¬çš„shapeéƒ½æ˜¯(N,)
$d$ä¸ºæ‰€æ±‚çš„è·ç¦»ï¼Œæ˜¯ä¸ªæµ®ç‚¹æ•°ï¼ˆfloatï¼‰ã€‚
import numpy as np #æ³¨æ„ï¼šè¿è¡Œä»£ç æ—¶å€™éœ€è¦å¯¼å…¥NumPyåº“ æ¬§æ°è·ç¦»(Euclidean distance) æ¬§å‡ é‡Œå¾—åº¦é‡(euclidean metric)(ä¹Ÿç§°æ¬§æ°è·ç¦»)æ˜¯ä¸€ä¸ªé€šå¸¸é‡‡ç”¨çš„è·ç¦»å®šä¹‰ï¼ŒæŒ‡åœ¨$m$ç»´ç©ºé—´ä¸­ä¸¤ä¸ªç‚¹ä¹‹é—´çš„çœŸå®è·ç¦»ï¼Œæˆ–è€…å‘é‡çš„è‡ªç„¶é•¿åº¦(å³è¯¥ç‚¹åˆ°åŸç‚¹çš„è·ç¦»)ã€‚åœ¨äºŒç»´å’Œä¸‰ç»´ç©ºé—´ä¸­çš„æ¬§æ°è·ç¦»å°±æ˜¯ä¸¤ç‚¹ä¹‹é—´çš„å®é™…è·ç¦»ã€‚
è·ç¦»å…¬å¼ï¼š
$$ d\left( x,y \right) = \sqrt{\sum_{i}^{}(x_{i} - y_{i})^{2}} $$ ä»£ç å®ç°ï¼š
def euclidean(x, y): return np.sqrt(np.sum((x - y)**2)) æ›¼å“ˆé¡¿è·ç¦»(Manhattan distance) æƒ³è±¡ä½ åœ¨åŸå¸‚é“è·¯é‡Œï¼Œè¦ä»ä¸€ä¸ªåå­—è·¯å£å¼€è½¦åˆ°å¦å¤–ä¸€ä¸ªåå­—è·¯å£ï¼Œé©¾é©¶è·ç¦»æ˜¯ä¸¤ç‚¹é—´çš„ç›´çº¿è·ç¦»å—ï¼Ÿæ˜¾ç„¶ä¸æ˜¯ï¼Œé™¤éä½ èƒ½ç©¿è¶Šå¤§æ¥¼ã€‚å®é™…é©¾é©¶è·ç¦»å°±æ˜¯è¿™ä¸ªâ€œæ›¼å“ˆé¡¿è·ç¦»â€ã€‚è€Œè¿™ä¹Ÿæ˜¯æ›¼å“ˆé¡¿è·ç¦»åç§°çš„æ¥æºï¼Œæ›¼å“ˆé¡¿è·ç¦»ä¹Ÿç§°ä¸ºåŸå¸‚è¡—åŒºè·ç¦»(City Block distance)ã€‚
è·ç¦»å…¬å¼ï¼š
$$ d(x,y) = \sum_{i}^{}|x_{i} - y_{i}| $$ ä»£ç å®ç°ï¼š
def manhattan(x, y): return np.sum(np.abs(x - y)) åˆ‡æ¯”é›ªå¤«è·ç¦»(Chebyshev distance) åœ¨æ•°å­¦ä¸­ï¼Œåˆ‡æ¯”é›ªå¤«è·ç¦»(Chebyshev distance)æˆ–æ˜¯Lâˆåº¦é‡ï¼Œæ˜¯å‘é‡ç©ºé—´ä¸­çš„ä¸€ç§åº¦é‡ï¼ŒäºŒä¸ªç‚¹ä¹‹é—´çš„è·ç¦»å®šä¹‰æ˜¯å…¶å„åæ ‡æ•°å€¼å·®ç»å¯¹å€¼çš„æœ€å¤§å€¼ã€‚ä»¥æ•°å­¦çš„è§‚ç‚¹æ¥çœ‹ï¼Œåˆ‡æ¯”é›ªå¤«è·ç¦»æ˜¯ç”±ä¸€è‡´èŒƒæ•°(uniform norm)(æˆ–ç§°ä¸ºä¸Šç¡®ç•ŒèŒƒæ•°)æ‰€è¡ç”Ÿçš„åº¦é‡ï¼Œä¹Ÿæ˜¯è¶…å‡¸åº¦é‡(injective metric space)çš„ä¸€ç§ã€‚</description>
    </item>
    
    <item>
      <title>åˆ˜å»ºå¹³è€å¸ˆPinardåšå®¢çš„KNNç®—æ³•ä¾‹å­</title>
      <link>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84knn%E7%AE%97%E6%B3%95%E4%BE%8B%E5%AD%90/</link>
      <pubDate>Tue, 14 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E5%88%98%E5%BB%BA%E5%B9%B3%E8%80%81%E5%B8%88pinard%E5%8D%9A%E5%AE%A2%E7%9A%84knn%E7%AE%97%E6%B3%95%E4%BE%8B%E5%AD%90/</guid>
      <description>è¿™æ˜¯åˆ˜å»ºå¹³Pinardè€å¸ˆåšå®¢ä¸ŠKNNçš„ä¾‹å­ï¼Œç•¥åšäº†ä¿®æ”¹,https://www.cnblogs.com/nolonely/p/6980160.html
%matplotlib inline import numpy as np import pandas as pd import matplotlib.pyplot as plt # from sklearn.datasets.samples_generator import make_classification from sklearn.datasets._samples_generator import make_classification è¿™é‡Œå†è®²ä¸‹sklearn.datasets._sample_generator(æ—§å†™æ³•sklearn.datasets.sample_generator) æ˜¯ç”¨æ¥ç”Ÿæˆæ•°æ®é›†çš„ï¼šå¯ä»¥ç”¨æ¥åˆ†ç±»ä»»åŠ¡ï¼Œå¯ä»¥ç”¨æ¥å›å½’ä»»åŠ¡ï¼Œå¯ä»¥ç”¨æ¥èšç±»ä»»åŠ¡ï¼Œç”¨äºæµå½¢å­¦ä¹ çš„ï¼Œç”¨äºå› å­åˆ†è§£ä»»åŠ¡çš„,ç”¨äºåˆ†ç±»ä»»åŠ¡å’Œèšç±»ä»»åŠ¡çš„ï¼šè¿™äº›å‡½æ•°äº§ç”Ÿæ ·æœ¬ç‰¹å¾å‘é‡çŸ©é˜µä»¥åŠå¯¹åº”çš„ç±»åˆ«æ ‡ç­¾é›†åˆ
make_blobsï¼šå¤šç±»å•æ ‡ç­¾æ•°æ®é›†ï¼Œä¸ºæ¯ä¸ªç±»åˆ†é…ä¸€ä¸ªæˆ–å¤šä¸ªæ­£å¤ªåˆ†å¸ƒçš„ç‚¹é›†
make_classificationï¼šå¤šç±»å•æ ‡ç­¾æ•°æ®é›†ï¼Œä¸ºæ¯ä¸ªç±»åˆ†é…ä¸€ä¸ªæˆ–å¤šä¸ªæ­£å¤ªåˆ†å¸ƒçš„ç‚¹é›†ï¼Œæä¾›äº†ä¸ºæ•°æ®æ·»åŠ å™ªå£°çš„æ–¹å¼ï¼ŒåŒ…æ‹¬ç»´åº¦ç›¸å…³æ€§ï¼Œæ— æ•ˆç‰¹å¾ä»¥åŠå†—ä½™ç‰¹å¾ç­‰
make_gaussian-quantilesï¼šå°†ä¸€ä¸ªå•é«˜æ–¯åˆ†å¸ƒçš„ç‚¹é›†åˆ’åˆ†ä¸ºä¸¤ä¸ªæ•°é‡å‡ç­‰çš„ç‚¹é›†ï¼Œä½œä¸ºä¸¤ç±»
make_hastie-10-2ï¼šäº§ç”Ÿä¸€ä¸ªç›¸ä¼¼çš„äºŒå…ƒåˆ†ç±»æ•°æ®é›†ï¼Œæœ‰10ä¸ªç»´åº¦
make_circleå’Œmake_moomäº§ç”ŸäºŒç»´äºŒå…ƒåˆ†ç±»æ•°æ®é›†æ¥æµ‹è¯•æŸäº›ç®—æ³•çš„æ€§èƒ½ï¼Œå¯ä»¥ä¸ºæ•°æ®é›†æ·»åŠ å™ªå£°ï¼Œå¯ä»¥ä¸ºäºŒå…ƒåˆ†ç±»å™¨äº§ç”Ÿä¸€äº›çƒå½¢åˆ¤å†³ç•Œé¢çš„æ•°æ®,Xä¸ºæ ·æœ¬ç‰¹å¾ï¼ŒYä¸ºæ ·æœ¬ç±»åˆ«è¾“å‡ºï¼Œ å…±1000ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬2ä¸ªç‰¹å¾ï¼Œè¾“å‡ºæœ‰3ä¸ªç±»åˆ«ï¼Œæ²¡æœ‰å†—ä½™ç‰¹å¾ï¼Œæ¯ä¸ªç±»åˆ«ä¸€ä¸ªç°‡
code:
#n_samples æ ·æœ¬æ•° n_featuresç‰¹å¾æ•° n_classesæ ·æœ¬yå³ç±»åˆ«æ•° n_clusters_per_class æ¯ä¸ªç±»åˆ«çš„ç°‡æ•° (è´¨å¿ƒ) æš‚æ—¶æ²¡ææ‡‚è¿™ä¸ªç°‡æ•°æœ‰ä»€ä¹ˆå½±å“ X, Y = make_classification(n_samples=1000, n_features=2, n_redundant=0, n_clusters_per_class=1, n_classes=3) X[:10] result: code:
Y[:10] result:
array([1, 0, 1, 2, 1, 1, 2, 1, 2, 0]) code:
plt.scatter(X[:, 0], X[:, 1], marker=&amp;#39;o&amp;#39;, c=Y) #å‚æ•°cå°±æ˜¯colorï¼Œèµ‹å€¼ä¸ºå¯è¿­ä»£å‚æ•°å¯¹è±¡ï¼Œé•¿åº¦ä¸xï¼Œyç›¸åŒï¼Œæ ¹æ®å€¼çš„ä¸åŒä½¿å¾—ï¼ˆx,yï¼‰å‚æ•°å¯¹è¡¨ç°ä¸ºä¸åŒçš„é¢œè‰²ã€‚ # ç®€å•åœ°è¯´ï¼ŒæŒ‰x,yå€¼å…¶ä¸­æŸä¸€ä¸ªå€¼æ¥åŒºåˆ†é¢œè‰²å°±å¥½ï¼Œæ¯”å¦‚ä¸Šè¾¹æƒ³æŒ‰ç…§yå€¼æ¥åŒºåˆ†ï¼Œæ‰€ä»¥ç›´æ¥c=yå°±å¯ä»¥äº†ï¼Œ #è¿™é‡Œå°±æ˜¯æ ¹æ®ç±»å–åˆ’åˆ†é¢œè‰² plt.</description>
    </item>
    
    <item>
      <title>my_KNN_code</title>
      <link>https://example.com/p/my_knn_code/</link>
      <pubDate>Sun, 12 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/my_knn_code/</guid>
      <description>è¿™é‡Œæ˜¯ç”¨sklearnçš„KDtreeæ¥å®ç°WZUå¯¹åº”çš„çº¯æ‰‹å†™çš„é‚£ä¸€éƒ¨åˆ†ï¼Œå› ä¸ºçº¯æ‰‹å†™å¤ªéº»çƒ¦äº†ï¼Œä¸è¿‡é‡Œé¢æåˆ°çš„æ’åºçš„æ€è·¯å€¼å¾—ä¸€å­¦ï¼ï¼ é¡ºä¾¿è¯´ä¸€ä¸‹ï¼ŒWZUçš„KNNçš„é‚£ä¸ªKDç»˜å›¾ï¼Œæˆ‘è¿˜æ²¡çœ‹
import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn import neighbors #sklearnä¸­çš„knnæ˜¯æœ‰kdæ ‘å’Œé™å®šåŠå¾„è¿‘é‚»ï¼Œæˆ‘ä»¬è¿™é‡Œç”¨çš„æ˜¯kdæ ‘ from matplotlib.colors import ListedColormap#æ–¹ä¾¿å¯è§†åŒ–æ—¶ï¼Œä½¿å¾—ç›¸åŒçš„ç±»é¢œè‰²ä¸€è‡´ åœ¨è¿™æ¬¡æ•°æ®ä¸­æ²¡æœ‰æ„ä¹‰äº† import random from time import process_time#è·å–å½“å‰çš„æ—¶é—´ import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = [&amp;#34;SimHei&amp;#34;] plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False åœ¨æ¬¡ä¹‹å‰å…ˆè®©æˆ‘ä»¬çœ‹çœ‹mdä¸­æ•°æ®æ¥ç†Ÿæ‚‰sklearnä¸­KDtreeçš„ä½¿ç”¨
from sklearn import neighbors data_md = [(2,3), (5,7), (9,6), (4,5), (6,4), (7,2) ] data_md_tree = neighbors.KDTree(data_md) #Get data and node arrays. data_md_tree.get_arrays() #Arrays for storing tree data, index, node data and node bounds.</description>
    </item>
    
    <item>
      <title>myNBcode</title>
      <link>https://example.com/p/mynbcode/</link>
      <pubDate>Sat, 11 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/mynbcode/</guid>
      <description>copyè¿‡æ¥çš„ï¼Œç•¥ä½œä¿®æ”¹
1ï¼æœ´ç´ è´å¶æ–¯æ³•æ˜¯å…¸å‹çš„ç”Ÿæˆå­¦ä¹ æ–¹æ³•ã€‚ç”Ÿæˆæ–¹æ³•ç”±è®­ç»ƒæ•°æ®å­¦ä¹ è”åˆæ¦‚ç‡åˆ†å¸ƒ $P(X,Y)$ï¼Œç„¶åæ±‚å¾—åéªŒæ¦‚ç‡åˆ†å¸ƒ$P(Y|X)$ã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨è®­ç»ƒæ•°æ®å­¦ä¹ $P(X|Y)$å’Œ$P(Y)$çš„ä¼°è®¡ï¼Œå¾—åˆ°è”åˆæ¦‚ç‡åˆ†å¸ƒï¼š
$$P(X,Y)ï¼P(Y)P(X|Y)$$
æ¦‚ç‡ä¼°è®¡æ–¹æ³•å¯ä»¥æ˜¯æå¤§ä¼¼ç„¶ä¼°è®¡æˆ–è´å¶æ–¯ä¼°è®¡ã€‚
2ï¼æœ´ç´ è´å¶æ–¯æ³•çš„åŸºæœ¬å‡è®¾æ˜¯æ¡ä»¶ç‹¬ç«‹æ€§ï¼Œ
$$\begin{aligned} P(X&amp;amp;=x | Y=c_{k} )=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} | Y=c_{k}\right) \ &amp;amp;=\prod_{j=1}^{n} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right) \end{aligned}$$
è¿™æ˜¯ä¸€ä¸ªè¾ƒå¼ºçš„å‡è®¾ã€‚ç”±äºè¿™ä¸€å‡è®¾ï¼Œæ¨¡å‹åŒ…å«çš„æ¡ä»¶æ¦‚ç‡çš„æ•°é‡å¤§ä¸ºå‡å°‘ï¼Œæœ´ç´ è´å¶æ–¯æ³•çš„å­¦ä¹ ä¸é¢„æµ‹å¤§ä¸ºç®€åŒ–ã€‚å› è€Œæœ´ç´ è´å¶æ–¯æ³•é«˜æ•ˆï¼Œä¸”æ˜“äºå®ç°ã€‚å…¶ç¼ºç‚¹æ˜¯åˆ†ç±»çš„æ€§èƒ½ä¸ä¸€å®šå¾ˆé«˜ã€‚
3ï¼æœ´ç´ è´å¶æ–¯æ³•åˆ©ç”¨è´å¶æ–¯å®šç†ä¸å­¦åˆ°çš„è”åˆæ¦‚ç‡æ¨¡å‹è¿›è¡Œåˆ†ç±»é¢„æµ‹ã€‚
$$P(Y | X)=\frac{P(X, Y)}{P(X)}=\frac{P(Y) P(X | Y)}{\sum_{Y} P(Y) P(X | Y)}$$
å°†è¾“å…¥$x$åˆ†åˆ°åéªŒæ¦‚ç‡æœ€å¤§çš„ç±»$y$ã€‚
$$y=\arg \max {c{k}} P\left(Y=c_{k}\right) \prod_{j=1}^{n} P\left(X_{j}=x^{(j)} | Y=c_{k}\right)$$
åéªŒæ¦‚ç‡æœ€å¤§ç­‰ä»·äº0-1æŸå¤±å‡½æ•°æ—¶çš„æœŸæœ›é£é™©æœ€å°åŒ–ã€‚ï¼ˆå¯èƒ½ä¼šç”¨åˆ°æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼‰
æ¨¡å‹ï¼š
é«˜æ–¯æ¨¡å‹ å¤šé¡¹å¼æ¨¡å‹ ä¼¯åŠªåˆ©æ¨¡å‹ è‡ªå®šä¹‰ä¸€ç»„æ•°æ®ç”¨æ¥çœ‹çœ‹ import numpy as np import pandas as pd import math from collections import Counter #è¿™é‡Œç”¨çš„æ˜¯sklearnä¸Šè‡ªå¸¦çš„æ•°æ®é›†Iris é¸¢å°¾èŠ± #https://www.cnblogs.com/nolonely/p/6980160.html #http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html from sklearn.datasets import load_iris #ä»model_selectionæ¨¡å—ä¸­å¯¼å…¥train_test_splitåˆ’åˆ†æ•°æ®ç”¨ from sklearn.</description>
    </item>
    
    <item>
      <title>mylogicRegresscode</title>
      <link>https://example.com/p/mylogicregresscode/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/mylogicregresscode/</guid>
      <description>è¿™æ¬¡æ¥ç»ƒä¹ ä¸‹é€»è¾‘å›å½’,æ„Ÿè§‰è¿‡ç¨‹å’Œçº¿æ€§å›å½’å¾ˆç±»ä¼¼ï¼Œåªæ˜¯åŠ äº†ä¸ªsigmoidå‡½æ•°,datasetåˆ†åˆ«æ˜¯ex2data1.txt / ex2data2.txt
dataset1 åœ¨è®­ç»ƒçš„åˆå§‹é˜¶æ®µï¼Œæˆ‘ä»¬å°†è¦æ„å»ºä¸€ä¸ªé€»è¾‘å›å½’æ¨¡å‹æ¥é¢„æµ‹ï¼ŒæŸä¸ªå­¦ç”Ÿæ˜¯å¦è¢«å¤§å­¦å½•å–ã€‚è®¾æƒ³ä½ æ˜¯å¤§å­¦ç›¸å…³éƒ¨åˆ†çš„ç®¡ç†è€…ï¼Œæƒ³é€šè¿‡ç”³è¯·å­¦ç”Ÿä¸¤æ¬¡æµ‹è¯•çš„è¯„åˆ†ï¼Œæ¥å†³å®šä»–ä»¬æ˜¯å¦è¢«å½•å–ã€‚ç°åœ¨ä½ æ‹¥æœ‰ä¹‹å‰ç”³è¯·å­¦ç”Ÿçš„å¯ä»¥ç”¨äºè®­ç»ƒé€»è¾‘å›å½’çš„è®­ç»ƒæ ·æœ¬é›†ã€‚å¯¹äºæ¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œä½ æœ‰ä»–ä»¬ä¸¤æ¬¡æµ‹è¯•çš„è¯„åˆ†å’Œæœ€åæ˜¯è¢«å½•å–çš„ç»“æœã€‚ä¸ºäº†å®Œæˆè¿™ä¸ªé¢„æµ‹ä»»åŠ¡ï¼Œæˆ‘ä»¬å‡†å¤‡æ„å»ºä¸€ä¸ªå¯ä»¥åŸºäºä¸¤æ¬¡æµ‹è¯•è¯„åˆ†æ¥è¯„ä¼°å½•å–å¯èƒ½æ€§çš„åˆ†ç±»æ¨¡å‹ã€‚ä¸Šé¢çš„è¯æ˜¯copyè¿‡æ¥çš„
åˆ†ææ•°æ® import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns sns.set_style(&amp;#39;white&amp;#39;) import warnings warnings.filterwarnings(&amp;#39;ignore&amp;#39;) #ä¸ºäº†ç¾è§‚ï¼Œå½“ç„¶æ˜¯ä¸å½±å“ç»“æœçš„å‰æä¸‹ plt.rcParams[&amp;#39;font.sans-serif&amp;#39;]=[&amp;#39;SimHei&amp;#39;] #æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡ plt.rcParams[&amp;#39;axes.unicode_minus&amp;#39;]=False #æ­£å¸¸æ˜¾ç¤ºéè´Ÿå· dataset1 = pd.read_csv(&amp;#39;./ex2data1.txt&amp;#39;,header=None,names=[&amp;#39;Exam1&amp;#39;,&amp;#39;Exam2&amp;#39;,&amp;#39;Admitted&amp;#39;]) dataset1.head() result: code:
dataset1.describe() result: code:
dataset1.shape result:
(100, 3) code:
dataset1.isnull().sum() result:
Exam1 0 Exam2 0 Admitted 0 dtype: int64 #å¯è§†åŒ–ä¸‹æ•°æ® f,axes = plt.subplots(figsize=(9,9)) dataset1_corr = dataset1.corr() print(dataset1_corr) sns.heatmap(dataset1_corr,annot=True) plt.xticks(range(len(dataset1_corr.columns)),dataset1_corr.columns) plt.yticks(range(len(dataset1_corr.columns)),dataset1_corr.columns) plt.show() result: f,axes = plt.</description>
    </item>
    
    <item>
      <title>WZU_å†³ç­–æ ‘ç®—æ³•ä»£ç å­¦ä¹ è®°å½•</title>
      <link>https://example.com/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>æœºå™¨å­¦ä¹ ç»ƒä¹ 7 å†³ç­–æ ‘ ä»£ç ä¿®æ”¹å¹¶æ³¨é‡Šï¼šé»„æµ·å¹¿ï¼Œhaiguang2000@wzu.edu.cn
1ï¼åˆ†ç±»å†³ç­–æ ‘æ¨¡å‹æ˜¯è¡¨ç¤ºåŸºäºç‰¹å¾å¯¹å®ä¾‹è¿›è¡Œåˆ†ç±»çš„æ ‘å½¢ç»“æ„ã€‚å†³ç­–æ ‘å¯ä»¥è½¬æ¢æˆä¸€ä¸ªif-thenè§„åˆ™çš„é›†åˆï¼Œä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯å®šä¹‰åœ¨ç‰¹å¾ç©ºé—´åˆ’åˆ†ä¸Šçš„ç±»çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚
2ï¼å†³ç­–æ ‘å­¦ä¹ æ—¨åœ¨æ„å»ºä¸€ä¸ªä¸è®­ç»ƒæ•°æ®æ‹Ÿåˆå¾ˆå¥½ï¼Œå¹¶ä¸”å¤æ‚åº¦å°çš„å†³ç­–æ ‘ã€‚å› ä¸ºä»å¯èƒ½çš„å†³ç­–æ ‘ä¸­ç›´æ¥é€‰å–æœ€ä¼˜å†³ç­–æ ‘æ˜¯NPå®Œå…¨é—®é¢˜ã€‚ç°å®ä¸­é‡‡ç”¨å¯å‘å¼æ–¹æ³•å­¦ä¹ æ¬¡ä¼˜çš„å†³ç­–æ ‘ã€‚
å†³ç­–æ ‘å­¦ä¹ ç®—æ³•åŒ…æ‹¬3éƒ¨åˆ†ï¼šç‰¹å¾é€‰æ‹©ã€æ ‘çš„ç”Ÿæˆå’Œæ ‘çš„å‰ªæã€‚å¸¸ç”¨çš„ç®—æ³•æœ‰ID3ã€ C4.5å’ŒCARTã€‚
3ï¼ç‰¹å¾é€‰æ‹©çš„ç›®çš„åœ¨äºé€‰å–å¯¹è®­ç»ƒæ•°æ®èƒ½å¤Ÿåˆ†ç±»çš„ç‰¹å¾ã€‚ç‰¹å¾é€‰æ‹©çš„å…³é”®æ˜¯å…¶å‡†åˆ™ã€‚å¸¸ç”¨çš„å‡†åˆ™å¦‚ä¸‹ï¼š
ï¼ˆ1ï¼‰æ ·æœ¬é›†åˆ$D$å¯¹ç‰¹å¾$A$çš„ä¿¡æ¯å¢ç›Šï¼ˆID3ï¼‰
$$g(D, A)=H(D)-H(D|A)$$
$$H(D)=-\sum_{k=1}^{K} \frac{\left|C_{k}\right|}{|D|} \log {2} \frac{\left|C{k}\right|}{|D|}$$
$$H(D | A)=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} H\left(D_{i}\right)$$
å…¶ä¸­ï¼Œ$H(D)$æ˜¯æ•°æ®é›†$D$çš„ç†µï¼Œ$H(D_i)$æ˜¯æ•°æ®é›†$D_i$çš„ç†µï¼Œ$H(D|A)$æ˜¯æ•°æ®é›†$D$å¯¹ç‰¹å¾$A$çš„æ¡ä»¶ç†µã€‚	$D_i$æ˜¯$D$ä¸­ç‰¹å¾$A$å–ç¬¬$i$ä¸ªå€¼çš„æ ·æœ¬å­é›†ï¼Œ$C_k$æ˜¯$D$ä¸­å±äºç¬¬$k$ç±»çš„æ ·æœ¬å­é›†ã€‚$n$æ˜¯ç‰¹å¾$A$å– å€¼çš„ä¸ªæ•°ï¼Œ$K$æ˜¯ç±»çš„ä¸ªæ•°ã€‚
ï¼ˆ2ï¼‰æ ·æœ¬é›†åˆ$D$å¯¹ç‰¹å¾$A$çš„ä¿¡æ¯å¢ç›Šæ¯”ï¼ˆC4.5ï¼‰
$$g_{R}(D, A)=\frac{g(D, A)}{H(D)}$$
å…¶ä¸­ï¼Œ$g(D,A)$æ˜¯ä¿¡æ¯å¢ç›Šï¼Œ$H(D)$æ˜¯æ•°æ®é›†$D$çš„ç†µã€‚
ï¼ˆ3ï¼‰æ ·æœ¬é›†åˆ$D$çš„åŸºå°¼æŒ‡æ•°ï¼ˆCARTï¼‰
$$\operatorname{Gini}(D)=1-\sum_{k=1}^{K}\left(\frac{\left|C_{k}\right|}{|D|}\right)^{2}$$
ç‰¹å¾$A$æ¡ä»¶ä¸‹é›†åˆ$D$çš„åŸºå°¼æŒ‡æ•°ï¼š
$$\operatorname{Gini}(D, A)=\frac{\left|D_{1}\right|}{|D|} \operatorname{Gini}\left(D_{1}\right)+\frac{\left|D_{2}\right|}{|D|} \operatorname{Gini}\left(D_{2}\right)$$
4ï¼å†³ç­–æ ‘çš„ç”Ÿæˆã€‚é€šå¸¸ä½¿ç”¨ä¿¡æ¯å¢ç›Šæœ€å¤§ã€ä¿¡æ¯å¢ç›Šæ¯”æœ€å¤§æˆ–åŸºå°¼æŒ‡æ•°æœ€å°ä½œä¸ºç‰¹å¾é€‰æ‹©çš„å‡†åˆ™ã€‚å†³ç­–æ ‘çš„ç”Ÿæˆå¾€å¾€é€šè¿‡è®¡ç®—ä¿¡æ¯å¢ç›Šæˆ–å…¶ä»–æŒ‡æ ‡ï¼Œä»æ ¹ç»“ç‚¹å¼€å§‹ï¼Œé€’å½’åœ°äº§ç”Ÿå†³ç­–æ ‘ã€‚è¿™ç›¸å½“äºç”¨ä¿¡æ¯å¢ç›Šæˆ–å…¶ä»–å‡†åˆ™ä¸æ–­åœ°é€‰å–å±€éƒ¨æœ€ä¼˜çš„ç‰¹å¾ï¼Œæˆ–å°†è®­ç»ƒé›†åˆ†å‰²ä¸ºèƒ½å¤ŸåŸºæœ¬æ­£ç¡®åˆ†ç±»çš„å­é›†ã€‚
5ï¼å†³ç­–æ ‘çš„å‰ªæã€‚ç”±äºç”Ÿæˆçš„å†³ç­–æ ‘å­˜åœ¨è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œéœ€è¦å¯¹å®ƒè¿›è¡Œå‰ªæï¼Œä»¥ç®€åŒ–å­¦åˆ°çš„å†³ç­–æ ‘ã€‚å†³ç­–æ ‘çš„å‰ªæï¼Œå¾€å¾€ä»å·²ç”Ÿæˆçš„æ ‘ä¸Šå‰ªæ‰ä¸€äº›å¶ç»“ç‚¹æˆ–å¶ç»“ç‚¹ä»¥ä¸Šçš„å­æ ‘ï¼Œå¹¶å°†å…¶çˆ¶ç»“ç‚¹æˆ–æ ¹ç»“ç‚¹ä½œä¸ºæ–°çš„å¶ç»“ç‚¹ï¼Œä»è€Œç®€åŒ–ç”Ÿæˆçš„å†³ç­–æ ‘ã€‚
import numpy as np import pandas as pd import math from math import log åˆ›å»ºæ•°æ® def create_data(): datasets = [[&amp;#39;é’å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;ä¸€èˆ¬&amp;#39;, &amp;#39;å¦&amp;#39;], [&amp;#39;é’å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;å¦&amp;#39;], [&amp;#39;é’å¹´&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;é’å¹´&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;ä¸€èˆ¬&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;é’å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;ä¸€èˆ¬&amp;#39;, &amp;#39;å¦&amp;#39;], [&amp;#39;ä¸­å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;ä¸€èˆ¬&amp;#39;, &amp;#39;å¦&amp;#39;], [&amp;#39;ä¸­å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;å¦&amp;#39;], [&amp;#39;ä¸­å¹´&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;ä¸­å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;éå¸¸å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;ä¸­å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;éå¸¸å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;è€å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;éå¸¸å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;è€å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;è€å¹´&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;è€å¹´&amp;#39;, &amp;#39;æ˜¯&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;éå¸¸å¥½&amp;#39;, &amp;#39;æ˜¯&amp;#39;], [&amp;#39;è€å¹´&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;å¦&amp;#39;, &amp;#39;ä¸€èˆ¬&amp;#39;, &amp;#39;å¦&amp;#39;], ] labels = [u&amp;#39;å¹´é¾„&amp;#39;, u&amp;#39;æœ‰å·¥ä½œ&amp;#39;, u&amp;#39;æœ‰è‡ªå·±çš„æˆ¿å­&amp;#39;, u&amp;#39;ä¿¡è´·æƒ…å†µ&amp;#39;, u&amp;#39;ç±»åˆ«&amp;#39;] # è¿”å›æ•°æ®é›†å’Œæ¯ä¸ªç»´åº¦çš„åç§° return datasets, labels datasets, labels = create_data() train_data = pd.</description>
    </item>
    
    <item>
      <title>WZU_é€»è¾‘å›å½’ä»£ç å­¦ä¹ è®°å½•</title>
      <link>https://example.com/p/wzu_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>æœºå™¨å­¦ä¹ ç»ƒä¹  3 - é€»è¾‘å›å½’
åœ¨è¿™ä¸€æ¬¡ç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†è¦å®ç°é€»è¾‘å›å½’å¹¶ä¸”åº”ç”¨åˆ°ä¸€ä¸ªåˆ†ç±»ä»»åŠ¡ã€‚æˆ‘ä»¬è¿˜å°†é€šè¿‡å°†æ­£åˆ™åŒ–åŠ å…¥è®­ç»ƒç®—æ³•ï¼Œæ¥æé«˜ç®—æ³•çš„é²æ£’æ€§ï¼Œå¹¶ç”¨æ›´å¤æ‚çš„æƒ…å½¢æ¥æµ‹è¯•å®ƒã€‚
ä»£ç ä¿®æ”¹å¹¶æ³¨é‡Šï¼šé»„æµ·å¹¿ï¼Œhaiguang2000@wzu.edu.cn
é€»è¾‘å›å½’ åœ¨è®­ç»ƒçš„åˆå§‹é˜¶æ®µï¼Œæˆ‘ä»¬å°†è¦æ„å»ºä¸€ä¸ªé€»è¾‘å›å½’æ¨¡å‹æ¥é¢„æµ‹ï¼ŒæŸä¸ªå­¦ç”Ÿæ˜¯å¦è¢«å¤§å­¦å½•å–ã€‚è®¾æƒ³ä½ æ˜¯å¤§å­¦ç›¸å…³éƒ¨åˆ†çš„ç®¡ç†è€…ï¼Œæƒ³é€šè¿‡ç”³è¯·å­¦ç”Ÿä¸¤æ¬¡æµ‹è¯•çš„è¯„åˆ†ï¼Œæ¥å†³å®šä»–ä»¬æ˜¯å¦è¢«å½•å–ã€‚ç°åœ¨ä½ æ‹¥æœ‰ä¹‹å‰ç”³è¯·å­¦ç”Ÿçš„å¯ä»¥ç”¨äºè®­ç»ƒé€»è¾‘å›å½’çš„è®­ç»ƒæ ·æœ¬é›†ã€‚å¯¹äºæ¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œä½ æœ‰ä»–ä»¬ä¸¤æ¬¡æµ‹è¯•çš„è¯„åˆ†å’Œæœ€åæ˜¯è¢«å½•å–çš„ç»“æœã€‚ä¸ºäº†å®Œæˆè¿™ä¸ªé¢„æµ‹ä»»åŠ¡ï¼Œæˆ‘ä»¬å‡†å¤‡æ„å»ºä¸€ä¸ªå¯ä»¥åŸºäºä¸¤æ¬¡æµ‹è¯•è¯„åˆ†æ¥è¯„ä¼°å½•å–å¯èƒ½æ€§çš„åˆ†ç±»æ¨¡å‹ã€‚
è®©æˆ‘ä»¬ä»æ£€æŸ¥æ•°æ®å¼€å§‹ã€‚
import numpy as np import pandas as pd import matplotlib.pyplot as plt path = &amp;#39;ex2data1.txt&amp;#39; data = pd.read_csv(path, header=None, names=[&amp;#39;Exam 1&amp;#39;, &amp;#39;Exam 2&amp;#39;, &amp;#39;Admitted&amp;#39;]) data.head() result: code:
data.shape result:
(100, 3) è®©æˆ‘ä»¬åˆ›å»ºä¸¤ä¸ªåˆ†æ•°çš„æ•£ç‚¹å›¾ï¼Œå¹¶ä½¿ç”¨é¢œè‰²ç¼–ç æ¥å¯è§†åŒ–ï¼Œå¦‚æœæ ·æœ¬æ˜¯æ­£çš„ï¼ˆè¢«æ¥çº³ï¼‰æˆ–è´Ÿçš„ï¼ˆæœªè¢«æ¥çº³ï¼‰ã€‚
positive = data[data[&amp;#39;Admitted&amp;#39;].isin([1])] negative = data[data[&amp;#39;Admitted&amp;#39;].isin([0])] fig, ax = plt.subplots(figsize=(12, 8)) ax.scatter(positive[&amp;#39;Exam 1&amp;#39;], positive[&amp;#39;Exam 2&amp;#39;], s=50, c=&amp;#39;b&amp;#39;, marker=&amp;#39;o&amp;#39;, label=&amp;#39;Admitted&amp;#39;) ax.scatter(negative[&amp;#39;Exam 1&amp;#39;], negative[&amp;#39;Exam 2&amp;#39;], s=50, c=&amp;#39;r&amp;#39;, marker=&amp;#39;x&amp;#39;, label=&amp;#39;Not Admitted&amp;#39;) ax.legend() ax.</description>
    </item>
    
    <item>
      <title>myRegressioncode1</title>
      <link>https://example.com/p/myregressioncode1/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/myregressioncode1/</guid>
      <description>è¿™æ˜¯é’ˆå¯¹å´æ©è¾¾è€å¸ˆè¯¾ç¨‹çš„çº¿æ€§å›å½’çš„è¯¾åç»ƒä¹  dataset:regress_data1.csv/regress_data2.csv
é‡‡ç”¨æ‰‹å†™ç®—æ³•ï¼ŒåˆæœŸä¸è°ƒç”¨sklearnåº“
æ”¶é›†æ•°æ® æ•°æ®ç”±å¤–éƒ¨æä¾›
åˆ†ææ•°æ® import pandas as pd import numpy as np import matplotlib.pyplot as plt dataset1 = pd.read_csv(&amp;#34;./regress_data1.csv&amp;#34;) print(dataset1.head()) print(dataset1.describe()) result: å¯ä»¥çœ‹å‡ºåªæœ‰ä¸€ä¸ªç‰¹å¾å±äºå•å˜é‡çš„çº¿æ€§å›å½’
#å¯è§†åŒ–æ•°æ® plt.rcParams[&amp;#39;font.sans-serif&amp;#39;]=[&amp;#39;SimHei&amp;#39;]#æ˜¾ç¤ºä¸­æ–‡ plt.rcParams[&amp;#39;axes.unicode_minus&amp;#39;]=False#æ˜¾ç¤ºè´Ÿå· dataset1.plot(kind=&amp;#39;scatter&amp;#39;,x=&amp;#39;äººå£&amp;#39;,y=&amp;#39;æ”¶ç›Š&amp;#39;,figsize=(12,8)) plt.xlabel(&amp;#39;äººå£&amp;#39;,fontsize=18) plt.ylabel(&amp;#39;æ”¶ç›Š&amp;#39;,fontsize=18)#å¯ä»¥æ·»åŠ rotationx=0ä½¿å¾—æ”¶ç›Šè½¬ä¸ºæ¥ plt.show() result: å¤„ç†æ•°æ® #æ’å…¥ä¸€åˆ—æ’ä¸º1çš„åˆ— dataset1.insert(0,&amp;#39;Ones&amp;#39;,1)#åœ¨ç¬¬é›¶åˆ—æ’å…¥åˆ—åä¸ºOnesï¼Œå€¼ä¸º1 çš„ä¸€åˆ— dataset1 result: #åˆ†å¼€ç‰¹å¾å’Œç›®æ ‡ X = dataset1.iloc[:,:2] Y = dataset1.iloc[:,2] print(X.head()) print(Y.head()) print(Y.shape) result: code:
X.shape result:
(97, 2) è®­ç»ƒç®—æ³• #ç¼–å†™costå‡½æ•°ï¼Œæ–¹ä¾¿èµ·è§å†™æˆnpæ•°ç»„ï¼Œå¹¶åˆå§‹åŒ–wå’Œalpha X = np.matrix(X.values) Y = np.matrix(Y.values).T w = np.matrix(np.array([0,0]))#å› ä¸ºä»dataset1ä¸­å¯ä»¥çœ‹å‡ºåªæœ‰ä¸¤ä¸ªç‰¹å¾ï¼Œæ‰€ä»¥åˆå§‹åŒ–wä¸ºï¼ˆ1ï¼Œ2ï¼‰çš„0çŸ©é˜µå°±å¥½äº† print(X.shape,Y.shape,w.shape)#æ³¨æ„çŸ©é˜µçš„æ•°æ®çš„è¡Œåˆ— result:
(97, 2) (97, 1) (1, 2) å‚æ•°$w$ä¸ºç‰¹å¾å‡½æ•°çš„ä»£ä»·å‡½æ•° $$J\left( w \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{{{\left( {{h}}\left( {{x}^{(i)}} \right)-{{y}^{(i)}} \right)}^{2}}}$$ å…¶ä¸­ï¼š$${{h}}\left( x \right)={{w}^{T}}X={{w }{0}}{{x}{0}}+{{w }{1}}{{x}{1}}+{{w }{2}}{{x}{2}}+&amp;hellip;+{{w }{n}}{{x}{n}}$$ code:</description>
    </item>
    
    <item>
      <title>myRegressioncode2</title>
      <link>https://example.com/p/myregressioncode2/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/myregressioncode2/</guid>
      <description>è¿™æ¬¡ç»ƒä¹ é‡‡ç”¨sklearnæ¥å®ç°é¢„æµ‹,datasetï¼šToyotaCorolla,è¿™é‡Œä¸è¯¦ç»†æ¢ç©¶è°ƒå‚ï¼ŒåæœŸè¿”å›æ¥å†æ‘¸ç´¢å‚æ•°å¯¹è®­ç»ƒçš„å½±å“,date 2021/10/1
æ”¶é›†æ•°æ® åˆ†ææ•°æ® import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt sns.set_style(&amp;#39;white&amp;#39;) dataset = pd.read_csv(&amp;#39;ToyotaCorolla.csv&amp;#39;) dataset.head()#æœ€å¥½åŠ ä¸Šï¼ˆï¼‰è¾“å‡ºçš„ç»“æ„ç»“æ„æ¯”è¾ƒå¥½çœ‹ result: dataset.describe() result: code:
len(dataset)#dataset.count()ä¹Ÿè¡Œ result:
1436 code:
dataset.isnull().sum()#æ•°æ®æ ·æœ¬çœ‹æ¥ä¸ç”¨åšnullçš„å¤„ç†äº†ï¼Œæ²¡æœ‰nullå€¼~~~å¤ªå¥½äº† result: code:
#é‡‡ç”¨å’Œseabornå¯è§†åŒ–æ•°æ®,ç”¨ä¸€ä¸‹çƒ­å›¾å§ #é¦–å…ˆï¼Œå…ˆçœ‹çœ‹ç›¸å…³æ€§ dataset_corr = dataset.corr() print(dataset_corr.shape) #corræ˜¯pandasçš„å‡½æ•°ä¹‹ä¸€ï¼Œè®¡ç®—åˆ—ä¸åˆ—ä¹‹é—´çš„ç›¸å…³ç³»æ•°ï¼Œè¿”å›ç›¸å…³ç³»æ•°çŸ©é˜µï¼Œç›¸å…³ç³»æ•°çš„å–å€¼èŒƒå›´ä¸º[-1, 1],å½“æ¥è¿‘1æ—¶ï¼Œè¡¨ç¤ºä¸¤è€…å…·æœ‰å¼ºçƒˆçš„æ­£ç›¸å…³æ€§ï¼Œæ¯”å¦‚â€˜sâ€™å’Œâ€˜xâ€™ï¼›å½“æ¥è¿‘-1æ—¶ï¼Œè¡¨ç¤ºæœ‰å¼ºçƒˆçš„çš„è´Ÿç›¸å…³æ€§ï¼Œæ¯”å¦‚â€˜sâ€™å’Œâ€˜câ€™ï¼Œè€Œè‹¥å€¼æ¥è¿‘0ï¼Œåˆ™è¡¨ç¤ºç›¸å…³æ€§å¾ˆä½. f,axes = plt.subplots(figsize=(10,10)) sns.heatmap(dataset_corr,annot=True,fmt=&amp;#39;.3f&amp;#39;) length = dataset_corr.columns plt.yticks(range(len(length)),dataset_corr.columns) plt.xticks(range(len(length)),dataset_corr.columns) plt.show() result: code:
dataset_corr = dataset.corr() length = dataset_corr.columns print(length) result: ç”±ä¸Šé¢çš„çƒ­å›¾å¯ä»¥çœ‹å‡ºpriceå’ŒAgeã€KMå‘ˆè´Ÿç›¸å…³ç³»æ•°è¾ƒå¤§ï¼Œå’ŒHPã€Weightå‘ˆæ­£ç›¸å…³çš„ç³»æ•°è¾ƒå¤§;æ³¨æ„çƒ­å›¾ä¸­æ²¡æœ‰æ˜¾ç¤ºFuelTypeçš„æ•°æ®ï¼Œå› ä¸ºå®ƒæ˜¯æ–‡æœ¬æ•°æ®
ç”»ä¸ªçº¿æ€§çš„å›¾çœ‹çœ‹ f,axes = plt.subplots(2,2,figsize=(14,8)) #è´Ÿç›¸å…³çš„ä¸¤ä¸ª sns.</description>
    </item>
    
    <item>
      <title>WZU_çº¿æ€§å›å½’ä»£ç å­¦ä¹ è®°å½•</title>
      <link>https://example.com/p/wzu_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/wzu_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>æœºå™¨å­¦ä¹ ç»ƒä¹  - çº¿æ€§å›å½’ ä»£ç ä¿®æ”¹å¹¶æ³¨é‡Šï¼šé»„æµ·å¹¿ï¼Œhaiguang2000@wzu.edu.cn
å•å˜é‡çº¿æ€§å›å½’ import numpy as np import pandas as pd import matplotlib.pyplot as plt import matplotlib.pyplot as plt plt.rcParams[&amp;#39;font.sans-serif&amp;#39;]=[&amp;#39;SimHei&amp;#39;] #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾ plt.rcParams[&amp;#39;axes.unicode_minus&amp;#39;]=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå· path = &amp;#39;data/regress_data1.csv&amp;#39; data = pd.read_csv(path) data.head() result: code:
data.describe() result: çœ‹ä¸‹æ•°æ®é•¿ä»€ä¹ˆæ ·å­
code:
data.plot(kind=&amp;#39;scatter&amp;#39;, x=&amp;#39;äººå£&amp;#39;, y=&amp;#39;æ”¶ç›Š&amp;#39;, figsize=(12,8)) plt.xlabel(&amp;#39;äººå£&amp;#39;, fontsize=18) plt.ylabel(&amp;#39;æ”¶ç›Š&amp;#39;, rotation=0, fontsize=18) plt.show() result: ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ¥å®ç°çº¿æ€§å›å½’ï¼Œä»¥æœ€å°åŒ–ä»£ä»·å‡½æ•°ã€‚
é¦–å…ˆï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªä»¥å‚æ•°$w$ä¸ºç‰¹å¾å‡½æ•°çš„ä»£ä»·å‡½æ•° $$J\left( w \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{{{\left( {{h}}\left( {{x}^{(i)}} \right)-{{y}^{(i)}} \right)}^{2}}}$$ å…¶ä¸­ï¼š$${{h}}\left( x \right)={{w}^{T}}X={{w }{0}}{{x}{0}}+{{w }{1}}{{x}{1}}+{{w }{2}}{{x}{2}}+&amp;hellip;+{{w }{n}}{{x}{n}}$$ code:
def computeCost(X, y, w): inner = np.</description>
    </item>
    
    <item>
      <title>ç”¨scikit-learnå’Œpandaså­¦ä¹ Ridgeå›å½’</title>
      <link>https://example.com/p/%E7%94%A8scikit-learn%E5%92%8Cpandas%E5%AD%A6%E4%B9%A0ridge%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8scikit-learn%E5%92%8Cpandas%E5%AD%A6%E4%B9%A0ridge%E5%9B%9E%E5%BD%92/</guid>
      <description>æ•°æ®è¯»å–ä¸è®­ç»ƒé›†æµ‹è¯•é›†åˆ’åˆ† import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) matplotlib.style.use(&amp;#34;ggplot&amp;#34;) from sklearn.linear_model import LinearRegression from sklearn import datasets data = pd.read_csv(&amp;#34;./CCPP/Folds5x2_pp.csv&amp;#34;) data.head() result: code:
from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=22) print(X_train.shape) print(X_test.shape) print(y_train.shape) print(y_test.shape) result:
(7176, 4) (2392, 4) (7176, 1) (2392, 1) ç”¨sklearnè¿è¡ŒRidgeå›å½’ è¦è¿è¡ŒRidgeå›å½’ï¼Œæˆ‘ä»¬å¿…é¡»è¦æŒ‡å®šè¶…å‚æ•°Î±ã€‚ä½ ä¹Ÿè®¸ä¼šé—®ï¼šâ€œæˆ‘ä¹Ÿä¸çŸ¥é“è¶…å‚æ•°æ˜¯å¤šå°‘å•Šï¼Ÿâ€ æˆ‘ä¹Ÿä¸çŸ¥é“ï¼Œé‚£ä¹ˆæˆ‘ä»¬éšæœºæŒ‡å®šä¸€ä¸ª(æ¯”å¦‚1)ï¼Œåé¢æˆ‘ä»¬ä¼šè®²åˆ°ç”¨äº¤å‰éªŒè¯ä»å¤šä¸ªè¾“å…¥è¶…å‚æ•°Î±ä¸­å¿«é€Ÿé€‰æ‹©æœ€ä¼˜è¶…å‚æ•°çš„åŠæ³•ã€‚
from sklearn.linear_model import Ridge ridge = Ridge(alpha=1) ridge.fit(X_train,y_train) result:
Ridge(alpha=1) code:
print(ridge.intercept_) print(ridge.coef_) result:</description>
    </item>
    
    <item>
      <title>ç”¨scikit-learnå’Œpandaså­¦ä¹ çº¿æ€§å›å½’</title>
      <link>https://example.com/p/%E7%94%A8scikit-learn%E5%92%8Cpandas%E5%AD%A6%E4%B9%A0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/%E7%94%A8scikit-learn%E5%92%8Cpandas%E5%AD%A6%E4%B9%A0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description>pandasæ¥è¯»å–æ•°æ® import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt matplotlib.style.use(&amp;#34;ggplot&amp;#34;) plt.rcParams[&amp;#34;font.sans-serif&amp;#34;] = &amp;#34;SimHei&amp;#34; plt.rcParams[&amp;#34;axes.unicode_minus&amp;#34;] = False from sklearn import datasets,linear_model import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) data = pd.read_csv(&amp;#34;./CCPP/Folds5x2_pp.csv&amp;#34;) data.head() result: å‡†å¤‡è¿è¡Œç®—æ³•çš„æ•°æ® data.shape result:
(9568, 5) ç»“æœæ˜¯(9568, 5)ã€‚è¯´æ˜æˆ‘ä»¬æœ‰9568ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬æœ‰5åˆ—ã€‚
ç°åœ¨æˆ‘ä»¬å¼€å§‹å‡†å¤‡æ ·æœ¬ç‰¹å¾Xï¼Œæˆ‘ä»¬ç”¨ATï¼Œ Vï¼ŒAPå’ŒRHè¿™4ä¸ªåˆ—ä½œä¸ºæ ·æœ¬ç‰¹å¾ã€‚
code:
X = data[[&amp;#34;AT&amp;#34;,&amp;#34;V&amp;#34;,&amp;#34;AP&amp;#34;,&amp;#34;RH&amp;#34;]] X.head() result: code:
y = data[[&amp;#34;PE&amp;#34;]] y.head result: åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1) print(X_train.shape) print(X_test.shape) print(y_train.shape) print(y_test.shape) #å¯ä»¥çœ‹åˆ°75%çš„æ ·æœ¬æ•°æ®è¢«ä½œä¸ºè®­ç»ƒé›†ï¼Œ25%çš„æ ·æœ¬è¢«ä½œä¸ºæµ‹è¯•é›†ã€‚ result: è¿è¡Œscikit-learnçš„çº¿æ€§æ¨¡å‹ scikit-learnçš„çº¿æ€§å›å½’ç®—æ³•ä½¿ç”¨çš„æ˜¯æœ€å°äºŒä¹˜æ³•æ¥å®ç°çš„ã€‚</description>
    </item>
    
  </channel>
</rss>
